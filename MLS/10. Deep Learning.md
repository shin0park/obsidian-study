## Deep Learning 101

- 심층 학습(Deep Learning)은 인간 뇌의 뉴런 연결 방식을 모방한 신경망을 기반으로 함
- 단순한 뉴런 단위는 간단하지만, 다층으로 연결될 경우 학습과 추론이 가능
    
### Biological Inspiration (생물학적 영감)

- 뉴런은 축삭(axon)으로 연결되며, 충분한 입력 자극이 오면 신호를 발화(fire)
- 뇌에는 수십억 개의 뉴런과 수천 개의 연결이 있어 복잡한 인지와 학습이 가능
    
#### Cortical Columns (피질 기둥 구조)

- 뉴런들은 **mini-column**(약 100개 뉴런 단위)으로 구성되고, 이들이 모여 **hyper-column**을 형성한다.
- 약 1억 개 이상의 mini-column이 병렬로 정보 처리 → GPU 구조와 유사하다.
	- 이 유사성은 딥러닝 모델의 훈련에 왜 GPU가 CPU보다 훨씬 효율적인지를 설명하는 근본적인 이유가 된다.
	- 딥러닝 모델은 수십억 개의 매개변수에 대한 행렬 연산을 수행하는데, GPU는 수천 개의 작은 코어를 통해 이러한 대규모 병렬 연산을 동시에 처리하도록 설계되어 있다. 
    

---

### Deep Neural Networks (심층 신경망)

- ![](images/Pasted%20image%2020250826012906.png)
  
- 심층 신경망(Deep Neural Networks, DNN)은 여러 개의 숨겨진 층(hidden layers)을 가진 신경망을 의미한다.
- 기본구조: 입력신호(x) → 가중치(weight) 곱하고-> 편향(Bias, b)를 합산(Σ) → 활성화 함수(activation) → 출력(y) 이 과정을 반복한다.
	- **가중치(Weight):** 입력 신호의 중요도를 조절하는 역할을 한다. 학습 과정에서 이 가중치들이 조정되며 데이터의 패턴을 파악하게 된다.
	- **편향(Bias):** 뉴런의 활성화 임계값을 조절하는 상수 값으로, 입력 신호가 0일 때도 뉴런이 활성화될 수 있게 해준다.
    
- 다층 구조를 통해 복잡한 입력-출력 매핑 가능하다
    
### Deep Learning Frameworks

- 대표 프레임워크: 
	- **TensorFlow/Keras**
		- 구글이 개발한 오픈 소스 라이브러리로, 딥러닝 모델 개발에 가장 널리 사용된다. 
		- Keras는 Tensorflow 위에서 작동하는 고수준(high-level) API로, 복잡한 딥러닝 모델의 구축을 더 직관적이고 쉽게 만들어준다.
	- **MXNet**
		- Amazon이 후원하는 오픈 소스 딥러닝 프레임워크. 
		- AWS 환경에 최적화된 장점이 있으며, AWS EMR(Elastic MapReduce)에서 Apache MXNet을 공식적으로 지원
---

### Types of Neural Networks

- **피드포워드 신경망(Feedforward Neural Network):** 
	- 가장 기본적인 신경망 형태로, 데이터가 입력층에서 출력층으로 오직 한 방향으로만 전달된다.
    
- **컨볼루션 신경망(Convolutional Neural Networks, CNN):** 
	- 이미지 분류(예: 이미지에서 정지 표지판 식별)와 같이 정형화되지 않은 데이터 내의 공간적 특징을 찾는 데 특화되어 있다.
	- 이미지 분류, 기계 번역, 문장 분류 등.
    
- **순환 신경망(Recurrent Neural Networks, RNN):** 
	- 시계열 데이터(예: 주가 예측)나 문장 속 단어 이해, 기계 번역 등 시간적 순서가 있는 시퀀스 데이터를 처리하는 데 사용된다. 
	- LSTM(Long Short-Term Memory)과 GRU(Gated Recurrent Unit)는 RNN의 대표적인 변형 모델

---

### Activation Functions (활성화 함수)

- 활성화 함수는 뉴런 입력 신호를 기반으로 출력 결정하며, 신경망의 표현력을 결정하는 핵심적인 요소이다.
- 단순한 활성화 함수는 여러 가지 근본적인 한계를 가진다
- 학습(역전파)을 가능하게 하려면 **비선형 함수** 필요
    

#### Linear

- 단순 선형 함수, 입력과 출력이 비례 관계
- 뉴런에 아무런 '변환'을 수행하지 않기 때문에, 여러 층을 쌓아도 결국 전체 네트워크가 하나의 선형 함수로 축소된다. 
- 기울기가 항상 일정하므로, 기울기 기반의 가중치 업데이트를 사용하는 역전파(backpropagation)가 의미 있게 작동하지 않는다.
    

#### Binary Step

- ![](images/Pasted%20image%2020250826013551.png)
- 0/1 출력만 가능, 다중 분류 불가
- 미분 불가능 지점(수직 기울기)이 존재하여 미적분 기반의 역전파 알고리즘에 문제를 일으킴

---

-> 신경망이 복잡한 데이터의 패턴을 학습하려면 '비선형성(non-linearity)'이 필수적이다.
#### Sigmoid / TanH

- ![](images/Pasted%20image%2020250826013604.png)
- **Sigmoid / Logistic 함수:** 
	- 모든 입력값을 0과 1 사이의 값으로 변환하는 부드러운 S자 곡선 형태
- **TanH(Hyperbolic Tangent) 함수:** 
	- 모든 입력값을 -1과 1 사이의 값으로 변환하는 부드러운 곡선. 
	- 출력값이 0을 중심으로 분포되어 학습이 더 효율적이므로 Sigmoid보다 일반적으로 선호된다

- 단점: **'기울기 소실(Vanishing Gradient)' 문제
	- 입력값이 매우 크거나 작을 때, 함수의 기울기가 0에 가까워지는 포화(saturation) 현상이 발생
	- 이로 인해 역전파 과정에서 가중치 업데이트가 거의 일어나지 않아 학습이 매우 느려지거나 멈추는 현상이 나타남 
	- 계산 비용이 상대적으로 비쌈
    

#### ReLU

**ReLU(Rectified Linear Unit):** 
- 음수 입력은 0으로, 양수 입력은 그대로 통과. 
- Sigmoid나 TanH에 비해 계산이 훨씬 빠르고 효율적. 
- 하지만 음수 입력에 대한 기울기가 항상 0이므로, 한 번 0보다 작은 입력이 들어오면 해당 뉴런이 더 이상 학습되지 않는 **'죽은 ReLU(Dying ReLU)'** 문제가 발생할 수 있다.
- ![](images/Pasted%20image%2020250826013615.png)
    

**Leaky ReLU:** 
- 죽은 ReLU' 문제를 해결하기 위해 음수 입력에 대해 0이 아닌 아주 작은 기울기(일반적으로 0.01)를 부여
- ![](images/Pasted%20image%2020250826013627.png)
    

**PReLU(Parametric ReLU):** 
- Leaky ReLU의 고정된 음수 기울기 값을 역전파를 통해 학습하도록 개선한 형태
- 즉, 음수 구간 기울기를 학습으로 최적화
- ![](images/Pasted%20image%2020250826013638.png)

    

#### 기타 ReLU 변형

- ![](images/Pasted%20image%2020250826013652.png)
- **ELU(Exponential Linear Unit):** 음수 영역에서 기울기가 0으로 포화되지 않고 부드럽게 감소하는 특징이 있다.
- **Swish:** 구글이 개발한 함수로, 특히 40개 이상의 층을 가진 매우 깊은 네트워크에서 뛰어난 성능을 보인다.
- **Maxout:** 여러 개의 선형 함수 입력 중 최댓값을 출력하는 함수로, ReLU의 일반화된 형태. 
	- 그러나 학습해야 할 매개변수가 두 배로 늘어나 실용성이 떨어진다는 단점이 있다.
    

####  Softmax

- ![](images/Pasted%20image%2020250826013701.png)
- 다중 클래스 분류 문제의 마지막 출력 레이어에 사용
- 각 클래스에 대한 출력을 확률 값(총합이 1)으로 변환하여, 가장 높은 확률을 가진 클래스를 예측 결과로 선택할 수 있게 해준다.
    

---

### Choosing Activation Functions

- **다중 분류 문제의 최종 레이어→ Softmax
    
- **RNN:** Tanh가 좋은 성능을 보임
    
- **그 외:** 우선 ReLU로 시작하여, '죽은 ReLU' 문제가 발생하거나 성능 개선이 필요할 경우 Leaky ReLU를 시도. PReLU, Maxout 등은 최후의 수단으로 고려할 수 있다. 

- 매우 깊은 네트워크를 구축할 때는 Swish 함수를 고려


**활성화 함수 비교표**

|함수명|특성|장점|단점|권장 사용처|
|---|---|---|---|---|
|**선형**|f(x)=x|없음|역전파 불가, 비선형성 부족|없음|
|**이진 계단**|x>0이면 1, 아니면 0|직관적|미분 불가, 다중 분류 부적합|없음|
|**Sigmoid**|0∼1로 변환|부드러움, 미분 가능|기울기 소실, 계산 비쌈|과거에 주로 사용|
|**TanH**|−1∼1로 변환|Sigmoid보다 학습 효율적|기울기 소실, 계산 비쌈|RNN 계열|
|**ReLU**|음수 0, 양수 그대로|계산 빠르고 효율적|'죽은 ReLU' 문제|대부분의 딥러닝 모델|
|**Leaky ReLU**|음수에도 작은 기울기|'죽은 ReLU' 문제 해결|ReLU보다 약간 복잡|ReLU 대체재|
|**PReLU**|음수 기울기를 학습|Leaky ReLU보다 유연|복잡, 성능 보장 어려움|실험적 접근|
|**Softmax**|출력을 확률 분포로 변환|다중 분류 최종 출력에 필수|단일 레이블에만 적합|다중 클래스 분류의 출력층|

---

### CNN(Convolution Neural Network)

- 이미지 분류(예: 사진 속 '정지 표지판' 식별), 기계 번역, 감정 분석 등과 같이 정형화되지 않은 데이터 내의 특징을 찾아내는 데 탁월한 성능을 발휘한다.

- 특징: **위치 불변성 (feature-location invariant)**
	- 특히 특정 위치에 국한되지 않는 특징(feature-location invariant)을 찾아낼 수 있는 강점을 가진다.
    
- 동작 원리:
	- ![](images/Pasted%20image%2020250826235112.png)
    - 인간의 시각 피질 구조를 모방: 
		- 우리의 뇌는 '국소 수용 영역(local receptive fields)'을 가지고 있어, 시야의 일부분에만 반응하며 이들이 겹쳐 전체 시야를 처리
		- 점, 선, 모서리와 같은 단순한 특징들을 식별한 후, 이러한 정보가 상위 계층으로 전달되며 점차 복잡한 이미지(예: 형태, 객체)를 인식하는 구조
    - CNN은 이와 유사하게 작동
	    - '필터(filters)' 또는 '커널(kernels)'이라고 불리는 국소 수용 영역이 이미지를 스캔하며 모서리나 선과 같은 특징을 찾아냄
	    - ex) stop 표지판을 인식하는 과정에서, 개별 필터들은 표지판의 모서리를 감지하고, 이 정보가 상위 계층으로 전달되어 표지판의 모양과 글자를 식별 -> 이러한 특징 조합이 최종적으로 'stop 표지판'이라는 패턴과 일치할 때 인식이 완료
	    - 필터 → 모양 → 객체 인식 계층적으로 진행
	      
- Keras/Tensorflow를 사용한 CNN 구현
	- Keras와 Tensorflow를 사용하면 CNN 모델을 쉽게 구현 가능
		- `Conv2D` 레이어: 2차원 이미지 데이터에 컨볼루션 연산을 수행하여 특징 맵(feature map)을 생성함
		- `MaxPooling2D` 레이어: 특징 맵 내의 주어진 블록에서 가장 큰 값만 남겨 차원을 축소(subsampling)함. 이는 계산 비용을 줄이고 과적합(overfitting)을 방지하는 효과가 있음
		- `Flatten` 레이어: 2차원 레이어의 출력을 1차원 벡터로 변환하여 완전 연결(Dense) 레이어에 전달
	- 일반적인 CNN 아키텍처는 다음과 같은 순서를 따른다: 
		- `Conv2D` -> `MaxPooling2D` -> `Dropout` -> `Flatten` -> `Dense` -> `Dropout` -> `Softmax`.
    
- 한계: CNN 모델을 구축하는 것은 여러 가지 어려움을 수반
	- **높은 리소스 요구량:** 훈련 시 CPU, GPU, RAM 등 막대한 컴퓨팅 자원을 필요로 함
	- **많은 하이퍼파라미터:** 커널 크기, 레이어 수, 풀링(pooling)량 등 수많은 하이퍼파라미터 튜닝이 필요
	- **데이터 확보의 어려움:** 양질의 훈련 데이터를 확보하고 이를 저장하고 접근하는 것이 가장 어려운 부분 중 하나
    
#### 주요 CNN 아키텍처

- CNN 아키텍처는 수많은 연구를 통해 지속적으로 발전해 왔다.
- 그 발전 과정은 단순히 레이어 수를 늘리는 것을 넘어, 깊이 증가에 따른 성능 저하 문제를 해결하는 방향으로 이루어졌다.
- 그렇다면 높은 성능에 적합한 레이어나 많은 파라미터들을 어떻게 찾아내는가. 이를 위한 여러 아키텍처 존재

종류
- **LeNet-5:** 손글씨 인식에 적합하도록 고안된 초기 CNN 아키텍처
    
- **AlexNet**: LeNet보다 더 깊은 구조를 가진 이미지 분류 모델로, CNN의 상업적 가능성을 증명
    
- **GoogLeNet:** '인셉션 모듈(inception modules)'을 도입하여 계산 효율성을 높이면서도 더 깊은 네트워크를 구축
    
- **ResNet(Residual Network)**: 
	- '스킵 연결(skip connections)'을 통해 네트워크가 깊어져도 성능이 저하되는 현상을 해결한 혁신적인 모델
	- 이 접근법은 입력 신호를 여러 레이어를 건너뛰고 바로 출력에 더함으로써 기울기 소실 문제를 완화하여 매우 깊은 네트워크에서도 효과적인 학습을 가능하게 함.

---
### RNN (Recurrent Neural Network)

- 주가 예측, 자율 주행차의 주행 경로 결정 등과 같은 시계열 데이터나, 문장 속 단어 이해, 기계 번역 등 임의 길이의 시퀀스 데이터를 처리하는 데 사용
    
- 구조: 
	- ![](images/Pasted%20image%2020250826235134.png)
	- RNN은 '메모리 셀(Memory Cell)'을 통해 이전 단계의 정보를 현재 단계의 처리 과정에 반영하는 순환적인 구조를 가짐. 
	- 이는 과거의 상태를 기억하고 다음 예측에 활용하는 방식으로 작동하도록 하며, 이 덕분에 시간의 흐름에 따라 변화하는 데이터의 패턴을 파악하는 데 유용하다.
	  
- RNN topologies
	- **Sequence to sequence:** 일련의 입력 시퀀스를 기반으로 또 다른 출력 시퀀스를 예측. 
		- 예: 시계열 데이터에 기반한 주가 예측
	    
	- **Sequence to vector:** 입력 시퀀스를 고정된 크기의 벡터로 변환. 
		- 예: 문장의 단어를 분석하여 감정(sentiment) 벡터로 변환.
	    
	- **Vector to sequence:** 고정된 벡터 입력으로부터 시퀀스를 생성
		- 예: 이미지로부터 설명 생성
	    
	- **Encoder -> Decoder:** 입력 시퀀스를 인코더가 벡터로 변환하고, 디코더가 이 벡터를 다시 출력 시퀀스로 변환. 
		- 예: 기계 번역

- 학습: 
	- **Backpropagation Through Time (BPTT)** 사용
		- 이는 모든 시간 단계에 대해 역전파를 적용해야 하므로 네트워크가 매우 깊은 것처럼 되어 기울기 소실 또는 폭발 문제가 발생하기 쉽다. 
		- 과거의 중요한 정보가 시간이 지남에 따라 점차 희석되어 사라지는 문제가 발생함
    
- 문제: 긴 시퀀스 학습 시 정보 희석(Vanishing Gradient)
    - 해결책: 
	    - **LSTM(Long Short-Term Memory)**
		    - LSTM은 장기 상태(long-term state)와 단기 상태(short-term state)를 별도로 관리하여 과거 정보의 손실을 방지
	    - **GRU(Gated Recurrent Unit)**
		    - GRU는 LSTM을 단순화한 형태로, 유사한 성능을 보이면서도 계산 효율성이 더 높음
        
- 단점: 학습 어려움, 리소스 집약적, 하이퍼파라미터에 민감.

+
#### 손실 함수(Loss Function)란?

- 손실 함수는 모델의 예측값과 실제값 사이의 오차를 계산하는 함수
- 손실 함수의 값이 작을수록 모델의 예측이 더 정확하다는 의미
#### 역전파(**Backpropagation**)란

- 역전파는 딥러닝 모델의 학습 과정에서 사용되는 알고리즘으로, 모델의 가중치를 최적화하기 위해 손실 함수의 기울기를 계산하고 이를 바탕으로 가중치를 업데이트하는 과정
- 기울기를 통해 손실함수의 값을 최소화 하는 방향으로 가중치를 업데이트

---
### Modern NLP (자연어 처리)

- 최신 트렌드: **Transformer 아키텍처**
	- 최근의 자연어 처리 분야에서는 RNN의 순차 처리 방식의 한계를 극복한 **트랜스포머(Transformer)** 아키텍처가 각광받고 있다 
	- 트랜스포머는 **'자기-어텐션(self-attention)'** 메커니즘을 도입하여, 입력 데이터의 각 부분이 다른 부분에 대해 얼마나 중요한지를 가중치로 부여한다 
	- 이 덕분에 전체 입력 시퀀스를 한 번에 처리할 수 있어, RNN처럼 단어 하나씩 순차적으로 처리할 필요가 없다.
        
- 주요 모델: **BERT, RoBERTa, GPT, T5, DistilBERT**
	- DistilBERT: **'지식 증류(knowledge distillation)'** 기법을 통해 모델 크기를 40%까지 줄이면서도 성능을 유지하여, 효율적인 추론을 가능하게 함
	  
---
### Transfer Learning (전이 학습)

- 대규모 모델을 처음부터 학습하는 것은 불가능에 가깝다.
- 전이 학습(Transfer Learning)은 대규모 데이터로 사전 훈련된(pre-trained) 모델을 가져와, 특정 작업에 맞게 미세 조정(fine-tuning)하는 기법이다.
	- 최신 NLP 모델들은 수십억 개의 매개변수를 가져서, 처음부터 훈련시키기에는 막대한 컴퓨팅 자원과 시간이 필요하다 
	- 이러한 문제를 해결하기 위해 Hugging Face와 같은 **'Model zoos'** 이 사전 훈련된 모델을 제공하며, 이를 AWS SageMaker의 Hugging Face Deep Learning Containers와 같은 서비스를 통해 손쉽게 활용할 수 있다.
    
- 전이 학습은 일반 기업이나 개발자도 이러한 최첨단 기술을 활용할 수 있게 해줌
- AWS가 SageMaker를 통해 이러한 모델을 쉽게 사용하도록 지원함.
- BERT 예시
	- BookCorpus + Wikipedia로 사전 학습
	- 추가 데이터로 fine-tuning → 낮은 learning rate 권장
    
#### 전이 학습 접근법

1. **Fine-tuning**: 낮은 학습률(low learning rate)로 기존 모델을 점진적으로 개선.
	1. BERT 모델은 BookCorpus 및 Wikipedia로 사전 훈련되어 있으며, 사용자는 자신의 데이터로 추가 훈련하여 특정 작업에 미세 조정할 수 있다.
    
2. **New Layers 추가**: 사전 훈련된 모델의 하위 레이어를 동결(freeze)하고, 상단에 새로운 레이어를 추가하여 새로운 데이터에 대한 예측을 학습시킴
   
3. **새로운 레이어 추가 후 미세 조정:** 두 가지 방법을 결합하여 처음에는 새로운 레이어만 훈련하고, 이후 전체 모델을 낮은 학습률로 미세 조정
    
4. **Retrain from scratch**: 훈련 데이터가 매우 방대하고 기존 모델의 사전 훈련 데이터와 근본적으로 다른 경우에만 사용
	1. 막대한 컴퓨팅 자원이 필요
    
5. **As-is 사용**: 원래 학습 데이터와 동일할 경우 그대로 사용

---
### Deep Learning on AWS (EC2 / EMR)

- AWS는 딥러닝 워크로드를 위한 다양한 컴퓨팅 환경을 제공
	- Amazon EMR(Elastic MapReduce)은 Apache MXNet과 같은 프레임워크와 GPU 인스턴스 유형을 지원하여 대규모 딥러닝 작업을 수행할 수 있도록 돕는다 
	- 딥러닝 모델 훈련을 위해 사전에 구성된 환경을 제공하는 **딥러닝 AMI(Amazon Machine Images)**를 제공한다.

- **EC2 인스턴스 유형**
    - **범용 GPU 기반 인스턴스:**
		- **P3:** 8개의 NVIDIA Tesla V100 GPU를 탑재한 훈련용 인스턴스
		- **P2:** 16개의 NVIDIA K80 GPU를 탑재한 인스턴스
		- **G3:** 4개의 NVIDIA M60 GPU를 탑재한 인스턴스
		- **G5g:** AWS Graviton2 프로세서와 NVIDIA T4G Tensor Core GPU를 탑재했으며, EMR에서는 아직 사용이 불가능
		- **P4d:** NVIDIA A100 GPU 기반의 "UltraClusters"로, 슈퍼컴퓨팅 용도에 적합
			
	- **AWS 전용 칩 기반 인스턴스:**
	    - **Trn1 / Trn1n:** AWS **Trainium** 칩 기반으로 '훈련(training)'에 최적화 
		    - Trn1n은 1600 Gbps의 더 높은 네트워크 대역폭을 제공하여 빠른 클러스터 통신을 지원
	    - **Inf2:** AWS **Inferentia2** 칩 기반으로 '추론(inference)'에 최적화
    
- **EMR**: Apache MXNet 및 GPU 인스턴스 지원


**AWS 딥러닝 인스턴스 비교표**

|인스턴스 유형|주요 하드웨어|최적화 용도|주요 특징|
|---|---|---|---|
|**P3**|NVIDIA Tesla V100 GPU|훈련|높은 성능의 범용 훈련 인스턴스|
|**P2**|NVIDIA K80 GPU|훈련|이전 세대의 범용 훈련 인스턴스|
|**G3**|NVIDIA M60 GPU|훈련|이전 세대의 범용 훈련 인스턴스|
|**G5g**|AWS Graviton2, T4G GPU|훈련/추론|ARM 기반 CPU와 GPU의 결합, EMR 미지원|
|**P4d**|NVIDIA A100 GPU|훈련|슈퍼컴퓨팅 용도의 초고성능 인스턴스|
|**Trn1/Trn1n**|AWS Trainium 칩|**훈련**|훈련에 특화된 비용 최적화 인스턴스|
|**Inf2**|AWS Inferentia2 칩|**추론**|추론에 특화된 비용 및 성능 최적화 인스턴스|
