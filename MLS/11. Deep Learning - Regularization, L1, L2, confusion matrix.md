
### Tuning Neural Networks (신경망 튜닝)

#### Learning Rate (학습률)

- 신경망 모델의 성능을 최적화하는 데 있어 학습률(Learning Rate)은 가장 기본적인 하이퍼파라미터 중 하나
- 신경망은 **경사하강법(gradient descent)** 으로 학습
	- 학습률은 경사 하강법(gradient descent)과 같은 최적화 알고리즘이 손실 함수(cost function)를 최소화하기 위해 모델의 파라미터, 즉 가중치를 업데이트할 때 얼마나 큰 '보폭'으로 이동할지를 결정하는 값
	- 모델이 최적의 해에 도달하는 속도와 안정성에 직접적인 영향을 미친다.
	- AWS는 Amazon ML 서비스에서 학습률을 확률적 경사 하강법(SGD) 알고리즘에 사용되는 상수 값으로 정의하며, 이 값이 알고리즘이 최적의 가중치에 수렴하는 속도에 영향을 미친다고 한다.
- ![](images/Pasted%20image%2020250901010647.png)
- 너무 크면 최적점을 지나쳐 버리고, 너무 작으면 수렴이 매우 느림
	- 학습률이 너무 높은 경우: 경사 하강법이 손실 함수의 최솟값을 지나쳐 '오버슈팅(overshoot)'하게 되면서 발산하거나 최적의 해를 찾지 못하고 불안정하게 맴돌 수 있다.
	- 학습률이 너무 작은 경우: 가중치 업데이트가 매우 미세하게 이루어져 최적의 해에 도달하는 데 지나치게 오랜 시간이 소요되어 훈련 효율성이 떨어진다.
- Amazon SageMaker는 자동 모델 튜닝(Automatic Model Tuning, HPO) 기능을 제공하여 학습률, 배치 크기 등 여러 하이퍼파라미터의 최적 조합을 자동으로 탐색한다. 
	- 사용자가 최적의 값을 수동으로 찾아야 하는 부담을 줄이고, AWS의 최적화된 시스템에 의존하여 튜닝 프로세스의 효율성을 극대화할 수 있도록 도움
    
#### Batch Size (배치 크기)

- 배치 크기는 모델의 수렴 경로와 훈련 속도에 영향을 미치는 중요한 하이퍼파라미터이다.
- ![](images/Pasted%20image%2020250901005645.png) (https://bruders.tistory.com/79)
- 각 훈련 epoch에서 모델이 가중치를 업데이트하기 위해 처리하는 훈련 데이터 샘플의 수를 의미
	- epoch 란
		- 사전적의미: 시대
		- 딥러닝에서의 epoch는 전체 데이터 셋이 신경망을 통과한 횟수, 즉 모든 데이터셋을 학습 하는 횟수를 의미
		- 예. 1-epoch: 전체 데이터셋이 하나의 신경망에 적용되어 순전파와 역전파를 통해 신경망을 한번 통과했다는 의미
		- epoch값이 너무 작으면 underfitting, 너무 크면 overfitting이 발생할 확률이 높다.

- ![400](images/Pasted%20image%2020250901005907.png)
- **작은 배치**: 
	- 손실 함수 곡선의 지역 최솟값(local minima)에서 벗어나기 쉬워 더 나은 일반화 성능을 얻을 수 있는 경향이 있음
	- 배치 크기가 너무 작아지면 적은 데이터로 가중치가 자주 업데이트되어 훈련이 불안정해질 수 있음
- **큰 배치**: 
	- 모델이 잘못된 해에 수렴하여 훈련이 제대로 진행되지 않거나, 지역 최솟값에 갇히게 될 가능성이 있음
	- 한번에 처리해야할 데이터의 양이 많아져, 학습속도가 느려지고 메모리 부족문제가 발생할 수 있음.
- epoch마다 무작위 섞기(random shuffling)가 필요하다.
	- 데이터가 무작위로 섞여 있지 않고 특정 유형의 데이터가 연속적으로 제공될 경우, 모델이 해당 데이터에만 과도하게 편향되어 전체 데이터에 대한 최적의 솔루션을 찾지 못할 수 있다.

#### Iteration
- 1-epoch를 마치는데 필요한 미니 배치의 수를 의미
- 즉, 1-epoch를 마치는데 필요한 파라미터 업데이트 횟수
- step이라 부르기도한다.
    

 요약 (To Recap)

- 작은 배치 크기는 모델이 손실 함수 곡선의 지역 최솟값에 갇히는 경향을 줄일 수 있다.
- 큰 배치 크기는 때때로 잘못된 솔루션으로 수렴할 수 있다.
- 높은 학습률은 최적의 솔루션을 지나쳐 오버슈팅할 수 있다.
- 낮은 학습률은 모델 훈련에 필요한 총 시간을 증가시킨다.

---

### Neural Network Regularization (정규화 기법)

#### What is Regularization?

- 모델이 훈련 데이터에 지나치게 '과적합(overfitting)'되는 현상을 방지하는 데 사용되는 일련의 기법들을 의미
- 학습 데이터에 존재하는 특정 패턴이나 노이즈까지 학습하여, 학습 데이터에서는 매우 높은 정확도를 보이지만 새로운 데이터에는 일반화 성능이 떨어지는 문제
- 학습 시 **training, evaluation, testing dataset** 구분 필요
	- 과적합을 탐지하고 방지하기 위해, 모델은 일반적으로 훈련(training), 평가(evaluation), 테스트(testing) 데이터 세트를 사용하여 검증된다.
	- 훈련 데이터셋에서는 높은 정확도를 보이지만, 평가 또는 테스트 데이터셋에서는 낮은 정확도를 보이는 것이 과적합의 전형적인 증상
	- 정규화 기법의 목적은 이러한 과적합을 방지하고 모델의 일반화 능력(generalization ability)을 향상시키는 것 -> 모델의 유연성(flexibility)을 인위적으로 감소시켜 훈련 데이터의 노이즈에 덜 민감하게 반응하도록 만든다.
- 모델의 훈련 과정은 과적합(높은 분산)과 과소적합(underfitting, 높은 편향) 사이의 균형점을 찾는 과정이다.
    
#### Dropout

![](images/Pasted%20image%2020250901014415.png)

- 학습 과정에서 무작위로 일부 뉴런을 '제거(drop out)'하여 과적합 방지한다.
- 매 훈련 반복(iteration)마다 다른 뉴런 조합을 사용하여 가중치를 업데이트한다.
- 이를 통해 각 뉴런이 다른 특정 뉴런에 과도하게 의존하는 것을 방지하고, 모델이 더 견고하고 일반화된 패턴을 학습하도록 유도한다.
- Amazon SageMaker의 `Object2Vec` 알고리즘은 훈련 파라미터로 `dropout`을 명시적으로 제공하여 이 기법을 적용할 수 있도록함

#### Early Stopping

- 모델의 훈련 과정에서 훈련 데이터에 대한 성능은 계속 개선되지만, 별도의 검증 데이터(validation data)에 대한 성능이 더 이상 개선되지 않거나 오히려 악화되는 지점에서 훈련을 중단하는 정규화 기법
- 모델이 훈련 데이터의 노이즈에 맞춰 과적합되기 시작하는 최적의 시점을 포착하여 훈련을 멈춤으로써, 과적합을 효과적으로 방지
- 조기 종료의 핵심은 적절한 '타이밍'을 판단하는 것
	- 훈련을 너무 일찍 멈추면 모델이 충분히 학습되지 않아 과소적합이 발생할 수 있고 반대로 너무 늦게 멈추면 모델이 과적합되어 일반화 성능이 저하될 수 있다.
- AWS
	- AWS는 이 복잡한 타이밍 판단을 자동화하여 훈련 과정의 비효율성을 줄인다. 
	- Amazon SageMaker의 하이퍼파라미터 튜닝 기능은 `TrainingJobEarlyStoppingType` 파라미터를 통해 조기 종료를 지원하며, 이를 `OFF` 또는 `AUTO`로 설정할 수 있다.

---

### L1 / L2 Regularization

- 정규화는 모델의 과적합을 방지하는 데 사용되는 광범위한 머신러닝 기법이다.
- 손실함수에 **Penalty Term(규제 항)** 을 더하여 Cost가 정해지고, 이에 따른 조절을 통해 Weight에 **Regularization**이 들어가는 것
	- 죽, 손실 함수에 가중치 제약을 추가하여 과적합 방지한다.
	- MSE (Mean Squared Error):  평균 제곱 오차 함수에 정규화를 적용한다면 아래와 같을 것이다.
		- ![](images/Pasted%20image%2020250901222905.png)
		- ![](images/Pasted%20image%2020250901222910.png)
		- https://draw-code-boy.tistory.com/502
		- 즉 penalty term을 추가함으로써 w가중치를 제어

- #### L1 Regularization (Lasso)
	- ![](images/Pasted%20image%2020250901222949.png)
	- ![](images/Pasted%20image%2020250901222941.png)
	- L1 정규화는 모델의 손실 함수에 가중치(wi )의 절댓값 합에 비례하는 페널티 항을 추가
	- 페널티 항: λ∑i=1k ∣wi ∣
	- L1 정규화는 "Lasso" 정규화라고도 불림
	- 손실이 최소가 되게 학습한다는 것은 Penalty Term도 더해져있으므로 Penalty Term 또한 최소가 되게 학습한다는 뜻 -> L1에서는 Penalty Term이 가중치들의 절댓값 총합이므로 가중치들이 최소가 되는 것
	- **L1에서는 특정 가중치들은 0으로 수렴하여 불필요한 Feature들은** 제거
- #### L2 Regularization (Ridge)
	- ![](images/Pasted%20image%2020250901223148.png)
	- ![](images/Pasted%20image%2020250901223153.png)
	- L2 정규화는 손실 함수에 가중치(wi )의 제곱 합에 비례하는 페널티 항을 추가
	- 페널티 항: λ∑i=1k wi2
	- L2 정규화는 "Ridge" 정규화 또는 "weight decay"라고도 불림
	- Penalty Term이 최소가 되도록 하는 것도 마찬가지
	- L2는 Descent를 하기 위해 w로 미분을 하면 w^2 Penalty Term함수는 w가 남는다. -> 이는 w의 기울기를 의미하며 0에 수렴하기 위한 값을 찾고 이 값을 다음 weight에 반영
	- **최적의 파라미터를 찾을 뿐 파라미터가 0이 되지는 않는다.**

L1은 가중치를 0으로 만들어 피처를 지우고, L2는 가중치가 완전히 0이 되지는 않아 피처가 모두 살아있는 이유

- ![](images/Pasted%20image%2020250901223342.png)
- 경사하강법은 손실함수의 기울기를 이용해서 가중치를 업데이트 하는 최적화 알고리즘이다. 
- 손실함수의 기울기가 작은 지점이 손실함수값이 최소로 계산되고 이때의 가중치값을 구하는
	- 손실 함수는 모델의 예측값과 실제값 사이의 차이를 나타내는 함수
- L1 정규화는 손실 함수에 절댓값 함수를 cost로 더한다. 기울기를 구하기 위해 가중치W에 대해 미분을 한다면.,추가한 Penalty Term도 같이 미분이 될 것. 
	- 절댓값 함수는 미분 불가능한 지점이 존재할 수 있다. 
	- 결국, 손실함수의 미분값이 0이 되는 지점을 찾아야 하는데, 미분 불가능한 지점은 경사하강법으로 w가중치의 최솟값을 구할 때, 미분이 정의되지 않기 때문에 w값을 구할 수 없고 w가 0이 되어 사라짐
	- 경사하강법의 계산식에서 가중치 w가 0에 도달하게 되는 구조
- L2 정규화는 제곱의 함수를 cost로 더하기 때문에 모든 지점을 미분 가능하게 됨. 따라서 W를 0에 수렴하도록 값을 구할 수는 있으나 0이 되지는 않음.

#### L1과 L2의 차이점 (What’s the difference?)

두 정규화 기법은 유사한 목적을 가지고 있지만, 가중치에 페널티를 부과하는 방식에 근본적인 차이가 있다.
- L1 정규화 (Lasso):
	- feature selection에 유리
		- 덜 중요한 피처의 가중치를 0으로 만들어 특징 선택(feature selection)을 수행한다.
	- 희소 출력(sparse),
		- 결과적으로 가중치가 0이 아닌 피처가 소수만 남게 되어 희소(sparse)한 모델을 생성
	- L2에 비해 연산 효율성이 낮을 수 있음
- L2 정규화 (Ridge)
	- 모든 피처 고려
		- 모든 피처를 모델에 유지하지만, 가중치 값을 0에 가깝게 줄여 과적합을 방지, 가중치가 완전히 0이 되지는 않음
	- 모든 피처가 고려되기 때문에 밀집(dense)한 모델을 생성
	- L1보다 연산 효율성이 높음

#### L1을 사용하는 이유 (Why would you want L1?)

- L1은 피처 선택을 통해 불필요한 피처의 가중치를 0으로 만들기 때문에, 모델의 차원을 효과적으로 줄일 수 있다.
- 이러한 희소성(sparsity)은 L1 정규화의 계산적 비효율성을 상쇄할 만큼 큰 가치를 가질 수 있다. 

---
### Grief with Gradients (기울기 문제)

- 신경망의 훈련 과정에서 경사 하강법과 역전파(backpropagation)를 통해 가중치를 업데이트할 때, 기울기(gradient) 값의 크기에 문제가 발생하는 현상이 존재한다.
- 이는 훈련의 안정성과 효율성에 직접적인 영향을 미친다.

#### Vanishing Gradient Problem (기울기 소실 문제)

- 기울기 소실(Vanishing Gradient) 문제는 훈련 시 기울기가 역전파를 통해 이전 계층으로 전달될 때 점진적으로 작아져 거의 0에 수렴하는 현상을 의미
- 깊은 신경망, RNN에서 기울기가 점점 0에 가까워지면서 학습이 멈추는 케이스가 있음
- 반대 현상: **Exploding Gradients** (기울기 폭발)
	- 반대로, 기울기가 기하급수적으로 커져 가중치 업데이트가 불안정해지고 모델이 발산하여 오버피팅을 유발

#### 해결책

- **다중 계층 계층 구조(Multi-level hierarchy):** 
	- 전체 네트워크를 여러 개의 작은 서브 네트워크로 나누어 개별적으로 훈련
- **장단기 메모리(Long Short-Term Memory, LSTM):** 
	- LSTM은 장기 상태(long-term state)와 단기 상태(short-term state)를 별도로 관리하여 과거 정보의 손실을 방지
- **잔여 네트워크(Residual Networks, ResNet):** 
	- 'skip connections'을 도입하여 기울기가 특정 계층을 우회하여 흐를 수 있도록 함으로써 정보 손실을 줄이고 훈련을 용이하게 함
- ReLU 같은 적절한 활성화 함수 선택
	- 시그모이드(sigmoid)나 하이퍼볼릭 탄젠트(tanh)와 달리, ReLU(Rectified Linear Unit)와 같은 활성화 함수는 양수 입력에 대해 기울기를 1로 유지함으로써 기울기 소실 문제를 완화하는 데 도움
    
#### Gradient Checking

- 신경망 훈련 과정에서 계산된 도함수(derivatives)의 정확성을 수치적으로 확인하는 디버깅 기법
- 이는 신경망 훈련 코드가 올바르게 구현되었는지 검증하는 데 유용하게 사용

---

### Confusion Matrix

- 모델의 성능을 평가할 때, 단순히 '정확도(Accuracy)'만으로는 모델의 실제 성능을 완벽하게 파악하기 어렵다
- 예: 드문 질병 예측 → 항상 “No”만 예측해도 99% 정확도가 됨
- 이러한 한계를 극복하기 위해, 예측 결과를 실제 값과 비교하여 시각적으로 보여주는 혼동 행렬(Confusion Matrix)이 사용
- 혼동 행렬은 **TP, TN, FP, FN** 값을 통해 성능을 종합적으로 평가

- 이진 혼동 행렬 (Binary Confusion Matrix)
	- 이진 분류 문제에서 혼동 행렬은 예측값과 실제값에 따라 결과를 네 가지 범주로 분류하는 2x2 테이블 형태
	- **이진 혼동 행렬의 구성 요소**

| **실제 클래스**              | **예측 클래스: 양성(Predicted Positive)** | **예측 클래스: 음성(Predicted Negative)** |
| ----------------------- | ---------------------------------- | ---------------------------------- |
| **양성(Actual Positive)** | 참 양성 (True Positive, TP)           | 거짓 음성 (False Negative, FN)         |
| **음성(Actual Negative)** | 거짓 양성 (False Positive, FP)         | 참 음성 (True Negative, TN)           |
- 요소
	- **참 양성(True Positive, TP):** 모델이 실제 양성(예: 'YES')을 양성으로 올바르게 예측한 경우
	- **참 음성(True Negative, TN):** 모델이 실제 음성(예: 'NO')을 음성으로 올바르게 예측한 경우
	- **거짓 양성(False Positive, FP):** 모델이 실제 음성을 양성으로 잘못 예측한 경우 (제1종 오류)  
	- **거짓 음성(False Negative, FN):** 모델이 실제 양성을 음성으로 잘못 예측한 경우 (제2종 오류)
- 대각선의 값이 높을 수록 정확도가 높은 것

예시
- 고양이 이미지 분류
    - ![](images/Pasted%20image%2020250901224725.png)
    - ![](images/Pasted%20image%2020250901224737.png)


---
### Measuring your Models

#### 정밀도와 재현율 (Precision and Recall)

- **정밀도(Precision):** 모델이 '양성'이라고 예측한 결과 중에서 실제로 '양성'인 비율을 나타냄
    
    - **공식:** Precision = TP / (TP + FN)
    - **중요성:** 거짓 양성(FP)이 큰 비용을 초래하는 경우에 중요 
	    - 예) 의료 검진이나 약물 검사에서 잘못된 양성 예측은 불필요한 치료나 심리적 고통을 유발할 수 있다.
        
- **재현율(Recall):** 실제 '양성'인 모든 사례 중에서 모델이 올바르게 '양성'으로 예측한 비율을 나타냄 
	- '민감도(Sensitivity)' 또는 'True Positive Rate'이라고도 한다.
    - **공식:** Recall= TP / (TP + FP)
    - **중요성:** 거짓 음성(FN)이 큰 비용을 초래하는 경우에 중요
	    - 예) 사기 탐지나 질병 진단에서 거짓 음성 예측은 중대한 손실이나 생명의 위험을 초래할 수 있다.

#### F1 Score

- Precision과 Recall의 조화 평균(harmonic mean)
- 두 지표 모두 중요할 때 균형 잡힌 평가를 제공
- F1=2⋅(Precision⋅Recall​/ (Precision+Recall))
    
#### Specificity

- TN / (TN + FP) → 실제 음성인 것들 중에서 모델이 올바르게 음성으로 예측한 비율을 의미
    
#### RMSE (Root Mean Squared Error)

- 회귀 모델에서 평균 제곱근 오차
- 오차는 양수 음수가 섞여 있기 때문에 단순히 더해서는 안되고, 부호를 없애야 정확한 오차를 구할 수 있다.
- 따라서, 각 오차의 값을 제곱해서 더해주고, n으로 나눠서 평균을 구한다. -> MSE(Mean Squared Error)
- MSE 값에 제곱근을 씌워준 값이 -> RMSE (Root Mean Squared Error)
- ![](images/Pasted%20image%2020250901230143.png)

---
### ROC / AUC / P-R Curve

#### ROC Curve

- ![](images/Pasted%20image%2020250902003831.png)
- **ROC 곡선(Receiver Operating Characteristic Curve)** 은 다양한 분류 임계값 설정에 따른 true positive rate (recall) vs false positive rate 의 그래프
- TPR(recall) vs. FPR(거짓 양성 비율)
- 곡선이 좌측 상단 모서리에 가까울수록 좋은 모델
- 대각선 위의 모든 점은 무작위 분류기보다 성능이 우수함을 의미
    
#### AUC

- ROC 곡선 아래 면적
- 분류기가 임의로 선택된 양성 인스턴스를 임의의 음성 인스턴스보다 더 높은 순위로 분류할 확률과 같다.
- AUC는 분류기의 전반적인 성능을 비교하는 데 널리 사용되는 단일 지표
- AUC 값이 1.0에 가까울수록 완벽한 분류기를 의미하며, 0.5는 무작위 추측과 다름없는 성능을 나타냄
    
#### P-R Curve

![](images/Pasted%20image%2020250902004408.png)

- **P-R 곡선(Precision-Recall Curve)**은 정밀도와 재현율 간의 절충 관계를 시각화한 그래프
- Precision vs. Recall
- ROC 곡선과 유사하게, 곡선 아래 면적이 넓을수록 모델 성능이 우수함을 의미
- P-R 곡선은 특히 정보 검색(information retrieval) 문제나 데이터 세트가 심하게 불균형한 경우에 ROC 곡선보다 더 유용


---
### Ensemble Learning (앙상블 학습)

#### Ensemble Methods

- 앙상블 학습(Ensemble Learning)은 여러 개의 개별 모델(종종 '약한 학습자'라고 불림)을 결합하여, 단일 모델보다 더 강력하고 안정적인 예측 성능을 가진 모델을 생성하는 기법
- 모델의 다양성을 활용하여 개별 모델의 약점을 상쇄하고 예측의 정확도와 견고성을 향상시키는 것을 목표 함
    
#### Bagging (Bootstrap Aggregation)

- 학습 데이터셋에서 복원 추출(random sampling with replacement)을 통해 여러 개의 새로운 학습 데이터셋을 생성하고, 각 데이터셋에서 독립적으로 모델을 훈련시키는 방식
	- 병렬처리가능
		- 각 모델은 병렬로 훈련될 수 있으며, 최종 예측은 모든 개별 모델의 예측을 평균 내어 도출
- 모델의 분산(variance)을 줄여 과적합을 방지하는 데 효과적
- 랜덤 포레스트(Random Forest)는 이러한 배깅 기법의 대표적인 예시
    
#### Boosting

- 학습 데이터의 각 관측치에 가중치를 부여하여 모델을 순차적으로(sequentially) 훈련시키는 방식
	- 각 모델은 이전 모델이 잘못 분류한 데이터에 더 높은 가중치를 부여함으로써 그 오류를 수정하는 데 집중함
- 부스팅은 모델의 편향(bias)을 줄여 전반적인 정확도를 향상
- 대표 알고리즘: **XGBoost**
	- AWS는 대규모 데이터 처리에 최적화된 부스팅 알고리즘인 XGBoost(eXtreme Gradient Boosting)를 SageMaker의 빌트인 프레임워크로 제공
	- XGBoost는 계산 속도와 확장성 측면에서 우수

#### Bagging vs. Boosting

배깅과 부스팅의 가장 큰 차이점 -> 훈련 방식(병렬 vs. 순차), 근본적인 철학

- Bagging: 
	- 여러 독립적인 모델을 훈련시켜 예측의 안정성을 확보하는 데 중점둠
	- 분산 감소를 목표
- Boosting: 
	- 이전 모델의 오류를 체계적으로 개선하여 모델의 예측 능력을 향상시키는 데 중점을 둠
	- 편향 감소를 목표
	- 전통적인 부스팅은 순차적인 훈련으로 인해 병렬화가 어려웠지만, XGBoost와 같은 최신 알고리즘은 CPU의 여러 코어를 활용하여 훈련을 병렬로 수행할 수 있도록 발전됨

**배깅과 부스팅 비교**

|특징|배깅 (Bagging)|부스팅 (Boosting)|
|---|---|---|
|**주요 목표**|분산(Variance) 감소|편향(Bias) 감소|
|**훈련 방식**|독립적, 병렬 훈련|순차적 훈련 (이전 모델의 오류 수정)|
|**모델 유형**|여러 개의 강력한 모델 생성|하나의 강력한 모델 생성|
|**예시 알고리즘**|랜덤 포레스트 (Random Forest)|XGBoost, AdaBoost|
|**주요 장점**|과적합 방지, 병렬 처리 용이|높은 예측 정확도 달성|
