
- Amazon Sagemaker > Notebook instances > crate notebook instance
	- open notebook
	- upload - Transformers 관련 py 파일

Transformer - Bert
- hugging face - 사전 훈련된 모델의 대규모 저장소 의 패키지를 설치한다 (pip install)
	- transformer 모델들 많이 있음
	- free
- Tokenizers
	- transformers 패키지로부터 tokenizer 하기 위한 패키지를 import
		- BertModel, BertTokenizer
		- Bert는 only encoder로 만들어진 트랜스포머이다 (디코더로만 구현된 GPT와는 반대로)
		- `tokenized = tokoenizer("I read a good novel.")`
- Positional Encoding
	- 병렬적으로 처리
	- sin/cos 함수를 통해 메트릭 추출
- Self-Attention
	- BertModel, BertTokenizer 를 import 해서 가져온다
	- 시각화를 위해 show 패키지 import
	- ```
	  tokenizer_viz = BertTokenizer.from_pretrained(modelName)
	  model_viz = BertModel.from_pretrained(modelName)
	  show(model_viz, "bert", tokenizer_viz, "I read a good novel.", display_mode = "light", head=11)
	  ```
	  - ex3ERT 라는 사이트에서도 시각화 가능
		  - ![](images/Pasted%20image%2020251229000640.png)

GPT2 model (137M parameter)
 - hugging face에서 가져온 transformer 패키지(pipeline)를 통해 사전에 훈련된 모델들을 쉽게 가져올 수 있다.
 - pipeline을 통해 gpt2 모델 가져옴
 - generator 함수에 특정 문장을 넣고 실행 -> 글을 작성
	 - 어떤 영화인지 말을 해주지 않아도 매우 구체적인 글을 작성해준 것을 볼 수 있음
- "Star Trek" 이란 문장을 넣고 실행
	- 위키피디아의 정보를 준 것을 볼 수 있음.

---

## Foundation Model

- 방대한 데이터로 사전 학습(pre-trained)된 대규모 Transformer 기반 모델이며
- 특정 Task에 맞게 fine tuning 을 거치게 된다.
	- 수조 개의 토큰으로 구성된 방대한 데이터셋을 심층 신경망 아키텍처를 통해 학습한 결과물로, 언어 이해와 텍스트 및 이미지 생성을 포함한 광범위한 일반 작업을 수행할 수 있는 범용성을 핵심 가치로 한다.
	- 과거의 데이터 과학자들이 매번 특정 작업을 위해 기계 학습 모델을 처음부터 개발해야 했던 것과 달리, 파운데이션 모델은 이미 구축된 강력한 성능을 출발점으로 삼아 기업의 고유한 요구 사항에 맞춰 빠르고 비용 효율적으로 애플리케이션을 개발할 수 있도록 지원한다.
- ex) GPT-n (OpenAI, Microsoft): 범용 텍스트 생성 및 복잡한 추론
	- Bert (Google): 자연어 이해 및 검색 쿼리 분석
	- DALL-E (OpenAI, Microsoft): 텍스트 기반 창의적 이미지 생성
	- LLaMa (Meta): 고성능 오픈 웨이트 언어 모델
	- Segment Anything (Meta): 이미지 내 모든 객체에 대한 시각적 세분화

### AWS Foundation Models

![](images/Pasted%20image%2020251229002125.png)
AWS는 **Amazon Bedrock**를 중심으로 여러 외부 및 자체 Foundation Model을 제공한다.

Jurassic-2 (AI21 Labs)
- 다국어 대형 언어 모델(LLM)
- 텍스트 생성에 특화
- 지원 언어: 스페인어, 프랑스어, 독일어, 포르투갈어, 이탈리아어, 네덜란드어 등
    
Claude (Anthropic)
- 대화형 LLM
- 주요 기능
    - 자연스러운 대화
    - 질문 응답(Q&A)
    - 워크플로 자동화 지원
        
Stable Diffusion (Stability AI)
- 이미지 생성 모델
	- 텍스트 프롬프트를 통해 독창적인 예술 작품, 로고, 디자인 템플릿을 생성하는 데 특화
- 활용 분야
    - 이미지
    - 예술 작품
    - 로고
    - 디자인 생성
        
Amazon Titan (AWS 자체 모델)
- AWS에서 직접 제공하는 Foundation Model
	- AWS가 직접 개발한 모델 제품군으로, 기업 환경에서 요구되는 성능, 보안, 비용 효율성의 균형을 목표로 한다.
- 주요 기능
    - 텍스트 요약
    - 텍스트 생성
    - 질문 응답(Q&A)
    - 임베딩 생성
- 임베딩 활용 사례
    - 개인화 추천
    - 검색(Search)

### Amazon SageMaker JumpStart with Generative AI

#### SageMaker JumpStart란?

- SageMaker Studio에 내장된 기능
- 사전 구축된 모델과 예제 노트북을 **즉시 실행 가능**한 상태로 제공
- 사용자는 복잡한 환경 설정 없이 바로 실습 및 실험 가능
    
#### 제공 모델 유형

1. Hugging Face 모델 (텍스트 생성)
    - Falcon
    - FLAN
    - BloomZ
    - GPT-J
        
2. Stable Diffusion
    - 이미지 생성
        
3. Amazon Alexa 모델
    - Encoder/Decoder 기반
    - 다국어 LLM

즉, JumpStart는 **생성형 AI 모델을 빠르게 테스트하고, 학습·배포까지 연결할 수 있는 진입 지점** 역할을 한다.


---

## Amazon Bedrock

Amazon Bedrock은 **Foundation Model을 API 형태로 제공하는 AWS의 완전관리형(Serverless) 서비스**이다.

- Foundation Model을 직접 인프라 구성 없이 API로 사용 가능
- 서버리스 구조이므로 인프라 관리 불필요
	- 개발자는 인프라를 직접 구축하거나 운영할 필요 없이 모델의 추능 성능과 기능을 즉시 활용할 수 있으며, 이는 기업의 민첩성을 극대화하는 핵심 요소
- **Fine-tuning API 제공**
    - 사용자는 S3에 라벨링된 예제 데이터를 업로드하여 모델 미세조정 가능
	    - 최소 약 20개 수준의 예제 데이터로도 미세조정 가능
		    - Bedrock의 파인튜닝 기능은 데이터의 양에 관계없이 높은 유연성을 보이는데, 특히 최소 20개 정도의 적은 예제만으로도 모델의 응답 스타일이나 특정 작업 수행 능력을 개선할 수 있다
	    - 최소 100개 이상 추천
		    - 복잡한 지식의 주입이나 정교한 성능 향상을 위해서는 작업의 복잡도에 따라 최소 100개 이상의 샘플을 사용하는 것이 권장된다
- **데이터 보안**
    - 사용자의 데이터는 해당 사용자 전용 모델 사본에서만 사용됨
	    - 즉, 사용자가 파인튜닝을 위해 제공한 데이터는 해당 사용자의 계정에 생성된 모델의 독점적인 복사본을 훈련하는 데만 사용
	    - 고객의 데이터는 파운데이션 모델의 기본 가중치를 업데이트하는 일반 학습 데이터로 절대 사용되지 않으며, 다른 고객이나 모델 제공업체에 공유되지 않는다
    - 데이터는 암호화되며 VPC 외부로 나가지 않음
	    - 데이터가 공용 인터넷을 통하지 않고 사설 네트워크 망 내부에서만 머무르도록 보장
	    - AWS Key Management Service(KMS)와의 통합을 통해 사용자가 직접 암호화 키를 생성하고 관리하며, 모델 커스터마이징 작업이나 세션 데이터를 암호화할 때 해당 키를 적용할 수 있
- Amazon SageMaker와 연동 가능

→ Bedrock은 **보안성과 관리 편의성을 유지하면서 생성형 AI 모델을 활용하기 위한 핵심 서비스**이다.

---

## Amazon CodeWhisperer (Overview)

Amazon CodeWhisperer는 **AWS에서 제공하는 AI 기반 코딩 보조 도구(AI coding companion)**이다.

- 지원 언어
    - Java, JavaScript, Python, TypeScript, C#
        
- 주요 기능
    - 실시간 코드 제안
    - 주석(Comment)으로 원하는 기능을 설명하면 코드 블록 자동 생성
        
- 학습 기반
    - 수십억 줄 규모의 코드로 학습된 대규모 언어 모델(LLM)
    - Amazon 내부 코드 + 오픈소스 코드 기반
        
#### 보안 및 코드 품질

- **보안 스캔 기능**
    - 코드 취약점 분석
    - Java, JavaScript, Python 지원
        
- **Reference Tracker**
    - 제안된 코드가 오픈소스 코드와 유사한 경우 이를 표시
    - 올바른 저작자 표기를 위한 주석(annotation) 제공
    
### Amazon CodeWhisperer (추가 기능 및 보안)

#### Bias avoidance (편향 방지)
- 편향되거나 불공정할 수 있는 코드 제안을 필터링

#### AWS 서비스 연동

- AWS API와 연동되는 코드 제안 가능
    
    - EC2
    - Lambda
    - S3

#### 보안

- 모든 전송 데이터는 TLS 사용
- 전송 중 암호화(Encrypted in transit)
- 저장 시 암호화(Encrypted at rest)
    
※ 단, **Individual 플랜의 경우 Amazon이 서비스 개선 목적으로 데이터를 분석(mine)할 수 있음**

### Amazon CodeWhisperer 요금 정책 (Pricing)

#### Individual Tier

- 무료 사용
- 월 최대 50회 보안 스캔 가능
    
#### Professional Tier

- 조직 단위 사용자 접근 관리 가능
- 조직 정책 관리
    - 예: 오픈소스 코드 사용 허용 여부
        
- IAM Identity Center로 인증
- 사용자당 월 최대 500회 보안 스캔
- 비용: **사용자당 월 $19**

### Amazon CodeWhisperer 지원 IDE

Amazon CodeWhisperer는 다양한 개발 환경에서 사용 가능하다.
- Visual Studio Code
- JetBrains 계열 IDE
    - IntelliJ
    - PyCharm
    - CLion
    - GoLand
    - WebStorm
    - PhpStorm
    - RubyMine
    - DataGrip
- JupyterLab
- SageMaker Studio
- AWS Lambda 콘솔
- AWS Cloud9
    
---