
- Amazon Sagemaker > Notebook instances > crate notebook instance
	- open notebook
	- upload - Transformers 관련 py 파일

Transformer - Bert
- hugging face - 사전 훈련된 모델의 대규모 저장소 의 패키지를 설치한다 (pip install)
	- transformer 모델들 많이 있음
	- free
- Tokenizers
	- transformers 패키지로부터 tokenizer 하기 위한 패키지를 import
		- BertModel, BertTokenizer
		- Bert는 only encoder로 만들어진 트랜스포머이다 (디코더로만 구현된 GPT와는 반대로)
		- `tokenized = tokoenizer("I read a good novel.")`
- Positional Encoding
	- 병렬적으로 처리
	- sin/cos 함수를 통해 메트릭 추출
- Self-Attention
	- BertModel, BertTokenizer 를 import 해서 가져온다
	- 시각화를 위해 show 패키지 import
	- ```
	  tokenizer_viz = BertTokenizer.from_pretrained(modelName)
	  model_viz = BertModel.from_pretrained(modelName)
	  show(model_viz, "bert", tokenizer_viz, "I read a good novel.", display_mode = "light", head=11)
	  ```
	  - ex3ERT 라는 사이트에서도 시각화 가능
		  - ![](images/Pasted%20image%2020251229000640.png)

GPT2 model (137M parameter)
 - hugging face에서 가져온 transformer 패키지(pipeline)를 통해 사전에 훈련된 모델들을 쉽게 가져올 수 있다.
 - pipeline을 통해 gpt2 모델 가져옴
 - generator 함수에 특정 문장을 넣고 실행 -> 글을 작성
	 - 어떤 영화인지 말을 해주지 않아도 매우 구체적인 글을 작성해준 것을 볼 수 있음
- "Star Trek" 이란 문장을 넣고 실행
	- 위키피디아의 정보를 준 것을 볼 수 있음.

---

## Foundation Model

- 방대한 데이터로 사전 학습(pre-trained)된 대규모 Transformer 기반 모델이며
- 특정 Task에 맞게 fine tuning 을 거치게 된다.
	- 수조 개의 토큰으로 구성된 방대한 데이터셋을 심층 신경망 아키텍처를 통해 학습한 결과물로, 언어 이해와 텍스트 및 이미지 생성을 포함한 광범위한 일반 작업을 수행할 수 있는 범용성을 핵심 가치로 한다.
	- 과거의 데이터 과학자들이 매번 특정 작업을 위해 기계 학습 모델을 처음부터 개발해야 했던 것과 달리, 파운데이션 모델은 이미 구축된 강력한 성능을 출발점으로 삼아 기업의 고유한 요구 사항에 맞춰 빠르고 비용 효율적으로 애플리케이션을 개발할 수 있도록 지원한다.
- ex) GPT-n (OpenAI, Microsoft): 범용 텍스트 생성 및 복잡한 추론
	- Bert (Google): 자연어 이해 및 검색 쿼리 분석
	- DALL-E (OpenAI, Microsoft): 텍스트 기반 창의적 이미지 생성
	- LLaMa (Meta): 고성능 오픈 웨이트 언어 모델
	- Segment Anything (Meta): 이미지 내 모든 객체에 대한 시각적 세분화

### AWS Foundation Models

![](images/Pasted%20image%2020251229002125.png)
AWS는 **Amazon Bedrock**를 중심으로 여러 외부 및 자체 Foundation Model을 제공한다.

Jurassic-2 (AI21 Labs)
- 다국어 대형 언어 모델(LLM)
- 텍스트 생성에 특화
- 지원 언어: 스페인어, 프랑스어, 독일어, 포르투갈어, 이탈리아어, 네덜란드어 등
    
Claude (Anthropic)
- 대화형 LLM
- 주요 기능
    - 자연스러운 대화
    - 질문 응답(Q&A)
    - 워크플로 자동화 지원
        
Stable Diffusion (Stability AI)
- 이미지 생성 모델
	- 텍스트 프롬프트를 통해 독창적인 예술 작품, 로고, 디자인 템플릿을 생성하는 데 특화
- 활용 분야
    - 이미지
    - 예술 작품
    - 로고
    - 디자인 생성
        
Amazon Titan (AWS 자체 모델)
- AWS에서 직접 제공하는 Foundation Model
	- AWS가 직접 개발한 모델 제품군으로, 기업 환경에서 요구되는 성능, 보안, 비용 효율성의 균형을 목표로 한다.
- 주요 기능
    - 텍스트 요약
    - 텍스트 생성
    - 질문 응답(Q&A)
    - 임베딩 생성
- 임베딩 활용 사례
    - 개인화 추천
    - 검색(Search)

### Amazon SageMaker JumpStart with Generative AI

#### SageMaker JumpStart란?

- SageMaker Studio에 내장된 기능
- 사전 구축된 모델과 예제 노트북을 **즉시 실행 가능**한 상태로 제공
- 사용자는 복잡한 환경 설정 없이 바로 실습 및 실험 가능
    
#### 제공 모델 유형

1. Hugging Face 모델 (텍스트 생성)
    - Falcon
    - FLAN
    - BloomZ
    - GPT-J
        
2. Stable Diffusion
    - 이미지 생성
        
3. Amazon Alexa 모델
    - Encoder/Decoder 기반
    - 다국어 LLM

즉, JumpStart는 **생성형 AI 모델을 빠르게 테스트하고, 학습·배포까지 연결할 수 있는 진입 지점** 역할을 한다.


---

## Amazon Bedrock

Amazon Bedrock은 **Foundation Model을 API 형태로 제공하는 AWS의 완전관리형(Serverless) 서비스**이다.

- Foundation Model을 직접 인프라 구성 없이 API로 사용 가능
- 서버리스 구조이므로 인프라 관리 불필요
	- 개발자는 인프라를 직접 구축하거나 운영할 필요 없이 모델의 추능 성능과 기능을 즉시 활용할 수 있으며, 이는 기업의 민첩성을 극대화하는 핵심 요소
- **Fine-tuning API 제공**
    - 사용자는 S3에 라벨링된 예제 데이터를 업로드하여 모델 미세조정 가능
	    - 최소 약 20개 수준의 예제 데이터로도 미세조정 가능
		    - Bedrock의 파인튜닝 기능은 데이터의 양에 관계없이 높은 유연성을 보이는데, 특히 최소 20개 정도의 적은 예제만으로도 모델의 응답 스타일이나 특정 작업 수행 능력을 개선할 수 있다
	    - 최소 100개 이상 추천
		    - 복잡한 지식의 주입이나 정교한 성능 향상을 위해서는 작업의 복잡도에 따라 최소 100개 이상의 샘플을 사용하는 것이 권장된다
- **데이터 보안**
    - 사용자의 데이터는 해당 사용자 전용 모델 사본에서만 사용됨
	    - 즉, 사용자가 파인튜닝을 위해 제공한 데이터는 해당 사용자의 계정에 생성된 모델의 독점적인 복사본을 훈련하는 데만 사용
	    - 고객의 데이터는 파운데이션 모델의 기본 가중치를 업데이트하는 일반 학습 데이터로 절대 사용되지 않으며, 다른 고객이나 모델 제공업체에 공유되지 않는다
    - 데이터는 암호화되며 VPC 외부로 나가지 않음
	    - 데이터가 공용 인터넷을 통하지 않고 사설 네트워크 망 내부에서만 머무르도록 보장
	    - AWS Key Management Service(KMS)와의 통합을 통해 사용자가 직접 암호화 키를 생성하고 관리하며, 모델 커스터마이징 작업이나 세션 데이터를 암호화할 때 해당 키를 적용할 수 있다.
- Amazon SageMaker와 연동 가능
	- 사용자는 SageMaker Studio Classic이나 SageMaker Notebook 인스턴스를 활용하여 Bedrock 모델을 호출하고 실험하는 코드를 작성할 수 있다.
	- Amazon SageMaker Unified Studio
		- Bedrock 모델을 검색하고 이를 활용한 생성형 AI 애플리케이션을 구축하는 과정이 더욱 단순화 되어있다.
	- SageMaker JumpStart를 통해 사용 가능한 모델과 Bedrock 모델을 상호 보완적으로 활용할 수 있다
		- 예를 들어, Bedrock을 통해 기초 모델을 API로 빠르게 적용하는 동시에, 보다 정교한 모델 제어나 인프라 커스터마이징이 필요한 워크로드는 SageMaker로 확장하는 하이브리드 전략이 가능하다.

→ Bedrock은 **보안성과 관리 편의성을 유지하면서 생성형 AI 모델을 활용하기 위한 핵심 서비스**이다.

---
### Bedrock API Endpoints

- Bedrock
	- **Bedrock API**는 Amazon Bedrock에서 사용하는 **관리(Management)용 API 엔드포인트**
	- Foundation Model 및 Bedrock 리소스의 **관리·배포·학습**을 담당
	- 주요 역할
	    - 모델 목록 조회
	    - 모델 설정 관리
	    - 미세조정(Fine-tuning) 작업 관리
	    - 에이전트 및 지식 기반 생성 전 단계 설정
	- 실제 추론(inference)은 수행하지 않음
		→ **제어 플레인(Control Plane)** 역할
- bedrock-runtime
	- **Bedrock Runtime API**는 **모델 추론(Inference)** 을 수행하기 위한 엔드포인트
	- 사전 학습되었거나 미세조정된 Foundation Model을 호출하여 결과 생성
	- 주요 추론 메서드
		- converse
			- 대화형 LLM과의 멀티턴 대화 수행
		- converseStream
			- 대화 결과를 스트리밍 방식으로 실시간 수신
		- invokeModel
			- 단일 요청 기반 텍스트 생성, 요약, Q&A 등 수행
	- → **데이터 플레인(Data Plane)** 역할
- bedrock-agent
	- **Bedrock Agent API**는 **LLM Agent 및 Knowledge Base를 관리**하기 위한 엔드포인트
	- LLM Agent의 **생성, 배포, 학습, 구성 관리**
	- Knowledge Base(지식 기반) 관리
		- 데이터 소스 연결
		- 검색 설정
	- Agent의 동작 흐름(오케스트레이션) 정의
	- → 에이전트 및 지식 기반에 대한 **관리 및 설정 전용 API**
- bedrock-agent-runtime
	- **Bedrock Agent Runtime API**는 **에이전트 및 지식 기반을 활용한 추론**을 수행
	- Agent를 호출하여 복합 작업 수행
	- Knowledge Base 기반 검색 + 생성(RAG) 지원
	- 주요 메서드
		- invokeAgent
			- Agent를 호출하여 작업 실행
		- retrieve
			- Knowledge Base에서 관련 정보 검색
		- retrieveAndGenerate
			- Knowledge Base에서 정보 검색 후
			- 검색 결과를 기반으로 LLM이 응답 생성 (RAG 패턴)
	- → **Agent 및 Knowledge Base 전용 추론 API**

---
#### Bedrock IAM permission

- IAM user 로 사용해야한다. (not root)
- 충분한 권한을 가져야한다.
	- AmazonBedrockFullAccess
	- AmazonBedrockReadOnly

#### Bedrock: Model Access

- base model 사용 전에, 먼저 요청해야한다.
- Amazon Titan model은 즉시 승인 가능
- Third-party model은 추가 정보 제출이 필요
	- AWS를 통해 비용 청구
	- 승인까지 2분 정도 소요


---

## Amazon CodeWhisperer (Overview)

- Amazon CodeWhisperer는 **AWS에서 제공하는 AI 기반 코딩 보조 도구(AI coding companion)** 이다.
- Amazon Q Developer라는 광범위한 AI 어시스턴트 서비스로 통합됨.

- 지원 언어
    - Java, JavaScript, Python, TypeScript, C#
    - 15개 이상의 프로그래밍 언어 지원
        
- 주요 기능
    - 실시간 코드 제안
    - 주석(Comment)으로 원하는 기능을 설명하면 코드 블록 자동 생성
        
- 학습 기반
    - 수십억 줄 규모의 코드로 학습된 대규모 언어 모델(LLM) 기반
    - Amazon 내부 코드 + 오픈소스 코드 기반
        
#### 보안 및 코드 품질

- **보안 스캔 기능**
    - 코드 취약점 분석
	    -  IDE 내부에서 직접 실행되는 실시간 보안 스캔 기능
	    - Java, JavaScript, Python과 같은 언어에서 하드코딩된 자격 증명(Credentials), SQL 인젝션 공격 위험, 로그 인젝션 등 보안에 위협이 되는 요소를 탐지
	    - 스캔 결과는 IDE의 '문제(Problems)' 패널에 표시되며, 각 취약점에 대해 왜 이것이 위협이 되는지, 그리고 어떤 방식으로 코드를 수정해야 하는지에 대한 구체적인 권장 사항을 포함한다.
    - Java, JavaScript, Python 지원
        
- **Reference Tracker** 오픈 소스 참조 추적기
    - 제안된 코드가 오픈소스 코드와 유사한 경우 이를 표시
    - 올바른 저작자 표기를 위한 주석(annotation) 제공

---

### Amazon CodeWhisperer (추가 기능 및 보안)

Amazon CodeWhisperer는 AI 모델이 가질 수 있는 편향성을 최소화하고, AWS 서비스와의 긴밀한 통합을 통해 최적화된 개발 경험을 제공하는 동시에, 엔터프라이즈급 보안 표준을 준수하도록 설계되었다.

#### Bias avoidance (편향 방지)

- 편향되거나 불공정할 수 있는 코드 제안을 필터링
	- 모델의 응답을 실시간으로 평가하여 부적절하거나 불공정한 스테레오타입을 포함할 가능성이 있는 코드 제안을 사전에 차단한다

#### AWS 서비스 연동

- AWS API와 연동되는 코드 제안 가능
    - Amazon EC2, AWS Lambda, Amazon S3와 같은 핵심 AWS 서비스의 API를 호출하는 코드를 작성할 때, 서비스의 모범 사례를 따르는 최적의 코드 스니펫을 제안한다.
    - 개발자가 방대한 AWS 공식 문서를 일일이 찾아보지 않고도 정확한 파라미터와 메서드를 사용하여 클라우드 인프라와 상호작용하는 코드를 신속하게 작성할 수 있게 해준다

#### 데이터 암호화 및 전송 보안

- 모든 전송 데이터는 TLS 사용
- 전송 중 암호화(Encrypted in transit)
- 저장 시 암호화(Encrypted at rest)
  
※ 단, 서비스 이용 티어에 따라 데이터 활용 정책이 달라질 수 있다는 점을 유의해야 한다.
- Individual 플랜의 경우 Amazon이 서비스 개선 및 모델 성능 향상 목적으로 사용자의 데이터나 상호작용 내역을 분석(mine)할 수 있는 권한을 가진다.
- 사용자가 IDE 설정을 통해 거부할 수 있으나, 완전한 데이터 격리가 필요한 기업의 경우에는 전문가용 티어(Professional Tier)를 사용하는 것이 권장된다.

---
### Amazon CodeWhisperer 요금 정책 (Pricing)

#### Individual Tier 개인용 티어
- 무료 사용
- 월 최대 50회 보안 스캔 가능
    
#### Professional Tier
- 조직 단위 사용자 접근 관리 가능
	- AWS IAM Identity Center(기존 AWS SSO)와 통합하여 어떤 개발자가 서비스에 접근할 수 있는지 제어 가능
- 조직 정책 관리
    - 오픈 소스 참조 코드를 포함하는 제안을 허용할지 여부 등 전사적인 서비스 이용 가이드라인을 설정하고 강제할 수 있다
- **확장된 보안 스캔:**
	- 사용자당 월 최대 500회 보안 스캔
- **데이터 주권 보장:** 
	- 전문가용 티어에서 처리되는 모든 소스 코드와 콘텐츠는 Amazon의 서비스 개선이나 모델 훈련에 절대 사용되지 않으며, 기업의 독점적인 자산으로 철저히 보호된다
- **지적 재산권 배상(IP Indemnity):** 
	- 생성된 코드로 인해 발생할 수 있는 저작권 문제에 대해 법적인 보호를 제공하여 기업의 리스크를 완화한다
- 비용: 
	- 월별 최대 활성 사용자 수를 기준으로 청구되며, 첫 달은 남은 일수에 따라 일할 계산(Prorating)된다.
	- **사용자당 월 $19**

---
### Amazon CodeWhisperer 지원 IDE

Amazon CodeWhisperer는 다양한 개발 환경에서 사용 가능하다.
- Visual Studio Code
- JetBrains 계열 IDE
    - IntelliJ
    - PyCharm
    - CLion
    - GoLand
    - WebStorm
    - PhpStorm
    - RubyMine
    - DataGrip
- JupyterLab
- SageMaker Studio
- AWS Lambda 콘솔
- AWS Cloud9
    
---

### AWS HealthScribe

**AWS HealthScribe**는 의료 상담 과정에서 생성되는 **음성 녹취를 임상 기록(Clinical Notes)** 으로 자동 변환하기 위해 설계된 AWS 서비스이다
- 의사가 환자와 상담하면서 동시에 메모를 작성해야 하는 부담을 줄이고, 진료에 더 집중할 수 있도록 지원하는 것이 목적이다.

- 임상 노트 자동 생성 Generates clinical notes
	- 생성되는 노트는 **Preliminary Notes**
	    - 최종 진료 기록이 아닌
	    - 의사가 검토 및 수정하는 것을 전제로 한 초안 형태
- HIPAA 규정 준수 HIPAA-Compliant
	- 의료 정보 보호를 위한 보안 및 개인정보 처리 기준 충족
	- 의료 데이터 처리에 적합한 AWS 보안 아키텍처 적용
- 의료 특화 LLM 기반
	- 의료 용어에 최적화된 LLM 사용
	- 일반 언어 모델과 달리
	    - 질병명
	    - 증상
	    - 약물명
	    - 임상 표현 을 정확하게 인식하도록 튜닝됨
	    - → 의료 상담 맥락에 맞는 정확한 기록 생성 가능
- 원본 녹취와의 연계 (References)
	- 생성된 임상 노트의 각 내용은 **원본 녹취(transcript)** 와 연결된 참조 정보를 제공
	- 의사는 노트의 근거가 되는 실제 발언을 쉽게 확인 가능
- 불필요한 대화 자동 제거 
	- small talk 제거
	- 침묵 제거
	- 임상적으로 의미 있는 내용 중심으로 요약·정리
- 데이터 저장 정책
	- 환자 음성 녹취 및 생성된 임상 노트는
	    - **기본적으로 AWS 클라우드에 저장되지 않음**
	- 사용자가 명시적으로 저장 설정을 하지 않는 한
	    - 데이터는 세션 처리 후 보존되지 않음
	- → 데이터 주권 및 개인정보 보호 강화
