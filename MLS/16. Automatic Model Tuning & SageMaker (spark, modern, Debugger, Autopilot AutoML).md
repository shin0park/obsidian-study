## Automatic Model Tuning (자동 모델 튜닝)

개요
- 여러 하이퍼파라미터(learning rate, batch size 등)의 조합을 자동으로 탐색하여 최적 모델 구성
	- 사용자는 최적화할 하이퍼파라미터, 시도할 범위(ranges), 그리고 최적화 목표 메트릭을 정의한다.
	- SageMaker는 이 정의를 기반으로 **Hyperparameter Tuning Job**을 생성하여 여러 조합을 병렬 학습 후 최적값을 자동 선택
	- 이 과정에서 훈련에 필요한 인스턴스들이 필요에 따라 생성된다.
	- AMT는 최적화를 진행하면서 이전 시도 결과를 학습하고 이를 활용하여 다음 최적의 파라미터를 탐색하는 지능적인 검색 전략(예: 베이지안 최적화, Multi-fidelity 최적화)을 사용한다. 
		- Bayesian Optimization: 베이지안 최적화
			- “모든 경우를 다 실험하지 않고, 똑똑하게 예측하며 탐색하자.”
			- 모델이 하이퍼파라미터 조합(예: learning rate, batch size 등)을 시도할 때마다  그 결과(정확도, 손실 등)를 기억해두고,  그걸 바탕으로 “다음엔 어디를 실험하면 좋을까?”를 **통계적으로 예측**한다.
			- 이렇게 하여, **적은 시도로도 좋은 조합을 빠르게** 찾는다.
			- 데이터셋이 **작거나(100MB 이하)**, 실험 비용이 큰 경우에 유리
		- Multi-fidelity Optimization: 멀티 피델리티 최적화
			- 시간이 많이 걸리는 실험을 다 끝까지 돌리지 말고, 가망 없는 후보는 중간에 미리 걸러내자.”
			- 하이퍼파라미터 조합이 여러 개 있을 때,  처음에는 **적은 데이터나 짧은 학습(epoch)** 으로 빠르게 시험한다.
			- 성능이 나쁜 조합은 **조기 종료(Early Stopping)** 시켜 자원 낭비를 막고, 가능성 있는 조합만 더 길게 학습시킨다.
			- **대규모 데이터셋(100MB 이상)** 에서 유리. 학습 시간 단축 및 리소스 절약 효과 큼.
	- 따라서 모든 가능한 조합을 시도하지 않고도 최적의 조합을 빠르게 찾을 수 있어 시간과 컴퓨팅 비용 효율성을 높인다.
    
#### 모범 사례 (Best Practices)

- **최적화 수 제한:** 한 번에 너무 많은 하이퍼파라미터를 동시에 최적화하지 않아야 한다.
- **탐색 범위 설정:** 탐색 범위를 가능한 한 좁게 제한하여 검색 공간을 줄인다.
- **로그 스케일 적용:** 하이퍼파라미터의 범위가 넓을 경우 로그 스케일(logarithmic scales)을 사용하는 것이 적절하다. (linear하게 일정한 간격으로 값 증가하는 것이 아닌 값이 로그 값으로 지수적 간격으로 증가하는것)
- **병렬 작업 관리:** 동시 학습(job) 수를 과도하게 늘리지 않기, 학습하는 능력을 제한할 수 있음
- **메트릭 정합성:** 다중 인스턴스에서 실행되는 훈련 작업의 경우, 최종적으로 정확한 목표 메트릭이 올바르게 보고되는지 확인해야 한다.

---

## SageMaker & Spark 통합

주요 개념

- SageMaker와 Apache Spark의 통합은 빅데이터 처리 능력(Spark)과 고성능 ML 훈련 및 추론(SageMaker)을 결합하여 대규모 ML 파이프라인을 구축하는 방법을 제공한다.
- Spark로 **데이터 전처리 및 DataFrame 생성** 후,  
    `sagemaker-spark` 라이브러리로 SageMaker 모델과 통합
- `sagemaker-spark` 라이브러리
	- **SageMakerEstimator**: KMeans, PCA, XGBoost 등 학습
	- **SageMakerModel**: 훈련된 모델로 예측 수행
	- 와 같은 핵심 클래스 제공하여 SageMaker 기능을 Spark 워크플로우 내에서 호출할 수 있게 한다.
- 개발 환경: SparkMagic (PySpark) 커널을 사용하는 노트북을 통해 구성하거나, 원격 EMR(Elastic MapReduce) 클러스터에 연결하여 사용할 수 있다. 
	- Amazon EMR은 `aws-sagemaker-spark-sdk` 구성 요소를 통해 SageMaker Spark와의 통합을 지원한다.

Spark 데이터프레임 요구사항 및 Estimator/Model 활용

- ![](images/Pasted%20image%2020251013224050.png)
- SageMaker Estimator를 통해 훈련을 시작하려면, Spark 훈련 데이터프레임은 특정 구조를 따라야 한다. 데이터프레임은 특징 데이터를 담고 있는 **특징(features) 열**과 선택적인 **레이블(labels) 열** 을 포함해야 한다.  
	- 사용자는 정의된 `SageMakerEstimator`에서 `fit` 메서드를 호출하여 SageMaker 클라우드 인프라에서 모델 훈련을 실행하고, 결과로 **`SageMakerModel`** 객체를 얻는다. 
	- 훈련이 완료된 후, 이 `SageMakerModel` 객체에 대해 `transform` 메서드를 호출함으로써 새로운 Spark 데이터프레임에 대한 추론을 실행할 수 있으며, 이 모든 과정은 Spark Pipelines와도 원활하게 연동된다.

이점

- Spark의 대용량 데이터 처리와 SageMaker의 ML 기능을 결합
- EMR + SageMaker 간 통합으로 대규모 ML 파이프라인 구현 가능
    

---

## Modern SageMaker (SageMaker Studio 시대)

#### SageMaker Studio

- ![](images/Pasted%20image%2020251013224622.png)
- MLOps 수명 주기 전반을 아우르는 시각적 통합 개발 환경(IDE)을 제공하며, 다양한 고급 기능을 통해 ML 작업의 효율성, 안정성, 책임성을 향상시킨다
- 모델 학습·튜닝·디버깅·배포까지 관리 가능
    
#### SageMaker Notebooks

- ![600](images/Pasted%20image%2020251013224636.png)
- 사용자는 Studio 내에서 Jupyter 노트북을 생성하고 공유할 수 있으며, 인프라를 직접 관리할 필요 없이 하드웨어 구성을 쉽게 전환할 수 있다
    
#### SageMaker Experiments: ML 작업의 조직화 및 비교 관리

- ![](images/Pasted%20image%2020251013224653.png)
- **SageMaker Experiments**는 반복적인 ML 훈련 작업(jobs)을 체계적으로 관리하고 재현성을 보장하는 데 중점을 둔다. 
- 이 기능은 수많은 ML 실험의 메트릭, 파라미터, 아티팩트 등을 **조직화, 캡처, 비교, 검색**하는 기능을 제공한다. 
- 이는 복잡한 ML 실험 과정에서 모델 거버넌스를 확립하고, 어떤 조건에서 최상의 성능이 달성되었는지 쉽게 추적할 수 있도록 지원한다


### SageMaker Debugger

- Debugger는 훈련 중 주기적인 간격으로 그래디언트(Gradients) 및 텐서(Tensors)와 같은 **내부 모델 상태**를 저장 및 시각화한다.
- 사용자는 이 정보를 바탕으로 훈련 중 모델 발산이나 기타 원치 않는 조건을 감지하기 위한 **규칙(rules)**을 정의할 수 있다. -> 오류 탐지 규칙(rule) 
	- 규칙이 감지되면 디버그 작업이 실행되고 CloudWatch 이벤트가 발생한다.
- SageMaker Studio에서 **자동  디버깅 리포트** 및 대시보드 제공
    

지원 프레임워크 & 알고리즘
- TensorFlow, PyTorch, MXNet, XGBoost
- SageMaker generic estimator (사용자 정의 훈련 컨테이너 사용)
    
#### 최신 SageMaker Debugger Features

- **Debugger Insights Dashboard**
- **ProfilerRule**, **ProfilerReport**
	- Debugger의 기능은 **ProfilerRule**을 통해 확장된다. 
	- ProfilerRule은 훈련 작업의 하드웨어 시스템 리소스 활용도 및 프레임워크 메트릭을 분석하여 성능 병목 현상을 자동으로 식별한다. 
	- 예를 들어, CPU 병목 현상으로 인해 GPU 활용이 저하되는 상황을 감지할 수 있다.
	- 하드웨어/프레임워크 메트릭 수집 (CPU/GPU 병목 등)
		- Hardware system metrics (CPUBottlenck, GPUMemoryIncrease, etc)
		- Framework Metrics (MaxInitializationTime, OverallFrameworkMetrics, StepOutlier)

- 규칙 기반 자동 조치: `StopTraining()`, `Email()`, `SNS 알림` 등
	- Debugger 규칙이 트리거될 경우, 사용자의 개입 없이 자동으로 취할 수 있는 내장된 조치(actions)가 제공된다.
	- StopTraining: 모델 발산이나 비정상적인 지연이 발생할 때 훈련을 즉시 중지시켜 클라우드 컴퓨팅 비용 낭비를 막는다.
	- Email, SMS와 같은 알림: SNS(Simple Notification Service)를 통해 전송하도록 구성가능
    

---

## SageMaker Autopilot (AutoML)

개요
- 알고리즘 선택, 데이터 전처리, 모델 튜닝 및 모든 인프라 관리를 자동화하여 ML 개발을 가속화한다.
- AutoML의 AWS 구현체
    
워크플로우

1. S3에서 학습 데이터 로드
2. 예측 대상 열(Target Column) 선택
3. 자동 모델 생성 
4. 모델 Notebook 생성 (보고 컨트롤 할 수 있음)
5. 결과 리더보드(Model Leaderboard) 제공 - ranked 추천 모델 리스트
6. 사용자 최적 성능 모델 선택 → 배포 및 모니터링
    

지원되는 문제 유형 및 알고리즘

- **문제 유형:** 이진 분류, 다중 클래스 분류, 회귀
- **알고리즘 유형:** Linear Learner, XGBoost, 딥러닝(MLP), 앙상블 모드
- **데이터 요구 사항:** 입력 데이터는 반드시 테이블 형식의 **CSV 또는 Parquet (테이블 형태)**

### Autopilot Training Modes

Autopilot은 데이터 세트 크기를 기반으로 최적화 전략을 자동으로 선택한다

- HPO (Hyperparameter Optimization) 모드
	- 주로 100MB를 초과하는 대규모 데이터 세트에 사용
	- 최적의 하이퍼파라미터 범위를 선택하고, 최대 100회의 시도를 통해 최적 파라미터를 찾는다.
	- 100MB 초과 시에는 Multi-fidelity 최적화를, 미만 시에는 베이지안 최적화를 사용하며, 성능이 저조한 시도는 조기 중단(Early stopping)된다.
- Ensembling (앙상블) 모드
	- 주로 100MB 미만의 소규모 데이터 세트에 사용된다. 
	- AutoGluon 라이브러리를 사용하여 여러 기본 모델(트리 기반, 신경망)을 훈련시키고 스태킹 앙상블 방식으로 결합한다. - 여러 모델(트리, NN 등)을 결합한 스태킹 앙상블
- Auto 모드
	- 데이터 크기에 따라 HPO 또는 Ensembling 모드를 자동으로 선택

### Autopilot Explainability 설명 가능성

- SageMaker **Clarify** 통합: 모델 예측의 투명성 제공
- 각 feature가 얼마나 중요한 기여했는지 알 수 있음
- 이 기능은 협력 게임 이론(cooperative game theory)에서 파생된 **SHAP Baselines / Shapley Values**를 활용하여 **특징 기여도(Feature attribution)** 를 분석한다. 
- Shapley Values는 특정 예측에 대해 각 입력 특징이 얼마나 중요한 기여를 했는지 정량적인 중요도 값을 할당하여 모델의 행동을 설명하는 데 도움을 준다
- **특성 중요도(Feature Attribution)** 분석:
    - SHAP/샤플리 값 기반 → 각 특성이 예측에 미치는 영향 수치화
        

---

## SageMaker Model Monitor

- Model Monitor는 배포된 모델의 품질 편차를 감지하고 CloudWatch를 통해 알림을 보낸다.
- data drift를 시각화 할 수 있다.
	- data drift: 모델 변화 훈련에 사용하는 데이터
	- 데이터에서 발생한 이상현상이나 이상치 감지 가능
- 코드 필요 없음 (웹 기반 대시보드로 설정 가능)

    
#### SageMaker Model Monitor + Clarify

- Clarify는 잠재적 편견(bias)를 감지한다.
- 모델 모니터는 배포된 모델에서 새로운 bias가 발생할떄 명확하게 알려주는 역할을 한다.
- 즉, 새로운 잠재적 편향에 대한 알림을 받을 수 있다.  
- **모델 행동 설명:** SageMaker Clarify는 모델 행동을 설명하는 데도 도움을 준다.
- **특징 기여도:** 어떤 특징이 예측에 가장 많이 기여했는지 파악할 수 있다.

#### Clarify의 사전 훈련 편향 메트릭

Clarify는 훈련 데이터 세트의 편향을 측정하기 위해 다양한 사전 훈련(Pre-training) 메트릭을 사용한다   

|메트릭 (Metric)|약어 (Acronym)|측정 내용 (Measurement)|
|---|---|---|
|Class Imbalance|CI|한 그룹(Facet)이 다른 그룹보다 더 적은 훈련 샘플 값을 가지는 정도|
|Difference in Proportions of Labels|DPL|그룹 값 간 긍정적 결과(Positive Outcomes)의 불균형|
|Kullback-Leibler Divergence|KL|그룹 간 결과 분포가 얼마나 발산하는지|
|Jensen-Shannon Divergence|JS|그룹 간 결과 분포의 다이버전스 정도|
|Lp-norm|LP|그룹 값 간 결과 분포의 P-노름 차이|
|Total Variation Distance|TVD|그룹 값 간 결과 분포의 L1-노름 차이|
|Kolmogorov-Smirnov|KS|그룹 값 간 결과 분포의 최대 발산 정도|
|Conditional Demographic Disparity|CDD|전체로서의 그룹 간, 그리고 하위 그룹별로 측정되는 결과의 격차|

#### SageMaker Model Monitor (작업 흐름 및 통합)

- 모니터링 데이터는 S3에 안전하게 저장된다
- **모니터링 스케줄(Monitoring Schedule)** 을 통해 모니터링 작업이 스케줄링된다.
- **메트릭 전송:** 측정된 메트릭은 CloudWatch로 전송된다. -> CloudWatch 알림
- **교정 조치:** 경보가 발생하면 모델 재훈련(retrain) 또는 데이터 감사(audit)와 같은 교정 조치를 취해야 한다.
- **시각화 통합:** TensorBoard, QuickSight, Tableau와 통합 가능
	- SageMaker Studio 내 시각화 지원


#### Monitoring 유형

- **데이터 품질 드리프트 (Drift in data quality):** 
	- 통계적 특징 변화 감지 - 여기서 "품질"은 특징(features)의 통계적 속성을 의미
	- 훈련 시 생성된 **기준선(baseline)** 대비 라이브 데이터의 통계적 속성 변화를 감지한다.
- **모델 품질 드리프트 (Drift in model quality) (예: 정확도):**
	- 정확도/성능 저하 탐지
	- 정확도(accuracy) 등 모델 품질 기준선과 비교하여 작동하며, Ground Truth 레이블과 통합될 수 있다.
- **편향 드리프트 (Bias drift)**:
	- 그룹 간 불균형 변화
- **특징 기여도 드리프트 (Feature attribution drift)**:
	- Normalized Discounted Cumulative Gain (NDCG) 점수를 기반으로 하며, 훈련 데이터와 라이브 데이터의 특징 순위(feature ranking)를 비교

---

## Deployment Safeguards (배포 안전장치)

- SageMaker는 비동기식(asynchronous) 또는 실시간 추론 엔드포인트에 대한 배포 위험을 통제하기 위한 안전 장치(Deployment Guardrails)를 제공한다.
- **배포 가드레일 (Deployment Guardrails):** 새로운 모델로 트래픽을 전환하는 것을 제어
- 실시간 및 비동기 추론 엔드포인트에서 **배포 트래픽 제어**:
    - **Blue/Green**: 모든 트래픽을 한 번에 전환하고 모니터링한 후 기존 플릿(Blue fleet)을 종료
    - **Canary**: 일부 트래픽만 새 모델로 전환
    - **Linear**: 일정 간격으로 점진적 전환
        
- **자동 롤백(Auto-Rollback)** 및 **Shadow Testing** 지원 → 새 모델을 실서비스 전 모니터링 후 승격 가능
- **승격 결정:** 사용자는 SageMaker 콘솔에서 섀도 변형을 모니터링하고, 안전성이 검증되면 언제 프로덕션으로 승격(promote)할지 결정
    

