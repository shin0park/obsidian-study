## Automatic Model Tuning (자동 모델 튜닝)

개요
- 여러 하이퍼파라미터(learning rate, batch size 등)의 조합을 자동으로 탐색하여 최적 모델 구성
	- 사용자는 최적화할 하이퍼파라미터, 시도할 범위(ranges), 그리고 최적화 목표 메트릭을 정의한다.
	- SageMaker는 이 정의를 기반으로 **Hyperparameter Tuning Job**을 생성하여 여러 조합을 병렬 학습 후 최적값을 자동 선택
	- 이 과정에서 훈련에 필요한 인스턴스들이 필요에 따라 생성된다.
	- AMT는 최적화를 진행하면서 이전 시도 결과를 학습하고 이를 활용하여 다음 최적의 파라미터를 탐색하는 지능적인 검색 전략(예: 베이지안 최적화, Multi-fidelity 최적화)을 사용한다. 
		- Bayesian Optimization: 베이지안 최적화
			- “모든 경우를 다 실험하지 않고, 똑똑하게 예측하며 탐색하자.”
			- 모델이 하이퍼파라미터 조합(예: learning rate, batch size 등)을 시도할 때마다  그 결과(정확도, 손실 등)를 기억해두고,  그걸 바탕으로 “다음엔 어디를 실험하면 좋을까?”를 **통계적으로 예측**한다.
			- 이렇게 하여, **적은 시도로도 좋은 조합을 빠르게** 찾는다.
			- 데이터셋이 **작거나(100MB 이하)**, 실험 비용이 큰 경우에 유리
		- Multi-fidelity Optimization: 멀티 피델리티 최적화
			- 시간이 많이 걸리는 실험을 다 끝까지 돌리지 말고, 가망 없는 후보는 중간에 미리 걸러내자.”
			- 하이퍼파라미터 조합이 여러 개 있을 때,  처음에는 **적은 데이터나 짧은 학습(epoch)** 으로 빠르게 시험한다.
			- 성능이 나쁜 조합은 **조기 종료(Early Stopping)** 시켜 자원 낭비를 막고, 가능성 있는 조합만 더 길게 학습시킨다.
			- **대규모 데이터셋(100MB 이상)** 에서 유리. 학습 시간 단축 및 리소스 절약 효과 큼.
	- 따라서 모든 가능한 조합을 시도하지 않고도 최적의 조합을 빠르게 찾을 수 있어 시간과 컴퓨팅 비용 효율성을 높인다.
    
#### 모범 사례 (Best Practices)

- **최적화 수 제한:** 한 번에 너무 많은 하이퍼파라미터를 동시에 최적화하지 않아야 한다.
- **탐색 범위 설정:** 탐색 범위를 가능한 한 좁게 제한하여 검색 공간을 줄인다.
- **로그 스케일 적용:** 하이퍼파라미터의 범위가 넓을 경우 로그 스케일(logarithmic scales)을 사용하는 것이 적절하다. (linear하게 일정한 간격으로 값 증가하는 것이 아닌 값이 로그 값으로 지수적 간격으로 증가하는것)
- **병렬 작업 관리:** 동시 학습(job) 수를 과도하게 늘리지 않기, 학습하는 능력을 제한할 수 있음
- **메트릭 정합성:** 다중 인스턴스에서 실행되는 훈련 작업의 경우, 최종적으로 정확한 목표 메트릭이 올바르게 보고되는지 확인해야 한다.

---

## SageMaker & Spark 통합

주요 개념

- SageMaker와 Apache Spark의 통합은 빅데이터 처리 능력(Spark)과 고성능 ML 훈련 및 추론(SageMaker)을 결합하여 대규모 ML 파이프라인을 구축하는 방법을 제공한다.
- Spark로 **데이터 전처리 및 DataFrame 생성** 후,  
    `sagemaker-spark` 라이브러리로 SageMaker 모델과 통합
- `sagemaker-spark` 라이브러리
	- **SageMakerEstimator**: KMeans, PCA, XGBoost 등 학습
	- **SageMakerModel**: 훈련된 모델로 예측 수행
	- 와 같은 핵심 클래스 제공하여 SageMaker 기능을 Spark 워크플로우 내에서 호출할 수 있게 한다.
- 개발 환경: SparkMagic (PySpark) 커널을 사용하는 노트북을 통해 구성하거나, 원격 EMR(Elastic MapReduce) 클러스터에 연결하여 사용할 수 있다. 
	- Amazon EMR은 `aws-sagemaker-spark-sdk` 구성 요소를 통해 SageMaker Spark와의 통합을 지원한다.

Spark 데이터프레임 요구사항 및 Estimator/Model 활용

- ![](images/Pasted%20image%2020251013224050.png)
- SageMaker Estimator를 통해 훈련을 시작하려면, Spark 훈련 데이터프레임은 특정 구조를 따라야 한다. 데이터프레임은 특징 데이터를 담고 있는 **특징(features) 열**과 선택적인 **레이블(labels) 열** 을 포함해야 한다.  
	- 사용자는 정의된 `SageMakerEstimator`에서 `fit` 메서드를 호출하여 SageMaker 클라우드 인프라에서 모델 훈련을 실행하고, 결과로 **`SageMakerModel`** 객체를 얻는다. 
	- 훈련이 완료된 후, 이 `SageMakerModel` 객체에 대해 `transform` 메서드를 호출함으로써 새로운 Spark 데이터프레임에 대한 추론을 실행할 수 있으며, 이 모든 과정은 Spark Pipelines와도 원활하게 연동된다.

이점

- Spark의 대용량 데이터 처리와 SageMaker의 ML 기능을 결합
- EMR + SageMaker 간 통합으로 대규모 ML 파이프라인 구현 가능
    

---

## Modern SageMaker (SageMaker Studio 시대)

#### SageMaker Studio

- ![](images/Pasted%20image%2020251013224622.png)
- MLOps 수명 주기 전반을 아우르는 시각적 통합 개발 환경(IDE)을 제공하며, 다양한 고급 기능을 통해 ML 작업의 효율성, 안정성, 책임성을 향상시킨다
- 모델 학습·튜닝·디버깅·배포까지 관리 가능
    
#### SageMaker Notebooks

- ![600](images/Pasted%20image%2020251013224636.png)
- 사용자는 Studio 내에서 Jupyter 노트북을 생성하고 공유할 수 있으며, 인프라를 직접 관리할 필요 없이 하드웨어 구성을 쉽게 전환할 수 있다
    
#### SageMaker Experiments: ML 작업의 조직화 및 비교 관리

- ![](images/Pasted%20image%2020251013224653.png)
- **SageMaker Experiments**는 반복적인 ML 훈련 작업(jobs)을 체계적으로 관리하고 재현성을 보장하는 데 중점을 둔다. 
- 이 기능은 수많은 ML 실험의 메트릭, 파라미터, 아티팩트 등을 **조직화, 캡처, 비교, 검색**하는 기능을 제공한다. 
- 이는 복잡한 ML 실험 과정에서 모델 거버넌스를 확립하고, 어떤 조건에서 최상의 성능이 달성되었는지 쉽게 추적할 수 있도록 지원한다


### SageMaker Debugger

- Debugger는 훈련 중 주기적인 간격으로 그래디언트(Gradients) 및 텐서(Tensors)와 같은 **내부 모델 상태**를 저장 및 시각화한다.
- 사용자는 이 정보를 바탕으로 훈련 중 모델 발산이나 기타 원치 않는 조건을 감지하기 위한 **규칙(rules)**을 정의할 수 있다. -> 오류 탐지 규칙(rule) 
	- 규칙이 감지되면 디버그 작업이 실행되고 CloudWatch 이벤트가 발생한다.
- SageMaker Studio에서 **자동  디버깅 리포트** 및 대시보드 제공
    

지원 프레임워크 & 알고리즘
- TensorFlow, PyTorch, MXNet, XGBoost
- SageMaker generic estimator (사용자 정의 훈련 컨테이너 사용)
    
#### 최신 SageMaker Debugger Features

- **Debugger Insights Dashboard**
- **ProfilerRule**, **ProfilerReport**
	- Debugger의 기능은 **ProfilerRule**을 통해 확장된다. 
	- ProfilerRule은 훈련 작업의 하드웨어 시스템 리소스 활용도 및 프레임워크 메트릭을 분석하여 성능 병목 현상을 자동으로 식별한다. 
	- 예를 들어, CPU 병목 현상으로 인해 GPU 활용이 저하되는 상황을 감지할 수 있다.
	- 하드웨어/프레임워크 메트릭 수집 (CPU/GPU 병목 등)
		- Hardware system metrics (CPUBottlenck, GPUMemoryIncrease, etc)
		- Framework Metrics (MaxInitializationTime, OverallFrameworkMetrics, StepOutlier)

- 규칙 기반 자동 조치: `StopTraining()`, `Email()`, `SNS 알림` 등
	- Debugger 규칙이 트리거될 경우, 사용자의 개입 없이 자동으로 취할 수 있는 내장된 조치(actions)가 제공된다.
	- StopTraining: 모델 발산이나 비정상적인 지연이 발생할 때 훈련을 즉시 중지시켜 클라우드 컴퓨팅 비용 낭비를 막는다.
	- Email, SMS와 같은 알림: SNS(Simple Notification Service)를 통해 전송하도록 구성가능
    

---

## SageMaker Autopilot (AutoML)

개요
- 알고리즘 선택, 데이터 전처리, 모델 튜닝 및 모든 인프라 관리를 자동화하여 ML 개발을 가속화한다.
- AutoML의 AWS 구현체
    
워크플로우

1. S3에서 학습 데이터 로드
2. 예측 대상 열(Target Column) 선택
3. 자동 모델 생성 
4. 모델 Notebook 생성 (보고 컨트롤 할 수 있음)
5. 결과 리더보드(Model Leaderboard) 제공 - ranked 추천 모델 리스트
6. 사용자 최적 성능 모델 선택 → 배포 및 모니터링
    

지원되는 문제 유형 및 알고리즘

- **문제 유형:** 이진 분류, 다중 클래스 분류, 회귀
- **알고리즘 유형:** Linear Learner, XGBoost, 딥러닝(MLP), 앙상블 모드
- **데이터 요구 사항:** 입력 데이터는 반드시 테이블 형식의 **CSV 또는 Parquet (테이블 형태)**

### Autopilot Training Modes

Autopilot은 데이터 세트 크기를 기반으로 최적화 전략을 자동으로 선택한다

- HPO (Hyperparameter Optimization) 모드
	- 주로 100MB를 초과하는 대규모 데이터 세트에 사용
	- 최적의 하이퍼파라미터 범위를 선택하고, 최대 100회의 시도를 통해 최적 파라미터를 찾는다.
	- 100MB 초과 시에는 Multi-fidelity 최적화를, 미만 시에는 베이지안 최적화를 사용하며, 성능이 저조한 시도는 조기 중단(Early stopping)된다.
- Ensembling (앙상블) 모드
	- 주로 100MB 미만의 소규모 데이터 세트에 사용된다. 
	- AutoGluon 라이브러리를 사용하여 여러 기본 모델(트리 기반, 신경망)을 훈련시키고 스태킹 앙상블 방식으로 결합한다. - 여러 모델(트리, NN 등)을 결합한 스태킹 앙상블
- Auto 모드
	- 데이터 크기에 따라 HPO 또는 Ensembling 모드를 자동으로 선택

### Autopilot Explainability 설명 가능성

- SageMaker **Clarify** 통합: 모델 예측의 투명성 제공
- 각 =에 어떻게 다양한 feature에 기여했는지 알 수 있음
- 이 기능은 협력 게임 이론에서 파생된 **SHAP Baselines / Shapley Values**를 활용하여 **특징 기여도(Feature attribution)** 를 분석한다. 
- Shapley Values는 특정 예측에 대해 각 입력 특징이 얼마나 중요한 기여를 했는지 정량적인 중요도 값을 할당하여 모델의 행동을 설명하는 데 도움을 준다
- **특성 중요도(Feature Attribution)** 분석:
    - SHAP/샤플리 값 기반 → 각 특성이 예측에 미치는 영향 수치화
        

---

## SageMaker Model Monitor

- Model Monitor는 배포된 모델의 품질 편차를 감지하고 CloudWatch를 통해 알림을 보낸다.
- 모니터링 유형
	- **데이터 품질 드리프트:** 훈련 시 생성된 **기준선(baseline)** 대비 라이브 데이터의 통계적 속성 변화를 감지한다.
	- **모델 품질 드리프트(예: 정확도):** 모델 품질 기준선과 비교하여 드리프트를 감지하며, 필요에 따라 Ground Truth 레이블과 통합될 수 있다.
	- **이상치/새 특징 감지:** 입력 데이터의 이상치 및 훈련 시 없던 새로운 특징의 출현을 감지한다.

- SageMaker Studio 내 시각화 지원
- TensorBoard, QuickSight, Tableau와 통합 가능
    
#### Bias Metrics (Clarify 통합)

- Class Imbalance, DPL, KL Divergence, TVD, KS, CDD 등
- 사전훈련 데이터의 **편향도(bias)** 분석
    
#### Monitoring 유형

|유형|설명|
|---|---|
|데이터 품질 드리프트|통계적 특징 변화 감지|
|모델 품질 드리프트|정확도/성능 저하 탐지|
|편향 드리프트|그룹 간 불균형 변화|
|특성 중요도 드리프트|NDCG 기반 feature 순위 변화 감지|

- 모니터링 데이터는 S3에 안전하게 저장된다
- **모니터링 스케줄(Monitoring Schedule)** 을 통해 모니터링 작업이 스케줄링된다.

---

## Deployment Safeguards (배포 안전장치)

- 실시간 및 비동기 추론 엔드포인트에서 **배포 트래픽 제어**:
    - **Blue/Green**: 전체 전환 후 모니터링
    - **Canary**: 일부 트래픽만 새 모델로 전환
    - **Linear**: 일정 간격으로 점진적 전환.
        
- **자동 롤백(Auto-Rollback)** 및 **Shadow Testing** 지원 → 새 모델을 실서비스 전 모니터링 후 승격 가능
    

---