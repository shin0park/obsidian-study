## Automatic Model Tuning (자동 모델 튜닝)

개요
- 여러 하이퍼파라미터(learning rate, batch size 등)의 조합을 자동으로 탐색하여 최적 모델 구성
	- 사용자는 최적화할 하이퍼파라미터, 시도할 범위(ranges), 그리고 최적화 목표 메트릭을 정의한다.
	- SageMaker는 이 정의를 기반으로 **Hyperparameter Tuning Job**을 생성하여 여러 조합을 병렬 학습 후 최적값을 자동 선택
	- 이 과정에서 훈련에 필요한 인스턴스들이 필요에 따라 생성된다.
    
모범 사례 (Best Practices)
- 한 번에 너무 많은 하이퍼파라미터를 최적화하지 말 것
- 가능한 좁은 범위로 설정
- 필요 시 **로그 스케일(log scale)** 사용
- 동시 학습(job) 수를 과도하게 늘리지 않기
- 모든 인스턴스가 최종 성능 지표(metric)를 올바르게 보고하도록 설정
    

---

## SageMaker & Spark 통합

주요 개념

- Spark로 **데이터 전처리 및 DataFrame 생성** 후,  
    `sagemaker-spark` 라이브러리로 SageMaker 모델과 통합
- **SageMakerEstimator**: KMeans, PCA, XGBoost 등 학습
- **SageMakerModel**: 훈련된 모델로 예측 수행
    
예시

`val estimator = new KMeansSageMakerEstimator(...) val model = estimator.fit(trainingData) val transformedData = model.transform(testData)`

이점

- Spark의 대용량 데이터 처리와 SageMaker의 ML 기능을 결합
- EMR + SageMaker 간 통합으로 대규모 ML 파이프라인 구현 가능
    

---

## Modern SageMaker (SageMaker Studio 시대)

### SageMaker Studio

- 통합형 **시각적 IDE**로, 모델 학습·튜닝·디버깅·배포까지 관리 가능
    
### SageMaker Notebooks

- 인프라 관리 없이 **노트북 인스턴스 생성 및 공유**
- 하드웨어 전환 가능
    
### SageMaker Experiments

- 실험 추적, 비교, 결과 검색 기능
    

---

### SageMaker Debugger

기능

- 학습 중 **모델 내부 상태(gradient, tensor 등)** 저장 및 시각화
- 학습 중 오류 탐지 규칙(rule) 정의 가능
- 규칙 위반 시 CloudWatch 이벤트 트리거
- SageMaker Studio에서 **자동 디버깅 리포트** 및 대시보드 제공
    

지원 프레임워크

- TensorFlow, PyTorch, MXNet, XGBoost
- 사용자 정의 컨테이너도 지원
    
최신 기능

- **Debugger Insights Dashboard**
- **ProfilerRule**, **ProfilerReport**
- 하드웨어/프레임워크 메트릭 수집 (CPU/GPU 병목 등)
- 규칙 기반 자동 조치: `StopTraining()`, `Email()`, `SNS 알림` 등
    

---

## SageMaker Autopilot (AutoML)

개요

- 완전 자동화된 머신러닝:
    - 알고리즘 선택, 데이터 전처리, 모델 튜닝, 인프라 관리 자동화
        
- AutoML의 AWS 구현체
    
워크플로우

1. S3에서 학습 데이터 로드
2. 예측 대상 열(Target Column) 선택
3. 자동 모델 생성 및 결과 리더보드 제공
4. 최고 성능 모델 선택 → 배포 및 모니터링.
    

지원 문제 유형

- 이진/다중 분류, 회귀
    
알고리즘

- Linear Learner, XGBoost, MLP(딥러닝), Ensemble
    
입력 데이터 형식

- **CSV 또는 Parquet (테이블 형태)**
    

### Autopilot Training Modes

|모드|설명|
|---|---|
|HPO|하이퍼파라미터 최적화 (100MB 이상 데이터셋에서 기본값).|
|Ensembling|여러 모델(트리, NN 등)을 결합한 스태킹 앙상블 (100MB 이하).|
|Auto|데이터 크기에 따라 자동 선택.|

- Bayesian Optimization, Multi-Fidelity 기법 사용
- 성능 낮은 시도는 조기 종료(Early Stopping)
    

### Autopilot Explainability

- SageMaker **Clarify** 통합: 모델 예측의 투명성 확보
- **특성 중요도(Feature Attribution)** 분석:
    - SHAP/샤플리 값 기반 → 각 특성이 예측에 미치는 영향 수치화
        

---

## SageMaker Model Monitor

기능

- 배포된 모델의 품질 이상 감지 및 알림 (CloudWatch 연동)
- **Data Drift, Bias, Outlier, Feature Drift** 탐지
- SageMaker Studio 내 시각화 지원
- TensorBoard, QuickSight, Tableau와 통합 가능
    
#### Bias Metrics (Clarify 통합)

- Class Imbalance, DPL, KL Divergence, TVD, KS, CDD 등
- 사전훈련 데이터의 **편향도(bias)** 분석
    
#### Monitoring 유형

|유형|설명|
|---|---|
|데이터 품질 드리프트|통계적 특징 변화 감지|
|모델 품질 드리프트|정확도/성능 저하 탐지|
|편향 드리프트|그룹 간 불균형 변화|
|특성 중요도 드리프트|NDCG 기반 feature 순위 변화 감지|

---

## Deployment Safeguards (배포 안전장치)

- 실시간 및 비동기 추론 엔드포인트에서 **배포 트래픽 제어**:
    - **Blue/Green**: 전체 전환 후 모니터링
    - **Canary**: 일부 트래픽만 새 모델로 전환
    - **Linear**: 일정 간격으로 점진적 전환.
        
- **자동 롤백(Auto-Rollback)** 및 **Shadow Testing** 지원 → 새 모델을 실서비스 전 모니터링 후 승격 가능
    

---