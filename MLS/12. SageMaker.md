
### Amazon SageMaker 개요

- SageMaker는 **머신러닝 전체 워크플로우**를 지원하는 완전 관리형 서비스이다
    - 데이터 수집·정제·준비
    - 모델 학습 및 평가
    - 모델 배포 및 운영 환경 성능 모니터링
- SageMaker는 단일 서비스가 아니라, 기존의 검증된 AWS 서비스들을 유기적으로 통합하고 오케스트레이션하여 ML 파이프라인의 복잡성을 해소하는 데 중점을 둠
        

---

### SageMaker Training & Deployment

![](images/Pasted%20image%2020250916231511.png)

- 학습과 배포 모두 관리형으로 지원
- SageMaker의 핵심은 데이터와 코드를 분리하여 관리하는 구조에 있다.
- Training
	- S3에 저장된 훈련 데이터와 ECR에 등록된 훈련 코드 이미지를 활용하여 모델 학습
	- 그 결과물인 모델 아티팩트(model artifacts)는 다시 S3의 지정된 위치에 자동으로 저장
- Deploy
	- 훈련된 모델 아티팩트를 S3에서 가져와 ECR에 저장된 추론(inference) 코드 이미지와 결합하여 수행
	- 해당 리소스 기반으로 SageMaker Endpoint가 생성되어 클라이언트와 연결
    
- 구성 요소:
    - **S3**: 학습 데이터 및 모델 아티팩트 저장
    - **ECR**: 학습/추론 코드 이미지 저장
    - **엔드포인트(Endpoint)**: 모델 배포 후 클라이언트 앱과 연결
        

---

### SageMaker Notebooks & Console

SageMaker는 두 가지 주요 인터페이스를 통해 머신러닝 워크플로우를 제어하고 관리할 수 있도록 지원함.

- **Notebook Instance(EC2 기반)**:
	- ![](images/Pasted%20image%2020250916232157.png)
	- EC2 인스턴스에 기반한 관리형 Jupyter 노트북 환경 (콘솔에서 쉽게 실행가능)
    - S3에 저장된 데이터에 직접 접근 가능
    - Scikit-learn, Spark, TensorFlow 등의 내장 라이브러리 지원
    - 학습 인스턴스 실행 및 모델 배포 가능
        
- **SageMaker 콘솔**: GUI 기반으로 워크플로우 관리
	- ![](images/Pasted%20image%2020250916232209.png)
	- 훈련 작업, 노트북 인스턴스, 모델, 엔드포인트 등 SageMaker의 모든 리소스를 시각적으로 관리하고 모니터링하는 데 사용된다.
    

---

### Data Preparation on SageMaker

- 일반적으로 **S3**에서 데이터 로드 (S3는 확장성과 안정성이 뛰어난 클라우드 객체 스토리지)
	- S3 외에도 Amazon Athena, EMR(Elastic MapReduce), Redshift, 그리고 Amazon Keyspaces DB와 같은 다양한 AWS 서비스에서 데이터를 수집할 수 있는 유연성을 제공
- 알고리즘에 따라 권장 형식 다름
	- SageMaker의 내장 알고리즘의 경우, 종종 `RecordIO / Protobuf` 형식이 이상적인 데이터 형식임
- Spark와 통합 가능
- SageMaker Notebooks 환경 내에서는  `Scikit_learn`, `numpy`, `pandas`와 같은 널리 사용되는 데이터 과학 라이브러리를 활용하여 데이터 처리 작업을 자유롭게 수행가능하다.
    
###  SageMaker Processing

데이터 전처리
- 데이터 전처리 과정은 단순한 데이터 추출을 넘어 복잡한 변환, 정규화, 특성 공학(feature engineering) 등을 포함할 수 있으며, 이는 모델 훈련만큼이나 많은 컴퓨팅 자원을 요구한다.

![](images/Pasted%20image%2020250916232718.png)

- S3에서 원본 데이터 복사 → Processing container 실행 → 가공 결과 S3 저장
- 내장 또는 사용자 지정 컨테이너 사용 가능
- 입력 및 출력 경로는 각각  `/opt/ml/processing/input/`와 `/opt/ml/processing/output/`으로 표준화되어 있어, 컨테이너 내에서 데이터에 쉽게 접근할 수 있음

---
### Training on SageMaker

- SageMaker에서 모델 훈련을 시작하려면 훈련 작업을 생성해야 한다.
- 학습 작업(job) 생성 시:
    - 입력: 
	    - S3 학습 데이터 경로 
	    - 출력 S3 경로 
	    - 훈련에 사용할 ML 컴퓨팅 리소스(예: CPU 또는 GPU 인스턴스)를 선택
	    - 훈련 코드가 포함된 ECR 경로를 지정
	      
    - 지원 학습 방식:
        - 내장 알고리즘 (XGBoost, Linear Learner 등)
        - Apache Spark MLLib 지원
        - Python 기반의 TensorFlow, MXNet, PyTorch, Scikit-learn 코드를 직접 작성하여 사용 가능
        - Hugging Face 같은 최신 프레임워크도 지원
        - 직접 작성한 Docker 이미지, AWS Marketplace 알고리즘 사용 가능
            

---

### Deploying Trained Models

- 학습된 모델을 S3에 저장 후 배포 가능
- 배포 방식:
    - **Persistent Endpoint**: 실시간 예측
	    - 실시간 예측을 위해 상시 가동되는 엔드포인트로, 개별적인 예측 요청에 대해 즉시 응답해야 하는 애플리케이션에 적합하다.
    - **Batch Transform**: 대량 데이터 일괄 예측
	    - 전체 데이터셋에 대한 예측을 한 번에 수행할 때 사용
	    - 실시간 응답이 필요하지 않은 오프라인 예측 작업에 효율적이며, 비용을 절감하는 데 도움이 됨
        
- 고급 기능:
    - Inference Pipelines (복잡한 처리 파이프라인)
	    - 여러 컨테이너를 순차적으로 연결하여 복잡한 전처리 및 추론 단계를 하나의 엔드포인트에서 처리 가능
    - SageMaker Neo 
	    - 모델을 최적화하여 edge device에 배포하는 데 사용
    - Elastic Inference (딥러닝 추론 가속)
	    - 딥러닝 모델의 추론을 가속화하기 위해 GPU 가속기를 엔드포인트에 동적으로 연결
    - Automatic Scaling (엔드포인트 수 자동 조정)
	    - 트래픽 변화에 따라 엔드포인트 수를 자동으로 조정하여 비용 효율성을 높임.
    - Shadow Testing (새 모델과 기존 모델 비교 테스트)
	    - 규 모델을 현재 배포된 모델과 비교하여 성능과 오류를 평가하는 데 사용
---

### SageMaker Built-in Algorithms

#### (1) Linear Learner

- 용도: 선형 회귀 및 분류 (이진/다중 클래스)
  
- 입력 형식:
    - RecordIO-wrapped protobuf (float32)
    - CSV (첫 번째 열이 레이블(label)로 간주됨)
      
- 전처리: 데이터 정규화, 셔플 필요 (자동 지원)
  
- 학습: 확률적 경사하강법(SGD, Stochastic Gradient Descent), Adam/AdaGrad 지원, L1/L2 규제 가능
  
- 하이퍼파라미터:
    - balance_multiclass_weights: 클래스 균형 맞춤 (각 클래스에 동일한 중요도를 부여)
    - learning_rate, mini_batch_size
    - L1 정규화를 위한 L1, L2 정규화인 가중치 감소(weight decay)를 위한 Wd
    - target_precision / target_recall: 정밀도·재현율 기준 설정
      
- 인스턴스 유형: CPU/GPU 지원, 단일·멀티 머신 가능 (알고리즘의 특성상 멀티-GPU 성능 향상에 큰 도움이 되지 않음)

  

---

#### (2) XGBoost

Decision Tree란

- 결정트리 모델이란 데이터에 있는 규칙을 학습을 통해 자동으로 찾아내 트리 (Tree)기반의 분류 규칙을 만드는것으로 이 모양이 나무를 닮아 Tree 모델
- [https://velog.io/@ljs7463/%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%ACDecision-Tree%EB%AA%A8%EB%8D%B8Model](https://velog.io/@ljs7463/%EA%B2%B0%EC%A0%95%ED%8A%B8%EB%A6%ACDecision-Tree%EB%AA%A8%EB%8D%B8Model)

앙상블(Ensemble)이란?

- 여러 개의 머신러닝 모델을 조합해 예측 성능을 높이는 기법
- 개별 모델의 약점을 보완하고, 예측의 안정성과 정확도를 향상

결정 트리의 앙상블 대표 기법

1. **랜덤 포레스트(Random Forest)**

    - 여러 개의 결정 트리를 각각 랜덤하게 학습시켜(입력 데이터와 특성을 랜덤 샘플링)
    - 결과를 다수결(분류) 혹은 평균(회귀)으로 결합
    - 과적합(overfitting)을 줄이고, 예측 성능이 높아짐

2. **그래디언트 부스팅(Gradient Boosting)**

    - 여러 결정 트리를 순차적으로 학습시킴
    - 앞선 트리의 오류를 다음 트리가 보완한다
    - 대표 알고리즘: XGBoost, LightGBM, CatBoost 등

#### XGBoost

  ![](images/Pasted%20image%2020250917223729.png)

- 결정 트리의 앙상블을 사용하는 알고리즘으로, 새로운 트리를 추가하여 이전 트리의 오류를 수정하는 방식으로 작동
    - hot model
	    - XGBoost는 분류 및 회귀 문제 모두에 뛰어난 성능을 보임
	    - XGBoost는 분류 및 회귀문제 모두에 뛰어난 성능을 보이며, Kaggle과 같은 데이터 과학 대회에서 자주 우승을 차지함

- 용도: eXtreme Gradient Boosting (의사결정트리 앙상블)
  
- 입력 형식: CSV, LibSVM, RecordIO-Protobuf, Parquet
    - 오픈 소스 알고리즘이지만, AWS는 이를 SageMaker 환경에 통합하면서 기능을 확장함
    - 기존의 CSV 또는 libsvm 형식 외에도 RecordIO-protobuf와 Parquet 형식의 입력 데이터를 처리할 수 있도록 지원

- How is it used:
	- `Pickle`을 사용한 직렬화 및 역직렬화
	- notebook 내에서 `sagemaker.xgboost` 프레임워크로 활용
	- SageMaker 내장 알고리즘 사용

- 하이퍼파라미터:
    - subsample: 과적합 방지
    - eta: 학습률 조절 (step size shrinkage) - 과적합 방지
    - gamma: 노드 분할 최소 손실 감소값
    - L1 정규화 alpha, L2 정규화 lambda
    - eval_metric: 최적화할 평기 지표를 지정. AUC(Area Under the Curve), RMSE(평균 제곱근 편차), Error 등
    - scale_pos_weight: 불균형 데이터 가중치 조정
    - max_depth: 트리 최대 깊이 설정

- 인스턴스 유형:
    - CPU 메모리 바운드 → M5 권장
        - XGBoost는 연산(compute-bound)보다는 메모리(memory-bound) 기반의 작업으로, 충분한 메모리를 가진 M5 인스턴스가 좋은 선택이다.
    - XGBoost 1.2: 단일 GPU 지원 (P2, P3) -`tree_method` 하이퍼파라미터를 `gpu_hist`로 설정해야함
    - XGBoost 1.2-2: GPU 지원 (P2, P3, G4dn, G5)
    - XGBoost 1.5+: 분산 GPU 학습 가능 (Dask 활용) (CSV 또는 Parquet 입력 형식에서만 작동)


---

#### (3) Seq2Seq: 시퀀스 변환 모델

- 용도: 시퀀스 입력 → 시퀀스 출력
    - 입력 시퀀스를 출력 시퀀스로 변환하는 데 사용

- 기계 번역, 텍스트 요약, 음성→텍스트

- 입력 형식: 다른 알고리즘과 달리, 토큰이 정수(integer)로 변환된 RecordIO-Protobuf 형식 필요
    - 훈련을 위해서는 훈련 데이터, 검증 데이터, 그리고 어휘(vocabulary) 파일을 모두 제공해야함.

- 알고리즘(학습): RNN/CNN 기반으로 구현

- Seq2Seq 모델 훈련은 상당한 시간이 소요될 수 있으며, 경우에 따라 며칠이 걸리기도 한다.
    - 사전 훈련된 모델을 활용하거나 공개된 데이터셋을 사용하는 것이 효율적일 수 있다.

- 하이퍼파라미터:
    - batch_size
    - optimizer_type (예: Adam, SGD)
    - learning_rate
    - num_layers_encoder, num_layers_decoder (인코더와 디코더의 레이어 수를 지정)

- Can Optimize on:
    - Accuracy
        - [https://white-joy.tistory.com/9](https://white-joy.tistory.com/9)
        - Accuracy(정확도): 모델이 전체 문제 중에서 정답을 맞춘 비율

    - 기계 번역 성능을 측정하는 BLEU(Bilingual Evaluation Understudy) score (기계 번역 결과와 사람이 번역한 참조 번역 간의 유사도를 측정하는 자동 평가 지표)
        - [https://modulabs.co.kr/blog/bleu-machine-translation](https://modulabs.co.kr/blog/bleu-machine-translation)

    - Perplexity (언어 모델의 예측 성능을 평가)
        - [https://fashionsale.tistory.com/entry/perplexity](https://fashionsale.tistory.com/entry/perplexity)

- 인스턴스 유형:
    - GPU 전용 (P3 등)
        - Seq2Seq는 복잡한 딥러닝 연산을 수행하므로, 훈련에는 GPU 인스턴스(예: P3)가 필수적
    - 단일 머신·멀티 GPU 가능


---

#### (4) DeepAR: 시계열 예측 모델

- 용도: 단일 차원 시계열 데이터 예측에 특화된 알고리즘

- 특징: RNN 기반, 여러 시계열 데이터에서 주기성과 계절성을 찾아내 학습

- 입력 형식: Gzip 또는 Parquet으로 압축된 JSON lines 형식의 입력 데이터 필요
	- ![](images/Pasted%20image%2020250917224505.png)
	- 각 레코드는 start(시작 타임스탬프)와 target(시계열 값)을 반드시 포함해야 하며, 선택적으로 동적 특성(dynamic features)을 위한 dynamic_feat와 범주형 특성(categorical features)을 위한 cat을 포함할 수 있다.

- 사용 방법:
    - 훈련, 테스트, 추론 시에는 항상 전체 시계열을 포함해야 한다.
    - 훈련 세트로 전체 데이터셋을 사용하고, 테스트를 위해서는 마지막 시점의 값을 제외하고 훈련한 후 보류된 값에 대해 예측 성능을 평가하는 방법이 권장된다.
    - 예측 길이는 너무 길게 (>400) 설정하지 말 것

- 하이퍼파라미터:
    - context_length: 모델이 예측 전에 보는 시점 수
    - epochs, mini_batch_size, learning_rate
    - num_cells: RNN의 셀 수를 지정

- 인스턴스 유형:
    - CPU/GPU 모두 가능
    - 작은 모델은 CPU(c4.2xlarge)에서 시작, 필요 시 GPU 사용 (대규모 모델이나 큰 미니배치 사이즈(>512))
    - 추론은 CPU only

---

### BlazingText 

- Word2vec과 텍스트 분류 알고리즘을 고도로 최적화하여 구현한 것
	- **Word2Vec**: 
		- 비지도 학습(Unsupervised learning) 방식
		- 핵심 기능은 단어 임베딩(Word Embedding)을 생성하는 것
		- 단어의 의미를 수치화된 벡터로 벡터로 임베딩, 의미적으로 유사한 단어는 가까운 벡터로 표현
	- **텍스트 분류(Text Classification)**: 
		- 지도 학습(Supervised learning) 방식
		- 문장 단위로 레이블을 예측
		- 웹 검색, 정보 검색, 문서 분류와 같이 문장이나 문서에 대한 레이블 예측이 필요한 광범위한 애플리케이션에 필수적인 역할을 수행
    
- 기계 번역, 감정 분석 등에서 활용
- 단, 단어 단위만 처리 가능 (문장·문서 불가)
        

#### Training Input

![](images/Pasted%20image%2020250917225428.png)

- **Text Classification (지도학습)**:
    - 한 줄에 하나의 문장
    - 첫 번째 "단어"는 `__label__` 형식의 라벨
- **증강 매니페스트 텍스트 형식(Augmented Manifest Text Format):** 
	- `{"source":"...", "label":...}` 와 같은 JSON Lines 구조를 따른다 
	- 이 방식은 대규모 데이터셋을 Amazon S3에서 직접 스트리밍하여 학습하는 파이프 모드(Pipe Mode)에서 특히 유용
- **Word2Vec**: 한 줄에 하나의 문장이 있는 text file 
    
#### How is it used?

- Word2Vec 모드:
    - CBOW (Continuous Bag of Words)
	    - 주변 단어들의 맥락을 기반으로 중심 단어를 예측
    - Skip-gram
	    - 중심 단어를 기반으로 주변 단어들을 예측
    - Batch Skip-gram (분산 처리 가능)
	    - 대규모 데이터셋에 대한 훈련을 위해 여러 CPU 노드에 걸쳐 분산 처리가 가능하도록 설계됨
        
#### Important Hyperparameters

- Word2Vec:
    - `mode`: - Word2vec 아키텍처를 지정하는 필수 파라미터 
	    - `batch_skipgram`, `skipgram`, `cbow` 중 하나를 선택
    - `learning_rate`
    - `window_size`: 주변 단어의 맥락을 정의하는 윈도우 크기
    - `vector_dim`: 생성될 단어 임베딩 벡터의 차원을 결정
    - `negative_samples`
        
- Text Classification:
    - `epochs`: 전체 훈련 데이터셋을 반복할 횟수 
    - `learning_rate`
    - `word_ngrams`: n-gram 모델을 위한 파라미터로, 단어 그룹의 크기를 지정
    - `vector_dim`
        

#### Instance Types

- Word2vec (cbow 및 skip-gram): 단일 CPU 또는 GPU
	- `ml.p3.2xlarge`와 같은 GPU 인스턴스는 높은 병렬 처리 능력을 활용하는 데 효과적
    
- Word2vec (batch_skipgram): 이 모드는 분산 컴퓨팅을 지원하므로, 단일 또는 다중 CPU
    
- Text Classification:

    - 데이터 < 2GB → C5 인스턴스 권장
    - 대규모 데이터 → GPU (ml.p2.xlarge, ml.p3.2xlarge)
        

---

### Object2Vec 

- **BlazingText의 `Word2vec` 알고리즘을 단어라는 제약에서 벗어나 임의의 객체까지 임베딩**하는 것
- 이 알고리즘의 주요 목적은 고차원의 복잡한 객체들(예: 문장, 고객, 제품)을 저차원의 밀집 임베딩(low-dimensional dense embeddings)으로 변환하는 것
- 학습 과정에서 임베딩은 원본 공간에 존재하는 객체 쌍 간의 의미적 관계를 보존하도록 최적화된다.
	- 이를 통해, 임베딩된 벡터를 사용하여 객체 간의 유사도를 계산하거나, 클러스터를 시각화하는 등의 작업을 효율적으로 수행할 수 있게 된다.

- 사용 사례:
    - **객체 간 최근접 이웃(Nearest Neighbors) 계산:** 
	    - 유사한 객체를 빠르게 찾는 데 사용
    - **클러스터 시각화:** 
	    - 임베딩 공간에서 객체들의 군집을 시각적으로 확인하여 데이터의 구조를 파악하는 데 유용
    - **장르 예측:** 
	    - 콘텐츠의 특징을 임베딩하여 장르를 분류하거나 예측하는 데 활용
    - 추천 시스템 (유사 상품/사용자): 
	    - 사용자-항목, 상품-상품 등 객체 쌍 간의 관계를 학습하여 유사한 항목이나 사용자에게 맞는 추천을 제공
        
#### Training Input

- **토큰화:** 모든 입력 데이터는 텍스트, 이미지, 또는 기타 객체에 관계없이 사전에 정수(integer)로 토큰화되어야한다.
- 학습 데이터: 
	- ![](images/Pasted%20image%2020250917230901.png)
	- 학습 데이터는 `{"label": 0, "in0": [...], "in1": [...]}` 와 같은 JSON Lines 형식으로 구성되어야 한다. 
	- 각 줄에는 `label` 필드와 두 개의 입력 필드(`in0`, `in1`)가 포함된다. `in0`과 `in1` 필드는 정수 리스트로 표현된 객체 쌍을 나타낸다.
- **쌍으로 구성:** 학습 데이터는 두 개의 토큰 또는 토큰 시퀀스 쌍으로 구성
	- 예: 문장–문장, 고객–고객, 상품–상품, 사용자–아이템
        

#### How is it used?

- JSON Lines 형식으로 데이터 준비 후 셔플된 다음 학습에 사용
- 구조:
	- ![](images/Pasted%20image%2020250917231003.png)
    - 두 개의 입력 채널, 두 개의 인코더, 그리고 한 개의 비교기(Comparator)를 사용하여 학습
    - 입력 → 인코더 (CNN, BiLSTM, 평균 임베딩) → 비교기(Comparator) → 출력
	    - 두 입력 채널이 각각의 인코더를 통해 처리된 후, 결과는 비교기로 전달된다. 
	    - 이 비교기는 두 인코더의 출력을 비교하여 관계를 학습하며, 그 결과는 최종적인 피드포워드 신경망으로 전달되어 최종 예측을 수행한다.
    
#### Important Hyperparameters

- 일반 딥러닝 파라미터:
    - `dropout`, `epochs`, `learning_rate`, `batch_size`, `activation`, `optimizer`, `weight_decay`.
        
- 인코더 설정: 
	- `enc1_network`, `enc2_network`
		- 각 인코더에 사용될 네트워크 아키텍처를 지정
		- 선택 옵션으로는  `hcnn`, `bilstm`, `pooled_embedding`이 있다.
    

#### Instance Types

- 학습은 단일 머신만 지원 (CPU 또는 GPU, 멀티 GPU 가능)
- 권장: ml.m5.2xlarge, ml.p2.xlarge
- 대규모: ml.m5.4xlarge, ml.m5.12xlarge, P3, G4dn, G5
- 추론: ml.p3.2xlarge
	- `INFERENCE_PREFERRED_MODE` 환경 변수를 사용하여 인코더 임베딩에 대한 추론을 최적화할 수 있다.

---

### Object Detection 

- ![](images/Pasted%20image%2020250917231411.png)
- 단일 딥러닝 신경망을 사용하여 이미지 내의 모든 객체를 식별하고 분류하는 지도 학습(supervised learning) 알고리즘
- 이미지에서 객체 탐지 및 분류, 바운딩 박스로 위치 지정
- 출력: 객체 클래스 + 신뢰도 점수
	- 각 객체는 사전에 정의된 클래스 중 하나로 분류
	- 해당 클래스에 속할 확률을 나타내는 신뢰도 점수(confidence score) 포함
- 학습: 처음부터 학습 가능, 또는 **ImageNet 기반 사전학습 모델** 활용
    
#### How is it used?

- **MXNet**:
    - `Single Shot multibox Detector (SSD)` 프레임워크를 사용하며, 기본 CNN 네트워크로는 `VGG-16` 또는 `ResNet-50`을 선택할 수 있다. 
    - 과적합(overfitting)을 방지하기 위해 내부적으로 뒤집기(flip), 크기 조정(rescale), 지터링(jitter) 등의 데이터 증강(Data Augmentation) 기법을 사용한다.
        
- **TensorFlow**:
    - TensorFlow Model Garden에서 제공하는 `ResNet`, `EfficientNet`, `MobileNet` 모델을 기반으로 한다.
    
#### Training Input

- **MXNet**: RecordIO 또는 이미지 파일(JPG, PNG)
- 이미지 파일 사용 시: 각 이미지에 대한 주석 데이터(annotation data)가 포함된 JSON 파일을 함께 제공해야 한다.
    - 포함 항목: 파일명, 이미지 크기, 객체 클래스, 바운딩 박스 좌표
        
#### Important Hyperparameters

- `mini_batch_size`: 한 번의 훈련 반복에 사용되는 데이터 샘플의 수
- `learning_rate`: 모델의 가중치를 업데이트하는 속도를 제어하는 학습률
- `optimizer`: `sgd`, `adam`, `rmsprop`, `adadelta`와 같은 최적화 알고리즘을 선택할 수 있다.

#### Instance Types

- **학습**: GPU 권장 (멀티 GPU, 멀티 머신 지원) - 매우 계산 집약적인 작업이므로, GPU 인스턴스 사용이 필수적
    - ml.p2.xlarge, ml.p2.16xlarge, ml.p3.2xlarge, ml.p3.16xlarge, G4dn, G5
- **추론**: CPU 또는 GPU 모두 가능 (M5, P2, P3, G4dn)

