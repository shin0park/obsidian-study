
### Amazon SageMaker 개요

- SageMaker는 **머신러닝 전체 워크플로우**를 지원하는 완전 관리형 서비스이다
    - 데이터 수집·정제·준비
    - 모델 학습 및 평가
    - 모델 배포 및 운영 환경 성능 모니터링
- SageMaker는 단일 서비스가 아니라, 기존의 검증된 AWS 서비스들을 유기적으로 통합하고 오케스트레이션하여 ML 파이프라인의 복잡성을 해소하는 데 중점을 둠
        

---

### SageMaker Training & Deployment

![](images/Pasted%20image%2020250916231511.png)

- 학습과 배포 모두 관리형으로 지원
- SageMaker의 핵심은 데이터와 코드를 분리하여 관리하는 구조에 있다.
- Training
	- S3에 저장된 훈련 데이터와 ECR에 등록된 훈련 코드 이미지를 활용하여 모델 학습
	- 그 결과물인 모델 아티팩트(model artifacts)는 다시 S3의 지정된 위치에 자동으로 저장
- Deploy
	- 훈련된 모델 아티팩트를 S3에서 가져와 ECR에 저장된 추론(inference) 코드 이미지와 결합하여 수행
	- 해당 리소스 기반으로 SageMaker Endpoint가 생성되어 클라이언트와 연결
    
- 구성 요소:
    - **S3**: 학습 데이터 및 모델 아티팩트 저장
    - **ECR**: 학습/추론 코드 이미지 저장
    - **엔드포인트(Endpoint)**: 모델 배포 후 클라이언트 앱과 연결
        

---

### SageMaker Notebooks & Console

SageMaker는 두 가지 주요 인터페이스를 통해 머신러닝 워크플로우를 제어하고 관리할 수 있도록 지원함.

- **Notebook Instance(EC2 기반)**:
	- ![](images/Pasted%20image%2020250916232157.png)
	- EC2 인스턴스에 기반한 관리형 Jupyter 노트북 환경 (콘솔에서 쉽게 실행가능)
    - S3에 저장된 데이터에 직접 접근 가능
    - Scikit-learn, Spark, TensorFlow 등의 내장 라이브러리 지원
    - 학습 인스턴스 실행 및 모델 배포 가능
        
- **SageMaker 콘솔**: GUI 기반으로 워크플로우 관리
	- ![](images/Pasted%20image%2020250916232209.png)
	- 훈련 작업, 노트북 인스턴스, 모델, 엔드포인트 등 SageMaker의 모든 리소스를 시각적으로 관리하고 모니터링하는 데 사용된다.
    

---

### Data Preparation on SageMaker

- 일반적으로 **S3**에서 데이터 로드 (S3는 확장성과 안정성이 뛰어난 클라우드 객체 스토리지)
	- S3 외에도 Amazon Athena, EMR(Elastic MapReduce), Redshift, 그리고 Amazon Keyspaces DB와 같은 다양한 AWS 서비스에서 데이터를 수집할 수 있는 유연성을 제공
- 알고리즘에 따라 권장 형식 다름
	- SageMaker의 내장 알고리즘의 경우, 종종 `RecordIO / Protobuf` 형식이 이상적인 데이터 형식임
- Spark와 통합 가능
- SageMaker Notebooks 환경 내에서는  `Scikit_learn`, `numpy`, `pandas`와 같은 널리 사용되는 데이터 과학 라이브러리를 활용하여 데이터 처리 작업을 자유롭게 수행가능하다.
    
###  SageMaker Processing

데이터 전처리
- 데이터 전처리 과정은 단순한 데이터 추출을 넘어 복잡한 변환, 정규화, 특성 공학(feature engineering) 등을 포함할 수 있으며, 이는 모델 훈련만큼이나 많은 컴퓨팅 자원을 요구한다.

![](images/Pasted%20image%2020250916232718.png)

- S3에서 원본 데이터 복사 → Processing container 실행 → 가공 결과 S3 저장
- 내장 또는 사용자 지정 컨테이너 사용 가능
- 입력 및 출력 경로는 각각  `/opt/ml/processing/input/`와 `/opt/ml/processing/output/`으로 표준화되어 있어, 컨테이너 내에서 데이터에 쉽게 접근할 수 있음

---
### Training on SageMaker

- SageMaker에서 모델 훈련을 시작하려면 훈련 작업을 생성해야 한다.
- 학습 작업(job) 생성 시:
    - 입력: 
	    - S3 학습 데이터 경로 
	    - 출력 S3 경로 
	    - 훈련에 사용할 ML 컴퓨팅 리소스(예: CPU 또는 GPU 인스턴스)를 선택
	    - 훈련 코드가 포함된 ECR 경로를 지정
	      
    - 지원 학습 방식:
        - 내장 알고리즘 (XGBoost, Linear Learner 등)
        - Apache Spark MLLib 지원
        - Python 기반의 TensorFlow, MXNet, PyTorch, Scikit-learn 코드를 직접 작성하여 사용 가능
        - Hugging Face 같은 최신 프레임워크도 지원
        - 직접 작성한 Docker 이미지, AWS Marketplace 알고리즘 사용 가능
            

---

### Deploying Trained Models

- 학습된 모델을 S3에 저장 후 배포 가능
- 배포 방식:
    - **Persistent Endpoint**: 실시간 예측
	    - 실시간 예측을 위해 상시 가동되는 엔드포인트로, 개별적인 예측 요청에 대해 즉시 응답해야 하는 애플리케이션에 적합하다.
    - **Batch Transform**: 대량 데이터 일괄 예측
	    - 전체 데이터셋에 대한 예측을 한 번에 수행할 때 사용
	    - 실시간 응답이 필요하지 않은 오프라인 예측 작업에 효율적이며, 비용을 절감하는 데 도움이 됨
        
- 고급 기능:
    - Inference Pipelines (복잡한 처리 파이프라인)
	    - 여러 컨테이너를 순차적으로 연결하여 복잡한 전처리 및 추론 단계를 하나의 엔드포인트에서 처리 가능
    - SageMaker Neo 
	    - 모델을 최적화하여 edge device에 배포하는 데 사용
    - Elastic Inference (딥러닝 추론 가속)
	    - 딥러닝 모델의 추론을 가속화하기 위해 GPU 가속기를 엔드포인트에 동적으로 연결
    - Automatic Scaling (엔드포인트 수 자동 조정)
	    - 트래픽 변화에 따라 엔드포인트 수를 자동으로 조정하여 비용 효율성을 높임.
    - Shadow Testing (새 모델과 기존 모델 비교 테스트)
	    - 규 모델을 현재 배포된 모델과 비교하여 성능과 오류를 평가하는 데 사용

