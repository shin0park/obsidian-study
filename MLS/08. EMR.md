## **Amazon EMR (Elastic MapReduce)**

- EC2 기반 관리형 Hadoop 프레임워크
	- 즉, 빅데이터를 처리하고 분석하는 데 사용되는 관리형 서비스
	- Spark, Hive, HBase, Presto, Flink 지원
	- EMR 의 핵심 가치: Hadoop 클러스터의 복잡한 운영과 관리를 AWS가 대신 수행한다는 것
	- 페타바이트(petabyte)급의 대용량 데이터를 빠르고 효율적으로 분산 처리하여 분석 가능하다
	- 워크로드의 특성에 따라 클러스터를 신속하게 시작하거나 기존 클러스터에 서버를 동적으로 추가할 수 있는 유연한 용량을 제공한다.
	- EMR Serverless 제공

- **EMR 클러스터 구성 및 노드 유형**
	- ![](images/Pasted%20image%2020250812011549.png)
	- Master 노드: 클러스터 관리자 (EC2 1대)
		- 코어노드와 태스크 노드에 작업 할당
		- 전체 흐름 조정
	- Core 노드: 
		- HDFS(Hadoop Destributive File System) 데이터 저장 + 태스크 실행(연산처리)
		- 클러스터 실행 중에 확장하거나 축소할 수 있지만, HDFS에 데이터가 저장되어 있어 축소 시 데이터 유실 위험이 발생할 수 있다.
	- Task 노드: HDFS 데이터를 저장하지 않고 오직 연산 처리만 전담하는 노드
		- HDFS 데이터를 가지고 있지 않으므로 클러스터에서 제거해도 데이터 유실 위험이 없음.
		- Spot 인스턴스 사용 권장
    
- **Usage**: 
	- 다양한 빅데이터 워크로드의 특성에 따라 두가지 주요 운영 모델로 실행될 수 있음.
	- Transient(임시) vs Long-Running(장기) Clusters
		- 임시 클러스터는 특정 작업이 완료되면 자동으로 종료되므로 비용을 절감하는 데 유리
			- 이는 한 번만 실행되는 ETL(추출, 변환, 로드) 작업이나 배치 처리 작업에 적합
		- 장기 실행 클러스터는 지속적인 분석, 데이터 웨어하우징, 또는 서비스 제공과 같이 상시 가동이 필요한 환경에 사용
	- EMR Serverless
		- 사용자가 노드 프로비저닝이나 크기 조정에 신경 쓰지 않고도 워크로드에 따라 AWS가 자동으로 컴퓨팅 자원을 관리하는 유연성을 제공

- **AWS 서비스와의 통합**: 
	- **EC2**: EMR 클러스터를 구성하는 노드 인스턴스를 제공\
	- **VPC**: 클러스터가 실행되는 격리된 가상 네트워크 환경을 구성하여 보안을 강화합니다.  
	- **S3**: EMRFS를 통해 입력 및 출력 데이터의 영구적인 스토리지로 사용. EMR은 S3를 데이터 레이크로 활용하여 컴퓨팅과 스토리지를 분리하는 아키텍처를 구현
	- **CloudWatch**: 클러스터 성능을 모니터링하고, 특정 지표에 대한 알람을 설정하는 데 사용\ 
	- **IAM**: 클러스터 및 관련 AWS 리소스에 대한 접근 권한을 세밀하게 구성
	- **CloudTrail**: 서비스에 대한 모든 요청을 감사(audit)하여 보안 및 규정 준수를 지원
	- **Data Pipeline**: 클러스터의 시작 및 작업을 예약하고 조정하는 데 사용
	- **Glue Data Catalog**: EMR에서 Apache Hive 및 Spark의 관리형 메타데이터 리포지토리로 사용
	- **Kinesis, Redshift, DynamoDB**: EMR은 이러한 서비스들과도 쉽게 통합되어 데이터 이동, 워크플로 관리 및 분석을 지원

- **스토리지**: 
	- **HDFS (Hadoop Distributed File System)**: 
		- 하둡의 핵심 분산 파일 시스템으로, 마스터 및 코어 노드에 사용 
		- HDFS는 클러스터 내에서 빠른 처리를 위한 고성능을 제공하지만, 클러스터가 종료되면 데이터가 사라지는 휘발성 스토리지
		- 따라서 중간 작업 흐름 단계에서 생성된 결과를 캐시하는 데 가장 적합하다.
    
	- **EMRFS (EMR File System)**: 
		- EMR에서 Amazon S3로 직접 일반 파일을 읽고 쓸 수 있도록 하는 HDFS 구현체
		- Amazon S3에 영구 데이터를 저장 가능.
		- EMRFS는 S3의 서버 측 암호화, 읽기 후 쓰기 일관성(read-after-write consistency) 등 다양한 기능을 활용할 수 있도록 지원
		- https://docs.aws.amazon.com/ko_kr/emr/latest/ReleaseGuide/emr-fs.html
    
		- **EMRFS Consistent View**: 
			- EMR은 S3의 최종 일관성(eventual consistency) 모델을 보완하기 위해 자체적인 `Consistent View` 메커니즘을 제공한다. 
			- DynamoDB를 사용하여 S3에 저장된 파일의 메타데이터를 추적함으로써 파일의 일관성을 강화한다.
			- EMR 클러스터가 여러 작업에서 동일한 데이터에 접근할 때 데이터의 정합성을 보장하는 데 중요한 역할을 한다. 
			- https://docs.aws.amazon.com/ko_kr/emr/latest/ReleaseGuide/emrfs-configure-consistent-view.html
    
	- **로컬 파일 시스템**: 
		- 각 EMR 노드의 EC2 인스턴스에 연결된 인스턴스 스토어 볼륨을 의미. 
		- 이 스토리지의 데이터는 인스턴스의 수명 동안만 유지되므로, HDFS와 마찬가지로 버퍼, 캐시, 스크래치 데이터 등 임시 데이터를 저장하는 데 적합
    
	- **EBS (Elastic Block Store)**: 영구성을 갖는 EBS를 HDFS에 활용하여 데이터의 내구성을 높이는 방법으로 사용 가능

- **비용**:
	- EMR: 시간당 요금 + EC2 비용
	- EMR의 관리 모델은 '탄력성(elasticity)'이라는 핵심 가치를 기반으로 함
		- EMR은 클러스터의 코어 노드에 장애가 발생할 경우 새 노드를 자동으로 프로비저닝하여 가용성을 보장. 
		- 실행 중인 클러스터의 코어 노드와 태스크 노드를 동적으로 추가하거나 제거할 수 있는 기능을 제공.

---

### 빅데이터 프레임워크: Hadoop과 Spark

#### Hadoop의 기본 원리와 구성 요소

![](images/Pasted%20image%2020250812013201.png)

- Hadoop은 Google이 개발한 빅데이터 분산 처리 프레임워크로, 대규모 데이터 세트를 분산하여 처리하는 기본 원리를 제공
- EMR은 이러한 하둡의 원리를 기반으로 구축된 관리형 서비스. 

#### 세가지 핵심 요소

- **MapReduce**: 
	- 대규모 데이터 세트를 분산하여 처리하는 프로그래밍 모델. 
	- 데이터를 매핑(mapping)하고 축소(reducing)하는 두 단계의 작업을 통해 연산을 수행. (mapper)
    
- **YARN (Yet Another Resource Negotiator)**: 
	- 클러스터의 리소스를 관리하고, MapReduce와 같은 애플리케이션의 실행을 스케줄링하는 역할을 한다. 
	- YARN은 클러스터의 효율적인 리소스 활용을 가능하게 한다.
    
- **HDFS (Hadoop Distributed File System)**: 
	- 대규모 파일을 여러 컴퓨터에 분산하여 저장하는 하둡의 분산 파일 시스템. 
	- HDFS의 존재는 데이터가 클러스터 노드에 분산되어 처리될 수 있는 기반을 마련한다..  
    

EMR을 '관리형 Hadoop 프레임워크'로 정의하는 것은, EMR이 단순히 여러 오픈 소스를 모아놓은 것이 아니라 Hadoop의 핵심 원리(분산 처리, 리소스 관리, 분산 파일 시스템)를 기반으로 구축되었음을 의미. 
따라서 EMR을 깊이 있게 이해하기 위해서는 하둡의 기본 아키텍처와 원리를 먼저 파악하는 것이 중요.

---
### Apache Spark

![](images/Pasted%20image%2020250812013434.png)

- Apache Spark는 하둡과 마찬가지로 빅데이터 워크로드에 사용되는 오픈 소스 분산 처리 시스템이지만, 하둡 MapReduce에 비해 몇 가지 중요한 성능적 이점을 가지고 있다. 
- Spark는 하둡의 YARN과 HDFS 위에 구축되어 있으며, EMR 클러스터에서 하둡과 함께 사용할 수 있다.


Spark의 주요 특징
- **최적화된 비순환 방향 그래프(DAG, Directed Acyclic Graph) 실행 엔진과 데이터를 메모리에 캐시하는 기능.**
- 이로 인해 Spark는 하둡 MapReduce에 비해 특정 반복적인 알고리즘이나 대화형 쿼리에서 훨씬 뛰어난 성능을 보입다. 
- EMR 사용자가 MapReduce 대신 Spark를 선택하는 근본적인 이유가 바로 이러한 메모리 기반 처리와 최적화된 실행 엔진에 있다.
---
#### Spark의 작동 방식 및 아키텍처

![](images/Pasted%20image%2020250812013609.png)

- **드라이버 프로그램**: 
	- Spark 애플리케이션의 메인 함수를 실행하고 `Spark Context`를 생성. 
	- 드라이버는 전체 작업 흐름을 관리하며, 작업을 논리적 단계로 분할하여 클러스터 관리자에게 제출
    
- **클러스터 관리자**: Spark, YARN 등과 같은 클러스터 관리자가 드라이버 프로그램의 요청에 따라 클러스터의 리소스를 할당.
    
- **실행기(Executor)**: 클러스터 관리자에 의해 할당된 각 노드에서 실행되는 프로세스로, 실제 작업을 처리하고 결과를 반환. 실행기는 또한 데이터를 캐시하여 반복적인 작업의 성능을 향상시킨다.

-> 드라이버가 전체 작업 흐름을 조정하고, 클러스터 관리자가 자원을 분배하며, 실행기가 개별 작업을 병렬로 처리하는 분산 컴퓨팅의 핵심 원리이다.

---
#### Spark의 주요 구성 요소

![](images/Pasted%20image%2020250812013920.png)

- **Spark Core**: 모든 Spark 애플리케이션의 기반이 되는 엔진으로, 분산 처리, 메모리 관리, 작업 스케줄링 등을 담당.
    
- **Spark Streaming**: 실시간 데이터 스트림 처리를 위한 라이브러리로, 소규모 데이터 배치를 연속적으로 처리하는 방식을 사용.
	- ![](images/Pasted%20image%2020250812014232.png)
	- Data stream에 따라 행이 계속 생겨나면서 처리 가능함
    
- **Spark SQL**: 구조화된 데이터 처리를 위한 SQL 및 데이터프레임 API를 제공합니다. 사용자는 SQL 쿼리를 직접 실행하거나 데이터프레임 API를 통해 데이터를 조작 가능.
    
- **MLlib (Machine Learning Library)**: 분류(로지스틱 회귀, naïve Bayes), 회귀, Decision trees, 클러스터링(K-Means) 등 다양한 머신러닝 알고리즘과 워크플로 유틸리티를 제공.  
    
- **GraphX**: 그래프 및 그래프 병렬 계산을 위한 라이브러리.

---
### EMR 기반의 인터랙티브 개발 도구

EMR은 Zeppelin과 EMR Notebooks를 통해 Spark 코드를 대화형으로 실행할 수 있는 환경을 제공

- **Zeppelin + Spark**: 
	- Spark 셸과 유사하게 Spark 코드를 대화형으로 실행하며, SparkSQL에 대해 SQL 쿼리를 직접 실행할 수 있다. 
	- 쿼리 결과는 차트나 그래프로 시각화될 수 있어 Spark를 데이터 과학 도구처럼 사용할 수 있게 한다.  
    
- **EMR Notebooks**:
	- Zeppelin과 유사한 개념이지만 AWS 생태계와의 통합이 강화된 서비스. 
	- EMR 클러스터에서 Jupyter Notebook 및 JupyterLab 인터페이스를 생성하고 열 수 있도록 지원. 
	- 노트북 S3에 백업됨
		- 내구성과 유연한 재사용이 보장
    - 노트북 인터페이스 내에서 EMR 클러스터를 프로비저닝 할 수 있다.
    - VPC 내에 호스팅되며, AWS 콘솔을 통해서만 접근할 수 있어 보안이 강화됨

---

- **인스턴스 선택**: 
	- **마스터 노드 (Master node)**
	    - 노드 수 50개 미만: `m4.large`
	    - 노드 수 50개 이상: `m4.xlarge`
        
- **코어(Core) & 태스크(Task) 노드**
    - 일반적인 경우: `m4.large`
    - 외부 의존 작업(예: 웹 크롤러) 대기 시간이 많을 때: `t2.medium`
    - 성능 향상이 필요할 때: `m4.xlarge`
    - 연산 집약적(Computation-intensive) 작업: **고성능 CPU 인스턴스**
    - 데이터베이스·메모리 캐싱 애플리케이션: **고메모리 인스턴스**
    - 네트워크/CPU 집약적(NLP, ML) 작업: **클러스터 컴퓨팅 인스턴스**
    - 가속 컴퓨팅·AI 작업: **GPU 인스턴스** (`g3`, `g4`, `p2`, `p3`)
        
- **스팟 인스턴스(Spot Instances)**
    - 태스크 노드에 적합
    - 코어·마스터 노드에는 테스트 목적 또는 매우 비용 민감한 경우에만 사용 (데이터 손실 위험 존재)
