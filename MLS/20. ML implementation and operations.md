## Wrapping Up & Lab Activity

- AWS는 기업이 복잡한 머신러닝 모델 개발 과정 없이도 고급 AI 기능을 활용할 수 있도록 완전 관리형 AI 서비스 포트폴리오를 제공한다. 
	- 이러한 고수준 AI 서비스(High-Level AI Services)는 API 호출을 통해 음성 인식, 텍스트 분석, 번역 등 전문화된 기능을 수행한다. 
	- 이러한 접근 방식의 핵심은 **서비스 구성(Service Composition)** 을 통해 여러 서비스를 파이프라인 형태로 연결하고, 한 서비스의 출력이 다음 서비스의 입력으로 사용되는 구조를 형성하는 것이다.
	- 이를 통해 고객은 개발 복잡성을 최소화하고, 프로토타입 구축 시간을 단축하며, 빠르게 비즈니스 가치를 창출할 수 있다.   

### Putting Them Together (서비스 조합)

AWS의 여러 AI/ML 서비스를 조합하여 응용 시스템을 만들 수 있음

- **나만의 Alexa 만들기 예시**
    - Amazon Transcribe → Amazon Lex → Amazon Polly
    - 음성을 텍스트로 변환 → 챗봇 처리 → 다시 음성으로 출력
        
- **범용 번역기 만들기 예시**
    - Transcribe → Translate → Polly
    - 음성을 텍스트로 변환 → 번역 → 변환된 텍스트를 음성으로
        
- **콜센터 감정 분석하기**
    - Transcribe → Comprehend
    - 통화 내용을 텍스트로 변환 후 감정 분석

### Lab Activity
- ec2 (gpu ami) 직접 생성하여
- jupyter notebook을 통해 CNN 학습 flow 실습함
- 데이터 전처리, 배치사이즈 및 파라미터 조절

---

## ML Implementation & Operations (ML 구현 및 운영)

앞서 살펴본 고수준 AI 서비스가 아닌, 사용자가 직접 맞춤형 모델을 개발하고 운영해야 할 때 필요한 환경이 바로 MLOps이다.  MLOps는 모델의 학습, 배포, 모니터링 및 재훈련의 자동화된 반복 주기를 의미하며, Amazon SageMaker는 이 전체 주기를 포괄적으로 지원하는 플랫폼이다.

SageMaker의 핵심 역할은 데이터 사이언티스트와 ML 엔지니어가 인프라 관리에 드는 복잡성과 시간을 최소화하고, 모델 개발의 유연성을 극대화할 수 있도록 지원하는 것이다. 이는 Docker 컨테이너 기술을 기반으로 구현되며, 이 기술은 SageMaker 환경에서 모든 맞춤형 모델 개발 및 배포의 근간이 된다

### SageMaker와 Docker 컨테이너

- SageMaker에서 실행되는 모든 모델은 Docker 컨테이너 기반
- 사전 구축된 Docker 이미지를 제공한다
    - TensorFlow, MXNet, Chainer, PyTorch와 같은 주요 딥러닝 프레임워크 이미지
    - Scikit-learn 및 Spark ML을 위한 이미지
- 사용자는 **자신의 학습 코드 또는 기존 이미지 확장 가능**
	- 사전 구축된 이미지를 활용하거나, 자체 훈련 및 추론 코드를 포함하는 완전히 새로운 이미지를 구축하여 기존 이미지를 확장 가능하다.
        
- 분산 학습 지원:
    - Horovod
	    - 주로 딥러닝 모델의 효율적인 데이터 병렬 훈련에 사용
    - Parameter Server 구조
	    - 전통적인 ML 모델이나 희소(sparse)한 데이터셋 처리에 유용
	- 두가지 모두 지원함으로서 SageMaker가 최신 딥러닝 워크로드뿐만 아니라 광범위한 엔터프라이즈 ML 워크로드까지 포괄적으로 지원한다는 것
    
- 장점:
    - 런타임 또는 프로그래밍 언어에 구애받지 않고, 자체 스크립트나 알고리즘을 SageMaker 플랫폼 내에서 자유롭게 사용할 수 있음
    - 컨테이너는 필요한 종속성을 모두 포함하고, 격리된 환경에서 실행됨

---
## **Docker 사용 방식과 저장 구조**

### **Docker 기본 개념**

- 컨테이너는 **이미지(image)** 로부터 생성됨
- 이미지는 **Dockerfile** 로 빌드됨
- 빌드된 이미지는 레지스트리에 저장됨
    - AWS에서는 **Amazon ECR (Elastic Container Registry)**

### **SageMaker에서의 구성 흐름**

 ![400](images/Pasted%20image%2020251125232153.png)

- ECR: Docker 이미지 저장소
- S3: 학습 데이터 / 모델 아티팩트 저장
- Docker 컨테이너:
    - 학습 컨테이너
    - 배포(추론) 컨테이너
- Endpoints: 배포된 모델이 서비스되는 엔드포인트

 -> 훈련 데이터와 모델 아티팩트는 S3(Simple Storage Service)에 저장되는 반면, 실행 환경(코드 및 종속성)은 Docker/ECR에 저장된다. 이는 MLOps 아키텍처에서 필수적인 **컴퓨팅-스토리지 분리(Decoupling Compute and Storage)** 원칙을 따른다.
 - 이 분리를 통해 훈련 인스턴스가 종료되더라도 데이터와 모델은 영구적으로 보존되며, 훈련 인스턴스의 유형이나 크기를 인프라와 독립적으로 유연하게 조정가능하다.
## **Amazon SageMaker Containers**

- SageMaker와 호환되는 컨테이너를 쉽게 만들기 위한 라이브러리 제공
- Dockerfile 내에서 다음 명령으로 설치:
	- 커스텀 컨테이너를 구축하는 `Dockerfile`에는 반드시 해당 명령을 포함해야 한다.
	- `RUN pip install sagemaker-containers`
    

---

### Structure of a training container

![](images/Pasted%20image%2020251125232225.png)

SageMaker 표준 인터페이스: `/opt/ml` 디렉터리 구조

Table 2: Amazon SageMaker 훈련 컨테이너 `/opt/ml` 디렉터리 구조

|**경로 (Path)**|**목적 및 내용**|**주요 파일/데이터**|
|---|---|---|
|`/opt/ml/input/config`|환경 및 리소스 구성 정보|`hyperparameters.json`, `resourceConfig.json`|
|`/opt/ml/input/data/<channel name>`|훈련 데이터 입력 경로 (S3에서 다운로드된 데이터)|훈련 데이터 파일|
|`/opt/ml/model`|훈련 완료 후 모델 아티팩트 저장소|모델 파일 (예: `model.tar.gz`)|
|`/opt/ml/code`|사용자 정의 훈련 스크립트 위치|`train.py`, 보조 스크립트 파일|
|`/opt/ml/output/failure`|훈련 작업 실패 시 진단 및 오류 로그 저장 경로|오류 메시지 및 스택 추적 파일|


---

## Structure of a Deployment Container

![](images/Pasted%20image%2020251125232250.png)

- 추론에 사용되는 배포 컨테이너는 훈련된 모델 아티팩트만 필요로 하므로 구조가 더 단순하다. 
- 모델 파일은 `/opt/ml/model` 아래에 위치하게 된다
    

---

## Structure of your Docker image

커스텀 Docker 이미지를 구성할 때, 특히 추론 환경을 위한 필수 파일 시스템 구성 요소가 요구된다

- `WORKDIR`: 작업 디렉터리.
	- `nginx.conf`: 웹 서버(Nginx) 구성 파일. Nginx는 프론트엔드 트래픽 처리 및 연결 관리를 담당한다.
	- `predictor.py`: 실제 추론 로직을 구현한 Python 스크립트
	- `serve/`, `train/`: 추론 및 훈련 관련 파일이 포함된 디렉터리
	- `wsgi.py`: WSGI(Web Server Gateway Interface) 진입점. 
		- 이는 Nginx와 Python 기반 추론 서버 간의 효율적인 통신을 위한 표준을 제공한다. 
		- 이 구성은 ML 배포를 고성능의 API 기반 **마이크로 서비스** 관점으로 접근함을 시사한다.

### Dockerfile을 사용한 커스텀 컨테이너 정의

![](images/Pasted%20image%2020251125232354.png)

- 훈련을 위한 기반 이미지(예: TensorFlow)를 선택한 후, SageMaker 훈련 라이브러리를 설치한다. 
- `train.py`와 같은 학습 스크립트를 `/opt/ml/code` 표준 경로로 복사한다. 
- 환경 변수 `SAGEMAKER_PROGRAM`을 `train.py`로 설정하여 SageMaker가 훈련 작업 시작 시 해당 스크립트를 실행하도록 지시한다.

---

## SageMaker 환경 변수 (Environment Variables)

SageMaker는 훈련 인스턴스의 리소스 정보, 데이터 경로, 하이퍼파라미터 등 런타임 구성을 **환경 변수(Environment Variables)**를 통해 컨테이너에 전달한다. 이 변수들은 사용자 스크립트가 훈련 설정을 동적으로 로드하는 주요 메커니즘이다.

| **환경 변수**                      | **목적**                                       |
| ------------------------------ | -------------------------------------------- |
| `SAGEMAKER_PROGRAM`            | `/opt/ml/code` 내에서 실행할 사용자 스크립트 파일명 (훈련 진입점) |
| `SAGEMAKER_TRAINING_MODULE`    | 훈련을 시작하기 위한 모듈 경로                            |
| `SAGEMAKER_SERVICE_MODULE`     | 추론 서비스 시작을 위한 모듈 경로                          |
| `SM_MODEL_DIR`                 | 모델 아티팩트를 저장해야 하는 `/opt/ml/model` 경로          |
| `SM_CHANNELS` / `SM_CHANNEL_*` | 데이터 채널 이름 및 해당 데이터가 다운로드된 로컬 경로              |
| `SM_HPS` / `SM_HP_*`           | 훈련 작업에 정의된 하이퍼파라미터                           |
| `SM_USER_ARGS`                 | 사용자 스크립트에 전달되는 args                          |
- 하이퍼파라미터와 같은 구성 정보가 환경 변수로 제공되는 이유는, 환경 변수가 셸 스크립트나 컨테이너 초기화 단계에서 가장 쉽게 접근할 수 있기 때문이다. 
	- 이는 Python 외의 언어를 사용하거나 초기 설정 단계에서도 ML 설정을 즉각적으로 사용할 수 있도록 플랫폼 접근성을 높여준다. 
	- 또한, `SM_HPS` 변수는 SageMaker의 자동화된 하이퍼파라미터 튜닝(HPT) 작업에서 매 실행마다 새로운 조합을 컨테이너에 주입하여 **대규모 실험 관리**를 용이하게 하는 기반이 된다.

---

## Using your own image

![](images/Pasted%20image%2020251125232602.png)

**핵심**

- 사용자가 Dockerfile을 빌드하고 ECR에 등록했다면, SageMaker Python SDK의 `Estimator` 클래스를 사용하여 해당 이미지를 기반으로 훈련 작업을 시작할 수 있다.
- `image_name` 파라미터에 ECR에 등록된 커스텀 이미지의 URI를 지정
- `role`은 S3 접근 및 ECR 이미지 풀링을 위한 AWS IAM 실행 역할을 정의 
- `train_instance_type`과 `train_instance_count`는 훈련에 할당할 컴퓨팅 자원을 지정
- 로컬 모드 혹은 Amazon EC2 기반 학습 둘 다 지원

## **Production Variants (프로덕션 배포 전략)**

- 실시간 엔드포인트에 여러 모델 버전을 동시에 호스팅하고, 이들 사이에서 트래픽을 분할하여 테스트할 수 있도록 지원하는 기능이다.
    
- **변형 가중치 (Variant Weights)**
	- 트래픽을 각 모델에 어떻게 분산할지 결정
    - 예: 새 모델을 10%만 트래픽을 보내 A/B 테스트 수행, 성능이 우수하면 100%까지 점진적 확대
        
- 이러한 기능은 엔지니어에게 실제 환경에서 모델의 성능을 검증하고 A/B 테스트를 수행할 수 있게 한다.
    
- 오프라인 테스트 결과(예: 테스트 데이터셋에서의 정확도)가 항상 실제와 같지 않기 때문에 중요
	- 오프라인 테스트에서는 실제 트래픽 부하, 데이터 편향(Data Drift) 및 운영적 성능 지표(지연 시간, 리소스 소모)를 완전히 파악하기 어렵다.
	- 프로덕션 변형은 MLOps의 **지속적인 검증(Continuous Validation)** 단계에서 필수적인 요소
    
- 섀도우 변형 (Shadow Variants) 기능 제공
	- 섀도우 배포는 고객에게 반환되는 응답에 영향을 주지 않으면서, 실제 프로덕션 트래픽의 복사본을 새로운 모델(Shadow Variant)에 보내 테스트하는 **무위험(Risk-free)** 방식
		- 실제 요청을 그림자 모델에 보내지만 응답에는 사용하지 않음
	- 이 전략을 통해 엔지니어는 신규 모델이 프로덕션 수준의 부하를 견딜 수 있는지, 그리고 출력 분포가 기존 모델과 예상대로 일치하는지 등 **운영 데이터** 기반의 성능 및 정확도를 검증할 수 있다. 
	- 이는 A/B 테스트(Production Variants)를 시작하기 전에 배포 결정의 신뢰성을 높이는 중요한 전처리 단계이다.
        
- Deployment Guardrails
    - 프로덕션 환경에서 ML 모델을 업데이트할 때 안전성을 극대화하기 위해 Amazon SageMaker AI Inference가 제공하는 일련의 배포 옵션
    - 이는 모델 업데이트 시 발생할 수 있는 잠재적인 **퇴행성 업데이트(Regressive Updates)** (예: 모델 지연 시간 증가, 오류율 증가)의 위험을 완화하고, 통제된 방식으로 기존 모델(Blue fleet)에서 신규 모델(Green fleet)로 트래픽을 전환할 수 있게 한다.
    - 새 모델이 비정상 성능을 보일 경우 자동으로 롤백
	    - 배포 가드레일에는 자동 롤백과 같은 내장 안전장치가 포함되어 있다.
	    - 사용자가 사전에 지정한 Amazon CloudWatch 경보(예: 지연 시간 임계값, 오류율)가 신규 Fleet(Green fleet)에서 트립(trip)되면, SageMaker AI는 이를 자동으로 감지하여 즉시 기존 Blue Fleet으로 롤백을 시작한다. 
	    - 이 메커니즘은 생산에 중대한 비즈니스 영향이 미치기 전에 문제를 자동적으로 해결함으로써 서비스의 가용성을 유지한다. 
	    - 이러한 완전 관리형 배포 기능은 사용자가 자체적으로 복잡한 오케스트레이션, 모니터링, 롤백 메커니즘을 구축하고 유지할 필요가 없도록 만든다