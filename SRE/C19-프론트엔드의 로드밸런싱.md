
# Load Balancing at the Frontend

Google은 초당 수백만 건의 요청을 처리하며, 단일 컴퓨터로 이를 감당하지 않는다.
설령 모든 요청을 처리할 수 있는 슈퍼컴퓨터가 있다고 해도, 단일 실패 지점에 의존하는 전략은 대규모 시스템에 적합하지 않다! 
따라서 데이터센터 간 트래픽을 균형 있게 분산하는 **고수준 로드 밸런싱**이 필수적이다.

---
## Power Isn’t the Answer
모든 일을 힘으로만 해결할 수는 없는 법

설령 결코 고장 나지 않는 네트워크와 매우 강력한 기계를 가진다고 해도 Google의 요구를 충족시키지 못한다.

- 물리적 한계: 빛의 속도는 광케이블의 데이터 전송 속도를 제한하며, 데이터가 이동하는 거리와 속도에 상한선을 만든다.
- 단일 실패 지점에 의존하는 인프라는 위험하다.

#### 현실적인 방법: 트래픽 로드 밸런싱(Traffic Load balancing)

- Google은 수천 대의 기계와 더 많은 사용자들이 동시 다발적으로 요청을 보내는 환경에서 작동한다.
- 특정 요청을 어느 데이터센터에서 얼마나 많은 서버들이 처리할 것인지를 결정하기 위해 "트래픽 로드밸런싱"을 도입했다.
- 트래픽 로드 밸런싱은 요청이 적절히 분산되도록 하며, 이는 다음과 같은 여러 요소에 따라 달라진다.

1. 문제를 평가할 때의 계층 수준( 글로벌 vs. 로컬)
2. 문제를 평가할 때의 기술적 수준 (하드웨어 vs. 소프트웨어)
3. 처리해야 할 트래픽의 특성

1. **검색 요청**
    - 지연 시간(latency) 최소화
    - RTT(round-trip time. 왕복 시간)가 가장 짧은 가까운 데이터센터로 전송
2. **비디오 업로드 요청**
    - 처리량(throughput) 최대화
    - 현재 가장 사용량이 적은 링크로 전송, 지연시간은 감수

- 데이터 센터
	- 데이터센터 내에서는 모든 기계가 사용자와 동일한 거리와 네트워크 연결을 가진다고 가정한다.
	- 여기서는 **자원 활용 최적화**와 **단일 서버 과부하 방지**하는 것에 주력한다.
- 캐시 유지
	- 캐시를 충분히 활용하기 위해 더 먼 데이터센터로 요청을 보내는 경우도 있다.
- 네트워크 혼잡 회피
	- 비대화형(non-interactive) 트래픽(즉각적인 응답이 필요없는)을 다른 지역으로 전달할 수도 있다.

- 결과적으로, Google은 로드 밸런싱을 여러 계층에서 수행하며 이를 다양한 방식으로 최적화한다.

---
## Load Balancing Using DNS
DNS를 활용한 로드 밸런싱

HTTP 요청 전에 클라이언트는 DNS를 통해 IP 주소를 조회한다. 
이때 초기 로드 밸런싱을 적용할 수 있다.

#### DNS 로드 밸런싱

- DNS 응답에 여러 개의 A 또는 AAAA 레코드를 반환하여 클라이언트가 임의의 IP 주소를 선택한다.
- 문제
	- 클라이언트의 동작을 제어하기 어렵고, 트래픽이 고르게 분산되지 않을 가능성이 있다.
	- 클라이언트가 가장 가까운 주소를 결정할 수 없다.

개선 방법

1. **공인 네임서버의 애니캐스트(anycast) 주소 활용**
	- DNS 질의가 가장 가까운 데이터센터로 쿼리를 전달한다.
2. 네트워크와 물리적 위치를 매핑하여 이를 기반으로 DNS 응답 제공한다.
	- 복잡한 DNS 서버 구현 및 지속적인 맵 업데이트 필요함

DNS는 근본적으로 최적화가 쉽지 않다. 
이는 대부분의 사용자 요청이 **재귀적 DNS 서버(resolver)**를 통해 처리되기 때문이다.

#### 재귀 DNS 서버

- 권한 있는 네임서버(authoritative nameserver)는 클라이언트의 실제 IP 주소 대신 재귀 DNS 서버의 IP 주소만 볼 수 있다.
	- **문제**: 네임서버는 클라이언트가 아닌, 재귀 서버와 가장 가까운 경로를 기준으로 응답을 최적화한다.
	- **해결방안**: EDNS0 확장을 사용하여 DNS 쿼리에 클라이언트 서브넷 정보를 포함, 클라이언트 관점에서 최적화된 응답 제공하도록 한다.

- 재귀적 DNS 서버는 단일 데이터센터에서 수천~수백만 명의 사용자를 처리할 수 있다.
	- 한 국가의 ISP가 모든 사용자를 단일 데이터센터에서 처리하면서도, 실제 사용자는 전국적으로 분포
	- 따라서 ISP의 네임서버들은 더 나은 네트워크가 있든 없든 사용자에게 데이터센터에 최적화된 IP 주소를 리턴할 것
#### DNS 캐시

재귀적 DNS 서버는 응답을 캐싱하며, 캐싱된 응답은 TTL(Time-to-Live)에 따라 제한된다.
그 응답이 단일 사용자부터 수천 명의 사용자에게 전달 될 수 있어, 영향을 예측하기가 어렵다.

해결방안
- 각 resolver가 감당할 수 있는 적절한 사용자 수를 분석하고 업데이트했다.
- 사용자 지리적 분포를 예측하여 사용자들을 최적의 위치로 재연결 할 수 있도록 설정
- 지리적 분포 예측시 어려운 점: 사용자들이 넓은 지역에 분산되어있는 경우, 사용자에게 최적의 위치를 선택하는 것과 최적의 경험을 제공하는 것 중에서 취사 선택해야 한다.

#### DNS 로드밸런싱에서 "최적의 위치" 란?

최적 위치"는 일반적으로 **사용자와 가장 가까운 데이터센터**를 의미
아래의 기준도 고려해야한다.
- 데이터센터의 수용량: 요청을 처리할 충분한 용량이 있는지 확인
- 데이터센터 연결성: 데이터센터와 그 네트워크 연결성이 충분한가

-> Google은 트래픽과 수용량, 인프라스트럭처의 상태를 추적하는 **글로벌 제어 시스템**과 공인 DNS 서버와 통합하여 해결.

#### DNS 로드밸런싱의 한계

DNS는 여전히 가장 간단하고 효과적인 초기 로드 밸런싱 방법이지만, 단독으로는 충분하지 않.

- DNS 응답은 RFC 1035에 따라 **512바이트 제한**을 받으며, 이는 응답에 포함할 수 있는 IP 주소 수를 제한한다.
- 이를 보완하기 위해 **가상 IP(VIP)**를 활용한 다음 단계의 로드 밸런싱이 필요하다.

---
## **Load Balancing at the Virtual IP Address**
가상 IP 주소를 이용한 로드밸런싱

가상 IP(VIP)는 특정 네트워크 인터페이스에 할당되지 않고, 여러 기기에서 공유된다.

- 사용자 입장에서는 VIP가 단일 IP 주소처럼 보인다.
- VIP는 상세구현이나 유지보수 작업(업그레이드 또는 기기 추가)을 사용자 모르게 수행할 수 있다.

### network load balancer

VIP 구현에서 가장 중요한 구성 요소는 **네트워크 로드 밸런서**이다.

- 로드 밸런서는 패킷을 수신한 뒤, VIP 뒤에 있는 백엔드 중 하나로 전달한다.
- 백엔드는 패킷을 추가 처리한다.

#### 백엔드 선택방법

1. 최소 부하 백엔드
	- 부하가 가장 적은 머신 선택
	- **문제**: 상태 기반 프로토콜(Stateful Protocol)에서는 요청 중 하나의 백엔드를 지속적으로 사용해야 하므로 실용성이 급격히 무너짐.

2. 연결 ID 기반 해싱
	- 패킷 정보를 활용해 연결 ID를 생성하고, 이를 통해 백엔드 선택
	    - 예: `id(packet) mod N` (N: 설정된 백엔드 수)
	- 연결 상태를 저장하지 않고도 모든 패킷을 동일한 백엔드로 전달 가능.
	- 백엔드가 하나 제거되면 N이 N-1로 변경되어 거의 모든 연결이 새 백엔드로 매핑된다.
	    - 이는 기존 연결이 초기화되어 사용자 경험에 악영향을 미칠 수 있다.

3. 일관된 해싱(Consistent Hashing)
	- 새로운 백엔드 추가/제거 시 매핑이 안정적인 매핑이 가능한 알고리즘 제공
	- 이미 존재하는 연결에 발생하는 문제점을 최소화한다.
	- 시스템에 부담이 과중되면( DDoS 공격 중)되면일관된 해싱 기법으로 대체가능

---

"네트워크 로드밸런서가 정확하게 선택된 VIP 백엔드에 패킷을 전달하려면 어떻게 해야될까?"
#### 패킷 전달

1. 네트워크 주소 변환(NAT)
	- 패킷의 IP 주소를 변경한다.
	- 이 방법은 모든 연결에 대한 추적 테이블을 관리해야하는데, 그럼 상태가 없는(stateless) 메커니즘을 지원하기 어렵다

2. 데이터 링크 계층 조작
	- 패킷의 MAC 주소를 수정하여 백엔드로 전달한다.
	- **장점**: 원래 출발지 및 목적지 IP 주소 유지가능하다.
	- 직접 서버 응답 Direct Server Response(DSR): 백엔드가 원래 송신자에게 직접 응답을 보내는 
	    - **장점**: 로드 밸런서를 통과하는 트래픽을 최소화한다. 작은 크기의 요청만 밸런서를 통과하므로
	    - **문제**: 모든 기기(로드 밸런서 및 백엔드)가 반드시 데이터 링크 계층에서 서로 접근이 가능해야한다.
	    - **Google**: 네트워크 규모가 증가하면서 이 방식은 더 이상 적합하지 않게됐다.

3. 패킷 캡슐화(Packet Encapsulation)
	- Generic Routing Encapsulation(GRE)을 사용해 패킷을 다른 IP 패킷 안에 캡슐화한다.
	    - 로드 밸런서가 백엔드 주소를 목적지로 설정해 패킷 전달
	    - 백엔드는 외부 GRE 계층을 제거하고 내부 패킷을 처리
	- **장점**:
	    - 로드 밸런서와 백엔드가 같은 브로드캐스트 도메인에 있지 않아도 작동 가능하다
	    - 심지어 서로 다른 대륙에 위치해도 문제없다
	- **단점**:
	    - 캡슐화로 인해 패킷 크기 증가(IPv4+GRE 기준 24바이트 추가)
	    - MTU(Maximum Transmission Unit) 초과로 패킷 단편화(Fragmentation) 발생 가능하다

---

핵심내용

- 로드 밸런싱은 표면적으로는 단순해 보이지만, 대규모 환경에서는 많은 세부 사항을 고려해야 한다.

- **DNS 로드 밸런싱의 한계와 해결책**  
    DNS 로드 밸런싱은 간단하지만 클라이언트 동작 제어와 최적의 데이터센터 선택에 한계가 있다. 이를 개선하기 위해 애니캐스트 및 네트워크 맵을 활용하고, EDNS0 확장을 통해 클라이언트 관점의 최적화를 할 수 있따.
    
- **가상 IP(VIP)와 패킷 캡슐화를 활용한 로드 밸런싱**  
    Google은 VIP와 패킷 캡슐화를 사용하여 로드 밸런서를 유연하게 설계하며, 백엔드와 로드 밸런서가 다른 지역에 있어도 안정적으로 작동하도록 구현했다.

새로 알게된 내용

- 구글에서 VIP와 패킷 캡슐화를 활용해 로드밸런싱을 구현했다는 것
	- VIP에서 백엔드를 선택하는 것도
		- 최소 부하 백엔드,연결 ID 기반 해싱, 일관된 해싱(Consistent Hashing) 의 세가지 방법이 있다는 것
- DNS에서의 로드밸런싱 개념이 있다는 것부터 클라이언트로 부터 최적화 하기 어려운 이유들
	- 클라이언트의 동작을 제어하기 어렵고, 트래픽이 고르게 분산되지 않을 가능성이 있으며, 재귀 DNS 로 동작하기 때문에 클라이언트에 가까운 서버가 아닌 재귀 DNS 서버에 가까운 데이터센터로 전송하기 때문