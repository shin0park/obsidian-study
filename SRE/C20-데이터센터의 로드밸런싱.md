
# Load Balancing in the Datacenter

- 데이터센터 내에서 쿼리 스트림을 개별 서버로 분산시키는 알고리즘과 애플리케이션 수준 정책에 대해서 다룸

#### 백엔드 태스크(Backend Tasks)
- 데이터센터 내에 여러개의 서비스가 있으며, 각 서비스들은 각기 다른 머신에서 동작하지만 동일하며 상호 대체가 가능한 서버  프로세스.
#### 클라이언트 테스트(Client Tasks)
- 백엔드 태스크에 대한 연결을 관리
- 각 요청을 어느 백엔드가 처리할지 결정한다.
- TCP나 UDP 프로토콜을 혼합하여 구현된 프로토콜을 이용하여 백엔드와 통신한다.

구글 데이터센터에는 매우 다양한 서비스가 존재하며, 여기서 다루는 내용은 일반적인 사례 기반이다.

### 이상적인 사례
- 이상적인 로드밸런싱 상태는 특정 서비스의 부하가 모든 백엔드 태스크에 균등하게 분배되는 경우이다.
- 현실에서는 부하가 불균등하게 분배되는 경우가 많으며, 이러한 불균형으로 인해 많은 리소스가 낭비되고는 한다.
- 1000개의 CPU를 할당했다고 해도, 로드밸런싱이 비효율적이라면 실제 700개의 CPU만 사용될 수도 있다.

---
## Identifying Bad Tasks: Flow Control and Lame Ducks
비효율적인 태스크 감지: 흐름제어와 Lame Duck 상태
### Flow Control 흐름제어

- 클라이언트는 각 백엔드에 대한 연결별로 요청 개수를 추적할 수 있다고 가정.
- 특정 한도를 초과하면 해당 백엔드를 비정상적(unhealthy)으로 간주하고 추가 요청을 보내지 않는다.
- 일반적으로 요청 한도는 100개정도. (평균적으로 요청들의 처리는 충분히 빨리 완료되므로)

하지만 이 방식은 한계가 존재한다.
- 일부 백엔드는 매우 긴 요청을 처리해야하기 때문에 클라이언트는 이를 과부화 상태로 잘못 판단할 수도 있다.
- 모든 백엔드 태스크가 동시에 제한에 도달하면 전체 서비스가 응답하지 않는 상황이 발생할 수도 있다.
- 즉, 응답이 느린 것뿐인지 정말 unhealthy인지를 식별할 수 없다는 문제가 있다.

## A Robust Approach to Unhealthy Tasks: Lame Duck State
보다 더 강력한 접근 방식

백엔드 태스크는 다음 세가지 상태를 가질 수 있다.
1. 양호함(healthy): 정상적으로 요청을 처리하는 상태
2. 연결거부(Refusing connections): 백엔드가 응답하지 않거나, 시작/종료 중인 상태
3. Lame Duck: 백엔드가 여전히 요청을 수락할 수 있지만, 더 이상 요청을 보내지 않도록 클라이언트에게 알리는 상태

- 백엔드가 Lame Duck 상태로 전환되면, 모든 active 클라이언트에게 이를 알린다.
- 비활성 클라이언트도 주기적으로 UDP healthy check를 수행하기 때문에 대부분의 클라이언트는 빠르게 상태 변화를 감지할 수 있다.
- 장점: 백엔드가 오류 없이 정상적으로 종료될 수 있도록 한다는 것

다음 절차를 따른다.
1. 잡 스케줄러가 SIGTERM 신호를 백엔드 태스크에게 전달한다.
2. 백엔드 태스크는 레임덕 상태로 전환, 클라이언트들에게 요청을 다른 백엔드 태스크에게 전달할 것을 알린다.
3. 백엔드 태스크가 레임덕 상태로 전환되기 전에 처리 중이던 요청들은 정상적으로 실행한다.
4. 클라인트에게 응답을 전달하다 보면 해당 백엔드에 남은 active한 요청의 개수는 0으로 줄어든다.
5. 설정된 일정 시간을 기다린 다음, 백엔드 태스크는 깔끔하게 종료되거나, 잡스케줄러가 태스크를 종료한다.
   이 대기 시간은 제법 큰 값으로 설정하는 것이 좋다. (보통 클라이언트 복잡도에 따라 10초~150초)

코드 배포나 유지보수를 위해 서버를 종료해야하는 경우, 이 전략을 사용하면 active 요청이 자연스럽게 완료된 후 서버를 종료할 수 있다.

---
## Limiting the Connections Pool with Subsetting
연결 풀 제한: 서브셋 

서브셋: 클라이언트 태스크가 상호 작용할 수 잇는 백엔드 태스크 풀의 크기를 제한하는 기법

배경
- Google의 RPC 시스템에서 각 클라이언트는 백엔드 태스크와의 **장기적인 연결(pool of long-lived connections)** 을 유지한다. 이러한 연결은 클라이언트가 백엔드 태스크와 요청이 종료될때까지 연결을 유지하고는 한다.
- why? 매 요청 마다 새로운 연결을 설정하고 종료하면, 리소스 사용량 증가와 latency가 증가할 것이다.
- 따라서 대부분 초기에 연결을 설정한 후 유지하는 방식을 사용하고는 한다.

- 하지만, 모든 클라이언트가 모든 백엔드와 연결을 맺고 아무 일도 하지 않는 상태로 유지되면 리소스 낭비가 심할 것이다.
- 그래서 Google의 RPC 시스템에서는 **"비활성 모드(inactive mode)"** 를 도입했다.
- 비활성 모드에서는 **헬스 체크(health check) 빈도를 줄이고 TCP 연결을 끊은 후, UDP를 사용**하여 최소한의 리소스로 연결 상태를 유지한다.

- 결국 모든 연결은 메모리와 CPU를 양쪽에서 소비하며, 주기적인 헬스 체크를 하는 등 리소스를 사용한다.
	- 개별적으로는 오버헤드가 작을 수는 있어도, 수많은 머신에서 발생하면 심각한 문제가 될 수도 있다.
	- 서브셋은 이런 문제를 해결하기 위해, 하나의 클라이언트가 많은 수의 백엔드 테스크에 연결되거나 혹은 하나의 백엔드 태스크가 많은 수의 클라이언트 태스크들의 연결을 수용할 수 있게 하는 방법이다.

	- 즉, 서브셋은 클라이언트 태스크가 상호 작용 할 수 있는 백엔드 태스크 풀의 크기를 제한하는 기법이다.

### 적절한 서브셋 선택
- 각 클라이언트 연결이 얼마나 많은 백엔드 태스크에 연결될 것인지를 선택해야한다. -> 서브넷 크기를 설정해야함.
- 일반적으로 20~100 개의 백엔드 태스크가 적절한 크기, 최적의 크기는 서비스마다 다름

아래의 경우는 서브셋 크기가 커야된다.
1. 클라이언트 수가 백엔드 수보다 훨씬 적은 경우
	- 클라이언트당 백엔드 수가 너무 적으면 일부 백엔드가 트래픽을 받지 못할 수도 있음.
2. 클라이언트 간의 부하 불균형이 발생할 때
     - 일부 클라이언트가 다른 클라이언트 보다 훨씬 많은 요청을 보낼 경우, burst 순간적으로 많은 요청을 확 보내는 경우
     - 서브셋 크기가 작으면 해당 서브셋 내에서만 부하가 집중될 수도 있으므로

---
### A Subset Selection Algorithm: Random Subsetting
서브셋 선택 알고리즘: 랜덤 서브셋

- 가장 단순한 방식, 클라이언트가 백엔드 목록을 랜덤하게 섞고, 그 중 접근이 가능하고 healthy 상태의 백엔드를 선택해서 서브셋을 구축하는 방식

단점 존재
- 부하가 고르게 분산되지 않음
- 특정 백엔드에 요청이 과다 집중될 가능성 존재

![](images/Pasted%20image%2020250203215930.png)
![](images/Pasted%20image%2020250203215935.png)

위의 그래프처럼 시뮬레이션 결과 동일 패턴을 보임

-> 서브셋 크기를 작게하면 백엔드의 부하의 분균형이 심해진다.

**따라서 랜덤 서브셋 알고리즘은 대규모 시스템에서는 적절하지 않는 방식이다.**

---

### A Subset Selection Algorithm: Deterministic Subsetting
서브셋 선택 알고리즘: 결정적 서브셋

구글은 랜덤 서브셋의 제한을 해결하기 위해 결정적 서브셋 기법을 사용했다.

```
def Subset(backends, client_id, subset_size):
  subset_count = len(backends) / subset_size

  # 클라이언트가 속할 그룹을 선택한다. 각 라운드마다 동일한 방법으로 백엔드 목록을 섞는데 사용한다.
  round = client_id / subset_count
  random.seed(round)
  random.shuffle(backends)

  # 현재 크라이언트 기준으로 서브셋 id를 결정한다.
  # 서브셋의 id는 현재 클라이언트에 대응한다.
  subset_id = client_id % subset_count

  start = subset_id * subset_size
  return backends[start:start + subset_size]

```

- 클라이언트를 여러 라운드로 나눔
- 각 라운드는 동일한 방식으로 백엔드 리스트를 섞음
- 클라이언트는 자신의 ID 기반으로 라운드내에서 서브셋을 선택함
- 각 라운드에서 모든 백엔드가 균등하게 분배됨

ex)
백엔드가 12개([0, 11])이고, 서브셋 크기가 3이라면
각 4개(subsest_count = 12/3) 씩의 클라이언트가 할당된 세개의 라운드를 정의함.
(한 라운드당 클라이언트 4개 존재, 분배된 12개의 백엔드를 하나씩 가져가는)

- 라운드 0: `[0, 6, 3, 5, 1, 7, 11, 9, 2, 4, 8, 10]`
- 라운드 1: `[8, 11, 4, 0, 5, 6, 10, 3, 2, 7, 9, 1]`
- 라운드 2: `[8, 3, 7, 2, 1, 4, 9, 10, 6, 5, 0, 11]`

각 라운드에서 백엔드가 고르게 분배된다.
각 라운드마다 각 백엔드를 클라이언트의 전체 목록 중 한 클라이언트에만 할당한다.
각 라운드는 목록을 혼합할 때 각기 다른 시드 값을 사용

![](images/Pasted%20image%2020250203221720.png)
-> 특정 백엔드에 트래픽이 집중되는 문제를 방지할 수 있다.

---
## Load Balancing Policies
로드밸런싱 정책

클라이언트가 요청을 처리할 백엔드 태스크를 선택하는 로드밸런싱 정책

백엔드 상태에 대한 정보가 필요 없는 간단한 정책: 라운드 로빈
백엔드 부하상태를 반영하는 정책: 최소 부하 라운드 로빈, 가중치 라운드 로빈

---
### Simple Round Robin
단순 라운드 로빈

클라이언트가 자신의 서브셋 내의 백엔드 태스크에 순차적으로 요청을 보내는 방식
구현이 간단하고 임의로 백엔드를 선택하는 방식보다 훨씬 잘 동작했지만 결과는 좋지 않았다. - 부하의 차이가 CPU 사용률이 거의 2배가 나기도 함.

단순 라운드 로빈은 아래와 같은 이유로 부하가 균등하게 분배되지 않을 수 있다.
#### Small subsetting

- 일부 클라이언트는 다른 클라이언트보다 훨씬 많은 요청을 보낼 수 있다.
- 서브셋 크기가 작으면 특정 클라이언트에 의해 일부 백엔드가 과부할될 가능성이 크다.
#### Varying query costs
다양한 쿼리 비용, 요청당 부하 차이

- 서비스에 따라 요청 하나가 차지하는 리소스양이 매우 다를 수 있다.
- 따라서 동일한 요청 수를 분배해도, 각 백엔드의 실제 CPU 사용량을 크게 차이 날 수도 있다. 
- 쿼리 비용의 불규칙성이 큰 시스템의 로드밸런싱은 문제가 크게 발생할 수 있다.

#### Machine diversity
머신의 다양성, 성능차이

- 데이터센터 내 머신들이 동일한 성능을 갖고 있지 않을 수 있다.
- 같은 요청이라도 성능이 낮은 머신에서는 더 많은 CPU 리소스를 필요로 할 수 있다.
- Google에서는 **Google Compute Units (GCU)** 라는 가상 CPU 단위를 사용하여 머신별 성능 차이를 보정하는 방식을 사용함.

#### Unpredictable performance factors
예측 불가능한 성능 요인들

- Antagonistic Neighbors(정반대의 이웃들)
	- 다른 서비스가 동일한 물리적 머신에서 실행되면서 자원을 경쟁적으로 사용하여 성능 저하 초래할 수 있다.
- Task Restarts(태스크 재시작)
	- 일부 서비스는 재시작 후 일정 시간 동안 성능이 낮아질 수 있으며, 이로 인해 과부화가 발생할 수 있다.

이렇게 예기치 못한 성능 문제로 부하가 고르게 분산되지 않을 수 있다.

---
### Least-Loaded Round Robin

각 백엔드의 현재 active 요청 수를 추적하여, 가장 적은 요청을 처리 중인 백엔드에 우선적으로 요청을 배정하는 방식

- 각 클라이언트는 자신이 보낸 백엔드의 active 요청 개수를 추적할 수 있다.
- 새로운 요청을 보낼 때 가장 적은 요청을 처리 중인 백엔드를 선택한다.

문제점
- active 요청 개수는 특정 백엔드 용량을 파악하기에 가장 좋은 방법이 아닐 수 있다.
	- 일부 백엔드는 동일한 active 요청 수를 처리하더라도, 더 빠르게 응답할 수도 있다.
	- 하지만 이를 고려하지 않기 때문에 성능이 좋은 백엔드가 과소 평가될 수 도 있다.
- 각 클라이언트의 active 요청 수는 다른 클라이언트가 같은 백엔드에 할당한 요청의 수를 포함하지는 않는다.
	- 각 클라이언트는 자신이 보낸 요청만 추적하므로 다른 클라이언트들이 특정 백엔드에 많은 요청을 보내고 있는지를 알지 못한다.

---
### Weighted Round Robin

구글에서 널리 사용되는 방식으로,  **백엔드의 성능과 부하 상태를 반영하여 요청을 가중치에 따라 분배하는 방식**

- 각 백엔드는 주기적으로 CPU 사용량, 처리 요청수, 오류 rate를 보고한다.
- 클라이언트는 이를 바탕으로 각 백엔드의 "수용량 점수(capability score)"를 계산한다.
- 높은 점수를 가진 백엔드에 더 많은 요청을 분배한다.
- 즉, 요청의 비율에 따라 가중치를 계산

-> CPU 사용률이 낮은 백엔드에 더 많은 요청을 할당하여 부하를 균형있게 분산
최소 부하 라운드 로빈의 한계를 극복

![](images/Pasted%20image%2020250203223710.png)

