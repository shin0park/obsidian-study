## 데이터 무결성: 내가 기록한 그대로 읽을 수 있어야 한다.
Data Integrity: What You Read Is What You Wrote

#### 데이터 무결성이란 무엇인가?

- **데이터 무결성 정의**: 사용자가 데이터를 신뢰할 수 있는 상태를 의미하며, 사용자에게 원하는 서비스 수준을 제공하기 위해 **데이터 저장소의 접근성과 정확성**을 보장하는 것. 하지만 이 정의는 충분하진 않다.
- ex) Gmail에서 UI 버그로 사서함이 비어 보이면 데이터가 실제로 손실되지 않았더라도 사용자는 이를 데이터 손실로 인식할 수 있다. 이로 인해 Google의 데이터 관리 능력과 클라우드 컴퓨팅의 신뢰성이 의심받을 수 있음. - 단순 UI 버그만으로도 데이터 무결성을 만족 못할수 있다?
- 데이터를 사용할 숭 벗는 기간이 **"너무 길다"의 기준**: 2011년 Gmail 장애 사례에서 4일은 "너무 긴" 시간으로 간주됨. 이후 Google Apps에서는 24시간을 "너무 긴" 시간의 기준으로 설정.
- Google Photos, Drive 등 모든 서비스에 데이터 무결성이 적용되며, 데이터 손실, 손상, 장시간 접근 불가는 사용자에게 동일하게 느껴진다.
- 따라서 데이터 무결성은 모든 서비스의 모든 데이터 유형에 적용된다. 중요한 것은 클라우드 서비스는 사용자에게 접근 가능한 상태를 유지한다는 점이다.

---

#### 데이터 무결성의 중요한 조건
Data Integrity’s Strict Requirements

- **가용성 vs 데이터 무결성**: 시스템의 신뢰성 요구사항을 고려할 때, uptime (서비스 가용성 service availability) 이 데이터 무결성보다 더 엄격한 요구사항으로 보일 수 있다. 
	- 예를 들어, 사용자는 1시간의 이메일 다운 타임을 받아들이기 어려워하지만, 4일 동안 메일함을 복구하는 시간은 견딜 수 있을지 모른다. 
	- 그러나 가동 시간과 데이터 무결성의 요구사항은 다르게 고려해야 한다.
- 어떤 서비스의 SLO가  99.99% uptime을 보장한다면, 
	- 이 서비스는 1년 중 1시간의 downtime만 허용하지만, 
	- 데이터 무결성에서 99.99%는 2GB 데이터에 200KB 손상을 의미하며, 이는 문서, 실행 파일, 데이터베이스에 치명적이다.
- **사용자 기대**: 모든 서비스는 독립적인 업타임과 데이터 무결성 요구사항을 가지며, 데이터 손실러 인한, 사용자의 요구사항 실패가 가장 큰 문제이다.
- **재정의**: 데이터 무결성은 클라우드 서비스가 사용자에게 항상 완벽한 상태로 접근 가능하도록 제공해야한다.
- **사례 분석**: 연간 1회 데이터 손상이 발생하더라도, 사전 탐지와 빠른 복구로 손실을 최소화하면 가동 시간은 99.99%, 데이터 무결성은 100%에 가깝다. 
	- **핵심은 사전 탐지와 신속 복구**이다.

#### 최상의 데이터 무결성을 위한 전략 수립
Choosing a Strategy for Superior Data Integrity

- **전략 매우 다양하다** 
	- 데이터 손실의 빠른 탐지, 복구, 회복 전략은 업타임(가동시간/가용성)과 데이터 무결성 간 균형을 고려해야 한다. 컴퓨팅 패러다임에 따라 달라진다.
	- 대부분의 클라우드 컴퓨팅 애플리케이션은 가용성, 지연 시간, 확장성, 속도, 개인정보 보호 등을 최적화해야 한다.
- **클라우드 기반 애플리케이션의 충족해야할 요소**
    - **uptime**: 가용성(_availability_) 서비스 사용 가능 시간의 비율
    - Latency: 서비스가 사용자에게 얼마나 빠르게 반응하는지
    - **Scale**: 서비스가 처리할 수 있는 사용자 수와 작업량
    - **Velocity(속도)**: 혁신 속도와 비용 효율성
    - **Privacy**: 데이터 삭제 요구 시 적절한 시간 안에 삭제되어야한다.
- **ACID vs BASE**: 
	- 클라우드 애플리케이션은 ACID와 BASE API를 혼합하여 이러한 요구사항을 충족시킨다.
	- BASE는 ACID보다 높은 가용성을 제공하지만, 분산 일관성에 대한 보장은 약하다.
	- ex) Blobstore는 높은 업타임과 낮은 지연 시간을 위해 일관성을 희생, 반면, 중요한 메타데이터는 높은 지연 시간이 있지만 일관성이 높은 Paxos 기반 서비스인 Megastore에 저장
	- 이러한 클라우드 애플리케이션은 런타임에 서로 다른 저장소 간 참조 무결성(referential integrity) 같은 문제에 직면 할 수 있다.
	- 이외에 스키마 변경, 빠른 개발 속도로 인한 복잡성 증가의 현상이 나타난다.
- 이를 방지하기 위해 데이터 저장소 간의 독립적인 무결성 검사 시스템이 필요하다.

---
#### 백업과 아카이브
Backups Versus Archives

- **차이점**: 백업은 애플리케이션을 원상태로 복구하기 위해 사용, 아카이브는 장기 보관용(감사, 규제 준수 등)
- **아카이브**: 금융 데이터 7년 보관
- **백업**: 재해 발생 시 데이터는 빠르게 복구 (일별, 시간별 백업 권장). 최근 데이터 손실 최소화와 얼마나 신속하게 복구할 수 있을지 고려해야함

#### 클라우드 환경에 대한 거시적 요구사항
Requirements of the Cloud Environment in Perspective

- 클라우드 환경에서는 다음과 같은 기술적 문제가 발생할 수 있다.
    - 트랜잭션 및 비트랜잭션 백업/복구 방식이 혼재되어 데이터가 완전하지 않을 수 있다.
    - 만일 서비스가 무중단 운영을 지원해야한다면, 각기 다른 버전의 비즈니스 로직이 병렬로 데이터를 조작 할 수 있다.
    - 독립적으로 버전이 관리되는 서비스 간 호환성 문제로 데이터 손상 위험이 있다
- 이러한 문제를 해결하기 위해 클라우드 제공자는 Data locality, 캐싱, 데이터 분산, 일관성 보장, 내구성, 백업 및 복구를 고려한 API를 제공해야 한다.

---

#### 데이터 무결성과 가용성을 유지하기 위한 구글 SRE 목표
Google SRE Objectives in Maintaining Data Integrity and Availability

- 구글 SRE는 "영구 데이터의 무결성 유지" 하는 것을 목표로 한다. 그러나 단순한 선언이 아니라, 구체적인 측정 지표를 기반으로 성능을 평가하고 테스트해야 한다.
- **데이터 무결성(Integrity)과 가용성(Availability)**: 
	- 데이터 무결성은 데이터의 정확성과 일관성을 의미하지만, 사용자에게는 데이터 가용성이 더 중요하다.
	- 사용자 관점에서 볼 때, 일정 수준 이상의 데이터 가용성을 제공할 수 없는 데이터 무결성은 데이터가 전혀 존재하지 않는 것이나 다름 없기 때문이다.
		- 데이터 존재해도 접속 못하면 그만(email)
- **복구 시스템 구축**
	- 백업 자체보다는 데이터 복구 능력에 집중해야 한다.
	- Google SRE는 백업보다는 복구 목표(Service Level Objectives, SLOs)에 초점을 맞추며, 다양한 장애 시나리오에서 복구 능력을 평가하고 실습한다.
- 데이터 손실을 초래하는장애 유형
	- 근본 원인: 사용자 실수, 운영자 오류, 애플리케이션 버그, 인프라 결함, 하드웨어 고장 등
	- 범위: 특정 사용자만 영향을 받는 경우부터 전체 시스템이 영향을 받는 경우까지 다양함
	- **발생 속도**: 갑작스러운 대규모 손실(예: 1분 내 100만 개의 데이터 손실)부터 점진적인 손실(예: 매일 10개의 데이터가 삭제됨)까지 존재함
		- 효과적인 복구 계획은 이러한 실패 모드의 모든 조합을 고려해야 한다.
		- Google의 연구에 따르면, 가장 일반적인 데이터 손실 원인은 소프트웨어 버그로 인한 참조 무결성 손실 또는 데이터 삭제이며, 발견까지 수 주에서 수 개월이 걸릴 수도 있다. 
		- 이때, 데이터 복구를 위해서는 수백만 명의 며칠, 몇 주 혹은 몇달 간의 데이터를 조회하기 위한 대용량 어플리케이션이 필요하다.
		- 이런 시나리오를 시점 기반 복구(point-in-time recovery)라고도 하며, 구글 내에서는 time-travel 이라고도 한다.
---
#### 더 깊고 폭넓은 데이터 무결성 관리의 어려움
Challenges of Maintaining Data Integrity Deep and Wide

- 데이터 무결성 프로그램을 디자인할 때는, 복제(replication)와 중복저장(redundancy)이 복구 가능성(recoverability)을 보장하지 않음을 인식해야 한다.
- Scaling issues: 전체 백업, 증분 백업, 백업과 복구의 경쟁**
    - **복제의 한계**: 일반적으로 "백업이 있습니까?"라는 질문에 "복제 기능이 있습니다!"라고 답하는 경우가 많지만, 이는 완전한 해결책이 아니다.
	    - 복제는 특정 사이트의 장애로부터 보호해 주지만, 실수로 인한 삭제나 데이터 손상의 경우 모든 복제본에 즉시 영향을 미친다.
	    - 이를 보완하기 위해 별도의 형식으로 데이터를 저장하는 방법(예: 주기적인 데이터베이스 내보내기)이 있지만, 파일 시스템 또는 디바이스 드라이버 수준의 취약점이 있다면 모든 데이터가 영향을 받을 수 있다.
    - **이러한 문제를 해결하려면 다양한 계층에서 데이터를 보호해야 한다.
	    - 계층별 손실 방어를 위해 다양한 구성 요소에 저장한다.
- **보존 기간(Retention)**
    - 데이터 보존 기간은 데이터 복구 계획에서 중요한 요소이다.
    - 갑작스러운 데이터 손실은 즉시 발견되지만, 점진적인 데이터 손실은 며칠이 지나야 발견될 수 있다. 
    - 따라서, 장기간의 백업 데이터를 유지하는 것이 중요하.
    - 오래된 스냅샷 필요하고, 현재 상태와 병합 시 복잡성이 증가 할수도 있다.
---

#### 구글이 데이터 무결성 문제를 해결하는 방법
How Google SRE Faces the Challenges of Data Integrity

**Google은 모든 시스템이 장애에 취약하다는 가정하에 데이터 보호 전략을 수립한다. 
단일한 해결책이 아니라 상호 독립적인 여러 보호 계층을 활용하는 것이 핵심이다.**
#### 데이터 무결성 실패 모드 24가지 조합

- 단일 해결책으로 모든 문제를 방지할 수 없다. 
	- 따라서, "심층 방어(defense in depth)" 전략이 필요하다. 
	- 심층 방어는 여러 계층으로 구성되며, 각 계층은 점점 더 희귀한 데이터 손실 시나리오를 방지하는 역할을 한다.
---
#### **첫 번째 계층: 소프트 삭제 (Soft Deletion)**

- 대다수의 데이터 손실은 애플리케이션 버그로 인해 발생하며, 특히 개발자가 삭제 관련 코드를 수정할 때 문제가 빈번히 발생한다. 
- 따라서, 데이터 삭제 시 즉시 제거하는 것이 아니라 일정 기간 동안 '삭제됨'으로 표시하는 것이 중요하다.
- Google은 Gmail과 같은 서비스에서 소프트 삭제를 활용하여 사용자가 일정 기간내에 데이터를 복구할 수 있도록 지원한다. 
	- 휴지통 기능(예: Gmail 30일 이내 복구)으로 실수 삭제 부담 감소한다.
	- 또한, 계정 탈취와 같은 상황에서도 데이터를 복구할 수 있도록 설계되어 있다. 
	- 일반적으로 소프트 삭제 기간은 15일~60일이며, 60일 이내에 대부분의 데이터 무결성 문제가 보고된다.
- **개발자 실수 방지**: 익숙하지 않은 개발자의 삭제 코드(특히 배치 처리 파이프라인)로 인한 손실 방지를 위해 소프트 삭제 기능 및 삭제 취소 API를 구현한다.
- **클라우드 제공**: "Lazy Deletion"로 소프트 삭제의 추가 계층을 구현한다.
	- 클라우드 애플리케이션이 삭제한 데이터는 그 즉시 애플리케이션에 접근할 수 없는 상태가 되지만, 쿨라우드 서비스 제공자에 의해 몇 주간 보존된다. 
	- 단, 단기 데이터가 많거나 프라이버시 보장이 필요한 경우 부적합하다.
---
#### **두 번째 계층: 백업 및 복구 방법**

- 소프트 삭제가 일어난 이후의 이차적 방어선이다.
- 백업 그 자체보다 중요한 것은 복구 능력이다. 복구에 중점을 두어야한다. 
- 백업을 통해 데이터를 복구하기 위해서는 다음 사항을 고려해야한다.
	- **백업 방식**: 전체 백업과 증분 백업을 적절히 조합해야 한다.
	- **백업 빈도**: 데이터 손실 가능성을 최소화하기 위해 증분 백업 빈도를 증가시킬 수 있다.
	- **백업 저장 위치**: 데이터 복구 시간을 고려하여 로컬 및 원격 백업을 조합해야 한다.
	- **보존 기간**: 데이터 삭제 및 변형 오류를 감안하여 장기 백업을 유지해야 한다.
		- 오래 보존할수록 비용 증가, 복구 가능 시나리오 증가한다. 
- 빠른 개발 환경에서 코드/스키마 변경으로 오래된 백업 활용 어렵기도하다. 
- Google은 고빈도 백업(수 시간 내 복구 가능), 중기 백업(수 일 내 복구 가능), 장기 백업(수 주~수 개월 내 복구 가능)으로 계층화된 백업 전략을 사용한다. 
- Google은 빠른 복구를 위해 로컬 스토리지에 단기 백업을 저장하고, 장기 백업은 오프사이트(offsite storage) 및 테이프 라이브러리(tape libraries)를 활용하여 보관한다.

가장 중요한 단계: 복제 
Overarching Layer: Replication
- 백업 데이터 자체도 장애에 취약할 수 있기 때문에, 이상적인 경우라면 모든 저장 인스턴스는 복제되는 것이 좋다. 
- 다만, 데이터 규모가 증가함에 따라 전체 복제가 어려운 경우, 
- 서로 다른 사이트에 분산된 백업을 운영하고, RAID, Reed-Solomon 오류 정정 코드 등을 활용한 이중화 방식을 적용해야 한다.
---
#### **세 번째 계층: 조기 탐지(Early Detection)**

- 데이터 손상은 시간이 지남에 따라 전파되고 확산되므로, 조기 탐지가 중요하다.
- Google은 지속적인 데이터 검증과 자동화된 감지 시스템을 운영하여 데이터 손실이나 변형을 빠르게 발견하고 대응할 수 있도록 하고 있다.
- 클라우드 개발자들은 다음과 같은 데이터 무결성 문제에 직면한다
    - 데이터 저장소 간의 참조 무결성(Referential Integrity)
    - 스키마 변경(Schema Changes)
    - 오래된 코드
    - 무중단 데이터 마이그레이션
    - 다른 서비스와의 연결 지점 변화
        
- 초기 클라우드 개발자는 분산된 일관성 있는 저장 API(Megastore)를 선택해 애플리케이션 데이터의 무결성을 해당 API 밑의 분산 일관성 알고리즘(Paxos)에 맡겼다.
    - **이론 vs 현실**: 알고리즘은 완벽하나 구현은 해킹, 최적화, 버그로 불완전했다.
	    - Paxos는 실패한 컴퓨팅 노드를 무시하고 노드가 일정 수 이상 작동하면 진행할 수 있다고 이론적으로는 말하지만, 실제로는 실패한 노드를 무시하면 타임아웃, 재시도 등과 같은 오류 처리 방식에 의해 예기치 않은 동작이 발생했었다.
	    - 애플리케이션 규모가 커질수록, 이러한 불일치로 인한 영향을 인지하지 못한 채 애플리케이션이 영향을 받게됐다.
    - **결론**: Paxos 및 Bigtable 등 모든 저장소는 검증 없이는 100% 신뢰 불가하다. **신뢰하되 검증**이 필수다.
- 이러한 문제를 해결하기 위해 **대역 외 데이터 검증(Out-of-Band Data Validation)** 시스템이 필요하다.
- Google은 MapReduce 또는 Hadoop 작업을 통해 데이터 검증 파이프라인을 구축하며, 이를 통해 데이터 손실이나 손상을 조기에 탐지했다.
- 데이터 검증은 엔지니어링 속도를 늦출 수 있지만, 장기적으로는 개발자들이 더 빠르게 코드를 변경할 수 있도해주기 때문에 소프트웨어 개발 프로젝트의 전반적인 속도를 가속화한다.
---
#### 데이터 복구의 동작 여부 확인하기

- 아래의 요소들을 확인해야 한다.
	- 백업이 유효하고 완전한지
	- 복구 작업에 필요한 머신 리소스가 충분한지
	- 복구 프로세스가 합리적인 시간 내에 완료되는지 
	- 복구 과정을 모니터링할 수 있는지 
	- 외부 자원에 대한 의존성이 없는지

- 복구 테스트는 수동이 아닌 자동화되어야 하며, 지속적으로 실행되어야 한다.
- Google은 정기적인 복구 테스트를 통해 다양한 실패를 발견하고, 실제 데이터 손실 상황에서 문제를 해결할 수 있도록 준비했다.
---
### 사례연구

#### Gmail—2011년 2월: GTap로부터의 복원

Gmail 백업 시스템의 pager를 작동하여 컨퍼런스 콜에 합류할 수 있는 전화번호를 보내왔는데, 결국 지메일에서 상당한 양의 사용자 데이터 유실이 발생했다.
Gmail은 상당량의 사용자 데이터를 잃었고, 이는 GTape 오프라인 백업 시스템을 사용한 첫 번째 대규모 복구 사례가 되었다.

- **복구 과정**
    - GTape을 사용하여 대부분의 영향을 받은 사용자 계정을 몇 시간 내에 복구했으며, 이 시간을 예상했다.
    - 99% 이상의 데이터를 예상 시간 내에 복구했다.
    - 이 성공은 철저한 계획, 모범 사례의 준수, 협업의 결과였다.
        
- **심층 방어(Defense in Depth)**
    - 일반적으로 Google은 대량의 디스크와 빠른 네트워크를 통해 데이터를 복제하지만, 다중 방어 원칙에 따라 오프라인 테이프 백업을 추가적인 보호 계층으로 활용했다.
        
- **협력과 준비**
    - 이 사건에서 가장 중요한 점은 여러 팀이 원활하게 협력하여 복구를 수행했다는 것이다.
    - 이는 사전에 철저한 훈련과 모의 연습을 거쳤기 때문이며, Google은 이러한 장애를 피하려고만 하지 않고, **필연적으로 발생할 것**이라는 가정하에 대비하는 전략을 채택하고 있다.
---
#### Google Music – 2012년 3월: 데이터의 삭제가 급증하는 문제 발생

Google Music 사용자가 이전에 문제 없이 재생되던 트랙이 건너뛰어진다고 보고했다. 
초기 조사는 단순한 미디어 스트리밍 문제로 시작되었지만, 조사 결과 데이터 무결성 문제임이 드러났다.

엔지니어는 삭제된 데이터 참조 정보를 발견하고 경악했다. 이는 대량의 음악 데이터를 빠르게 삭제하도록 설계된 **개인정보 보호 삭제 파이프라인**에 의해 삭제된 것이었다.

손실된 데이터의 확인

- Google Music의 개인정보 보호 정책에 따라 사용자가 음악 파일을 삭제하면 일정 기간 내에 관련 데이터가 제거된다.
- 2012년 2월 6일, 삭제 프로세스가 새롭게 최적화되었고, 조사 결과 **약 60만 개의 오디오 참조 데이터가 잘못 삭제**되어 21,000명의 사용자에게 영향을 미쳤음이 밝혀졌다.
        
- **버그 식별 및 복구 병행 진행**
    - 근본적인 버그를 수정하지 않으면 복구가 무의미하다.
    - 데이터 삭제 파이프라인을 일시 중지하여 추가 피해 방지했다.
- 백업 데이프 복구
    - Google Music의 백업 테이프는 오프사이트 저장소에 보관되었기에 오프사이트로부터 복구했다.
    - 엔지니어 팀을 두 그룹으로 나누어 하나는 버그 수정, 다른 하나는 데이터 복구 진행했다.
        
1. **복구 1단계**
    - 약 1.5PB의 데이터를 포함한 복구 작업 수행
    - 자동화된 프로그램을 사용하여 복구 요청 처리
    - 이로써 99.95%의 복구 작업 완료
        
2. **복구 2단계**
    - 16만 개의 손실된 파일 중 일부는 스토어에서 다시 다운로드 가능
    - 사용자가 직접 업로드한 파일은 Google Music 클라이언트가 재업로드하도록 요청하여 복구 진행
    - 최종적으로 모든 데이터 복구 완료
        
**근본 원인 해결**

- 삭제 파이프라인은 단계적으로 데이터를 삭제하지만, **병렬화 및 데이터 복사 과정에서 발생한 race condition** 때문에 일부 데이터가 예기치 않게 삭제되었다. 
- Google은 이를 방지하기 위해 다음과 같은 조치를 취했다.
	- 데이터 삭제 파이프라인을 재설계하여 race condition 방지
	- 대규모 데이터 삭제를 사전에 탐지하고 경고하는 모니터링 시스템 구축

---
#### 데이터 무결성과 관련된 SRE의 일반 원리들

데이터 무결성 및 클라우드 컴퓨팅과 관련해서 SRE가 고려해야할 일반 원래들

**1. 초심자의 마음가짐 (Beginner’s Mind)**

- 복잡한 시스템에는 항상 이해하지 못하는 버그가 존재할 가능성이 있다
- **“이 시스템은 절대 그렇게 실패하지 않을 것이다”라는 생각을 버려야 한다**
- 방어 체계를 여러 겹으로 구성해야 한다
    
**2. 신뢰하되 검증하라 (Trust but Verify)**

- 모든 API는 불완전하므로 중요한 데이터는 **독립적인 검증 시스템(out-of-band validation)** 으로 확인해야 한다

**3. 희망은 전략이 아니다 (Hope Is Not a Strategy)**

- 데이터 복구 시스템은 정기적으로 테스트해야 하며, **자동화를 통해 지속적인 점검이 이루어져야 한다**
    
**4. 다중 방어 조치 (Defense in Depth)**

- 단일 시스템은 결코 완벽하지 않으므로 다층적 보호 전략을 수립해야 한다
    
**5. 지속적인 점검과 재검토 (Revisit and Reexamine)**

- 시스템이 어제 안전했다고 해서 오늘도 안전한 것은 아니다
- 서비스가 성장하면서 데이터 무결성 전략도 계속 수정해야 한다

이러한 원칙을 통해 Google은 대규모 데이터 삭제 사고에서도 데이터를 성공적으로 복구하고, 시스템을 개선하여 향후 사고를 방지할 수 있었다

---
결론

Google SRE는 데이터 무결성을 보장하기 위해 다음과 같은 전략을 사용한다:
1. **소프트 삭제**: 실수로 인한 데이터 삭제를 방어하는 첫 번째 방어선
2. **백업 및 복구**: 복구 가능성을 중심으로 한 계층화된 백업 전략
3. **조기 탐지**: 데이터 손실이나 손상을 조기에 탐지하고 해결하기 위한 대역 외 데이터 검증 시스템
4. **지속적인 복구 테스트**: 데이터 복구 프로세스가 실제로 작동할 것임을 확인하기 위해 정기적으로 테스트를 실행