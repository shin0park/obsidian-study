# Data Processing Pipelines

전통적 데이터 처리는 데이터를 읽고, 원하는 방식으로 변환한 뒤 새 데이터를 출력하는 프로그램을 작성하는 것이다. 이를 데이터 파이프라인이라 한다. 이는 점점 발전하여 "빅데이터"의 등장으로 주목을 받았다.

#### 단순한 파이프라인 패턴을 적용한 빅데이터의 기본적인 효과
Initial Effect of Big Data on the Simple Pipeline Pattern

- 빅 데이터를 주기적 또는 연속적으로 변환하는 프로그램은 "단순 단일 단계 파이프라인(one phase)"이라 불린다.
- 빅 데이터의 규모와 처리 복잡성 때문에 프로그램은 출력이 다음 입력이 되는 연쇄적 시리즈로 구성된다. -> 다단계 파이프라인 (multiphase pipelines)
- 이런 방식의 프로그램은 다단계 파이프라인이라 하며, 각 프로그램이 개별 데이터 처리 단계를 담당한다.

---
#### 정기적 파이프라인 패턴의 과제

- 정기적 파이프라인(periodic pipline)은 일반적으로 데이터를 처리할 충분한 작업자가 있으며, 처리에 대한 수요를 연산 능력으로 감당할 수 있을 때 안정적으로 동작한다.
- sre 경험으로 보면 정기적 파이프라인은 장애가 발생하기 쉽다.
- 자연적인 증가와 변화가 문제로 발생한다. (실행 기한 초과, 자원고갈, 처리 청크 멈춤에 의한 운영 부하)
---
#### 불균등한 작업 분배로 인한 문제

빅 데이터의 핵심은 "무조건적 병렬"알고리즘을 이용해 대용량 부하를 개별 머신이 처리할 수 있을 정도의 청크(chunk)로 나누어 애플리케이션에 전달하는 기법이다.

- 청크마다 자원 요구량이 달라 초기에는 이유가 명확하지 않을 수 있다.
- "청크 처리 정지(hanging chunk)" 문제는 클러스터 머신 간 차이나 과도한 자원 할당으로 발생하며, 스트림 같은 실시간 작업의 어려움에서 비롯된다. 사용자는 모든 계산이 완료될때까지 다음단계를 기다린다.
- 데이터를 나누는 방법에 따라 최악의 성능을 내면서 처리 시간이 현저히 늘어날 수 있다.
---
#### 분산 환경에서 정기적 파이프라인의 단점

- 빅데이터 정기적 파이프라인은 구글에서 폭넓게 사용되고 있다.
- 정기적 파이프라인은 일반적으로 실시간 서비스보다 우선순위가 낮으며 클러스터 자원을 효율적으로 활용할 수 있도록 설계된다.
- 하지만 이로 인해 다음과 같은 문제가 발생할 수 있다.
	- 낮은 우선순위로 인해 실행 지연 발생
	- 실행 빈도가 증가할수록 파이프라인 실행 간 최소 지연 시간이 한계점에 도달
	- 스케줄링 정책에 따라 실행이 중첩되거나, 기존 작업이 중단되는 문제 발생
- 이를 해결하려면 충분한 서버 자원을 확보해야 하지만, 공유 환경에서는 자원 할당이 쉽지 않다. 
- 따라서 배치 스케줄링 리소스와 프로덕션 우선순위 리소스를 구분하여 자원 확보를 최적화하는 전략이 필요하다.
---
#### 정기적 파이프라인의 모니터링 문제

- 실행 시간이 긴 파이프라인에서는 실시간 성능 모니터링이 필수적이다.
- 하지만 정기적 파이프라인에서는 일반적으로 실행 중에 수집된 메트릭을 종료 후에만 보고하기 때문에, 실행 중 문제가 발생하면 실시간으로 대응하기 어렵다.
- 반면, 지속적으로 실행되는(continuous) 연속 파이프라인에서는 이러한 문제가 발생하지 않는다.
- 이유: 작업들이 지속적으로 실행되며 실시간 메트릭을 제공하도록 설계되었다.

---
####  "Thundering Herd" 문제
천둥소리

- 대규모 파이프라인의 각 주기에서 수천 워커가 동시에 시작되면, 워커 과다, 오설정, 잘못된 재시도 로직으로 서버, 클러스터 서비스, 네트워킹 인프라가 과부하된다.
- 특히, 재시도(retry) 로직이 부적절하게 구현되었을 경우 문제를 더욱 악화시킬 수 있다.
- 엔지니어링 경험이 부족한 운영자가 실행 시간을 단축하기 위해 단순히 더 많은 작업자를 추가하는 경우에도 같은 문제가 발생할 수 있다. 
- 따라서 대규모 주기적 파이프라인에서는 작업자 수를 적절히 조정하고, 재시도 로직을 정교하게 설계하는 것이 중요하다.
---
#### 모아레 부하 패턴(Moiré Load Pattern

- "모아레 부하 패턴"은 여러 개의 주기적 파이프라인이 동시에 실행되면서 공유 자원을 과도하게 소비하는 현상을 의미한다.
- 여러 개의 파이프라인이 일정 간격으로 실행되다가 특정 시점에서 실행 간격이 중첩되면 리소스 사용량이 급증하여 시스템에 부하를 초래할 수 있다. 
- 이 패턴은 파이프라인의 공유 자원 활용도에 주로 나타난다.
![](images/Pasted%20image%2020250310223139.png)

---
#### 구글 Workflow 소개

- 일회성 배치(batch) 파이프라인이 지속적으로 갱신되는 결과를 요구하는 비즈니스 요구 사항에 부딪히면, 개발팀은 기존 설계를 개편하거나 연속적인 파이프라인 모델로 전환하는 방법을 고려하게 된다.
- 그러나 이러한 전환은 주로 적절하지 않는 시점에 발생하며, 새로운 기능 추가와 엄격한 마감 기한까지 맞춰야 하는 경우가 많다.
- 이러한 문제를 해결하기 위해 Google은 2003년 "Workflow"라는 시스템을 개발했다.
- 이 시스템은 리더-팔로워(leader-follower) 분산 시스템 설계 패턴과 system prevalence(만연성, 널리퍼짐) design 패턴을 활용한다. 
- 이로써 대규모 트랜잭션 데이터 파이프라인을 지원하며, 정확히 한 번만 실행되는(exactly-once) 처리를 보장한다.

#### Workflow와 모델-뷰-컨트롤러(MVC) 패턴

Workflow는 system prevalence 개념을 적용하여 모델-뷰-컨트롤러(MVC) 패턴을 분산 시스템에 맞게 확장한 형태로 볼 수 있다.

- **모델(Model)**: "Task Master"라는 서버가 모든 작업 상태를 메모리에 유지하며, 동기적으로 변화를 디스크에 기록한다.
    
- **뷰(View)**: 시스템의 상태를 트랜잭션 단위로 갱신하는 작업자 프로세스이다.
	- 작업자(Workers)들은 시스템 상태를 지속적으로 갱신하는 역할을 한다. 
	- Task Master에는 전체 데이터가 저장될 수도 있지만, 보통은 작업의 포인터만 저장하고 실제 입출력 데이터는 공용 파일 시스템이나 별도의 저장소에 보관하는 것이 성능 면에서 유리하다.
    
- **컨트롤러(Controller)**: 선택적으로 추가 가능하며, 파이프라인에 영향을 미치는 보조적 성격들 띠는 시스템 활동들
	- 파이프라인의 런타임 확장, 스냅샷 생성, 상태 롤백, 글로벌 차단 등의 기능을 수행할 수 있다.
![](images/Pasted%20image%2020250310224229.png)
---
### Workflow 실행 단계

- Workflow는 여러 개의 태스크 그룹(Task Groups)으로 나뉘어 있으며, 각 그룹은 특정 데이터 처리 단계를 담당한다. 
- 이러한 구조를 통해 맵핑(mapping), 셔플링(shuffling), 정렬(sorting), 분할(splitting), 병합(merging) 등의 작업을 쉽게 수행할 수 있다.
- 각 단계에는 특정 유형의 작업자(Workers)가 할당되며, 여러 개의 작업자가 동시에 실행될 수 있다. 
- 작업자들은 스스로 어떤 작업을 수행할지 결정할 수 있으며, 이전 단계에서 받은 작업을 처리하여 다음 단계로 출력한다. 
- Workflow 내에서는 모든 작업이 한 번만 실행되도록 보장되며, 처리된 작업은 영구적으로 저장된다.

#### Workflow의 정확성 보장 (Correctness Guarantees)

- Task Master는 RAM 크기 제한 때문에 파이프라인의 모든 상태 정보를 저장할 수 없다.
- 하지만 **이중 정확성(double correctness) 보장**을 통해 시스템의 무결성을 유지한다.
	- 이를 위해 Task Master는 **고유한 데이터 포인터 집합**을 보유하고, 각 작업 단위(Work Unit)에 대해 **고유한 임대(lease)**를 설정한다.
	- 작업자들은 임대를 통해 작업을 획득하며, 현재 유효한 임대 데이터를 보유하고 있는 태스크에 대해서만 작업을 수행한다.

- 이중 정확성
	- 고아 작업자(orphaned worker)-마스터와 연결이 끊긴 작업자가 작업을 계속 수행해 현재 작업자의 결과를 덮어쓰는 문제를 방지하기 위해, **각 작업자가 열어둔 출력 파일은 고유한 이름을 가진다.**
		- 이렇게 하면, 고아 작업자가 마스터(Task Master)와 독립적으로 작업을 계속할 수 있지만, 최종적으로 커밋을 시도하면 **이미 다른 작업자가 해당 작업을 소유하고 있기 때문에 커밋할 수 없다.**
		- 결과적으로, **출력 파일의 고유성**과 **임대 기반의 작업 보장**을 통해 **이중 정확성 보장**이 유지된다.

	- 즉, **작업자는 유효한 임대(lease)**를 가지고 있어야만 작업을 수행하고 커밋 가능
	- **출력 파일은 고유한 이름을 가짐**, 고아 작업자가 기존 작업을 덮어쓰지 못함

- **삼중 정확성 보장**
	- 모든 작업은 **버전 관리**되며, 설정이 변경되면 기존 작업자는 커밋 불가
    - 임대와 작업 ID 검증을 통해 **일관된 상태 유지**

- **추가적인 안전장치**
	- 하지만, 삼중 정확성 보장만으로 모든 문제를 해결할 수 있는 것은 아니다
	- Task Master의 네트워크 주소가 변경되었거나, 메모리 손상으로 인해 IP나 포트 번호가 잘못 매핑된 경우 등..
    - **Task Master의 고유 서버 토큰을 검증**하여 잘못된 설정이나 충돌 방지
#### **Workflow의 4가지 정확성 보장**

1. 설정(task ID) 변경이 반영된 작업만 커밋 가능
2. 유효한 임대를 가진 작업자만 커밋 가능
3. 출력 파일은 항상 고유한 이름을 가짐
4. Task Master는 서버 토큰 검증을 통해 정합성 유지

---
#### **비즈니스 연속성 보장**

Workflow는 **장애(네트워크 단절, 전력 장애 등) 발생 시에도 데이터 처리를 지속**할 수 있도록 설계되었다.

1. **Spanner를 활용한 글로벌 일관성 유지**
    - Task Master는 Spanner에 **저널(journal)을 저장**하고, **Chubby 분산 잠금 서비스**로 쓰기 권한을 조정
    - Spanner는 **전역적으로 일관성이 유지되는(low-throughput) 파일 시스템** 역할을 한다.
    - 여러 개의 Task Master가 존재할 경우, **분산 잠금 서비스(Chubby)**를 사용하여 하나의 Task Master만 쓰기 권한을 가지도록 보장한다.
2. **로컬 및 글로벌 Workflow 구조**
    - Spanner는 높은 처리량을 제공하지 않기 때문에, **각 지역(cluster)별로 독립적인 Workflow를 실행**하면서도 **전역 Workflow(Global Workflow)를 통해 전체적인 일관성을 유지**하는 방식을 사용한다.
    - 개별 파이프라인에서 작업이 진행될 때, 해당 작업을 전역 Workflow에도 기록한다.
    - 작업이 완료되면, 전역 Workflow에서도 해당 작업을 제거한다.
    - 만약 전역 Workflow에서 작업을 삭제할 수 없다면, **로컬 Workflow는 작업을 계속 진행하지 않고 대기(blocking) 상태**에 머물게 된다.  
    - -> 이를 통해 **트랜잭션 일관성을 보장**할 수 있다.**
3. 자동 장애 조치(Failover)**
    - 보조 바이너리(helper binary)가 **하트비트(heartbeat) 업데이트**
    - 하트비트 누락 시 **다른 Workflow가 작업을 이어받아 지속 처리**

---
요약
- **정기적인(Periodic) 파이프라인은 유용하지만, 데이터 처리가 지속적(Continuous)이라면 적합하지 않음**
- **Workflow 같은 연속적 데이터 처리 시스템을 활용해야 함**
- Workflow는 **분산 클러스터 환경에서 높은 성능과 확장성을 제공하며**,
- **강력한 정확성 보장과 비즈니스 연속성을 유지하는 안정적인 시스템**으로 운영 가능함